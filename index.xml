<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bogdan Penkovsky, PhD on Bogdan Penkovsky, PhD</title>
    <link>https://penkovsky.com/</link>
    <description>Recent content in Bogdan Penkovsky, PhD on Bogdan Penkovsky, PhD</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Bogdan Penkovsky 2024</copyright>
    <lastBuildDate>Wed, 14 Aug 2024 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Gentle Introduction to Quantum Machine Learning</title>
      <link>https://penkovsky.com/post/qml/</link>
      <pubDate>Sun, 11 Aug 2024 11:45:48 +0200</pubDate>
      
      <guid>https://penkovsky.com/post/qml/</guid>
      <description>&lt;p&gt;Why quantum machine learning or QML might be worth exploring?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Quantum models are inherently generative.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/post/qc/&#34;&gt;Quantum parallelism&lt;/a&gt; over bits in superposition.&lt;/li&gt;
&lt;li&gt;In certain cases, quantum models can be more interpretable than classical models.&lt;/li&gt;
&lt;li&gt;Learning from quantum data. Data generated by quantum processes.&lt;/li&gt;
&lt;li&gt;This is the very beginning of the QML field, so there are many opportunities for breakthroughs.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Edit 21/08/2024:&lt;/strong&gt; Added results running the ML model on a real quantum computer.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;It is probably worth mentioning that by quantum machine learning we usually mean
a form of machine learning where a &lt;em&gt;part of&lt;/em&gt; algorithm is executed on a quantum
computer.
In certain cases (small number of qubits or non-entangled states),
a quantum algorithm is efficiently simulated on a classical machine.
Such as your laptop.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Machine_learning&#34;&gt;Machine learning&lt;/a&gt; refers to
algorithms learning by examples. That is, learning from data.
The difference between machine learning and other subfields of
&lt;a href=&#34;https://en.wikipedia.org/wiki/Artificial_intelligence&#34;&gt;AI&lt;/a&gt; is that machine
learning heavily relies on statistics. Unlike symbolic approaches for instance.
The most popular application of machine learning, apparently, is
being able to tell if there is a cat in a given picture or not.
At least that would be quite hard with a symbolic approach.
Obviously, in quantum machine learning, the cat would be
&lt;a href=&#34;https://sciencing.com/wavefunctions-definition-properties-equation-signs-w-diagrams-13722576.html&#34;&gt;Schrödinger&#39;s&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Disclaimer: The article assumes some familiarity with quantum mechanics and
statistics. If you are new to quantum computing, I recommend starting
with the &lt;a href=&#34;https://penkovsky.com/post/qc/&#34;&gt;Quantum Computing&lt;/a&gt; post.
You may also safely ignore the blue boxes providing unnecessary mathematical
details in this article.&lt;/p&gt;

&lt;h2 id=&#34;quantum-model-as-an-expectation-value&#34;&gt;Quantum Model as an Expectation Value&lt;/h2&gt;

&lt;p&gt;A quantum model $f_{\theta}$ parameterized by $\theta$ can be represented as an
expectation value&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-expval&#34;&gt;&lt;a href=&#34;#fn:fn-expval&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; of an observable operator $\mathcal{M}$:&lt;/p&gt;

&lt;p&gt;$$ f_{\theta} = \langle 0 | \mathcal{M} | 0 \rangle,$$&lt;/p&gt;

&lt;p&gt;where $| 0 \rangle$ is the ground
state of the quantum system. The expectation value of $f_{\theta}$ is a real
number since $\mathcal{M}$ is a Hermitian operator. It &lt;em&gt;must&lt;/em&gt; be
Hermitian because physically we can only measure real numbers (see also
the blue box &amp;quot;Expectation Values&amp;quot;).&lt;/p&gt;

&lt;div class=&#34;alert alert-info&#34;&gt;
&lt;h4&gt;Hermitian Operators&lt;/h4&gt;
An operator $\mathcal{M}$ is Hermitian if

$$ \langle \Psi_1 | \mathcal{M} \Psi_2 \rangle = \langle \mathcal{M} \Psi_1 | \Psi_2 \rangle $$

for arbitrary operators $\Psi_1$ and $\Psi_2$.

Or, in other words,

$$ \int dx \Psi_1^{*}(x) \mathcal{M} \Psi_2(x) = \int dx (\mathcal{M} \Psi_1(x))^{*} \Psi_2(x), $$

where $\Psi_i(x)$ is a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Wave_function&#34;&gt;wave function&lt;/a&gt;.

&lt;/div&gt;

&lt;p&gt;For instance, consider a quantum circuit measured in the computational basis:&lt;/p&gt;

&lt;p&gt;$$ f_{\theta} = \langle 0 | U^{\dagger} \sigma_z U | 0 \rangle,$$&lt;/p&gt;

&lt;p&gt;where $U$ is a unitary operator that represents the quantum circuit,
$U^{\dagger}$ is the adjoint of $U$, and $\sigma_z$ is the Pauli-Z operator.
The expectation value of $f_{\theta}$ is
then between -1 and 1. -1 corresponds to the state $| 1 \rangle$, 1 corresponds
to the state $| 0 \rangle$, and 0 corresponds to the superposition state $(| 0
\rangle + | 1 \rangle) / \sqrt{2}$.&lt;/p&gt;

&lt;div class=&#34;alert alert-info&#34;&gt;
&lt;h4&gt;Expectation Values&lt;/h4&gt;

Given that $dx \left| \Psi(x) \right|^{2} = \Psi^{*}(x) \Psi(x) dx$
is the probability of finding the particle in the interval $[x, x + dx]$,
the expectation value of the position operator $\hat x$:

$$ \langle \hat x \rangle = \int x \Psi^{*}(x) \Psi(x) dx. $$

In general, for operator $\mathcal M$:

$$ \langle \mathcal M \rangle = \int dx \Psi^{*}(x) \mathcal M \Psi(x). $$

If operator $\mathcal M$ is Hermitian, then the expectation value

$$ \langle \mathcal M \rangle = \sum |\alpha_{i}|^2 q_i, $$

where $|\alpha_{i}|^2$ are the probabilities of measuring the eigenvalues $q_i$
of the operator $\mathcal M$.

For a more detailed explanation, see the
&lt;a href=&#34;https://www.youtube.com/watch?v=XQKV-hpsurs&amp;list=PLUl4u3cNGP60cspQn3N9dYRPiyVWDd80G&amp;index=38&#34;&gt;lectures&lt;/a&gt;
by Barton Zwiebach on the topic.

&lt;/div&gt;

&lt;h2 id=&#34;the-first-taste-of-quantum-machine-learning&#34;&gt;The First Taste of Quantum Machine Learning&lt;/h2&gt;

&lt;p&gt;Let us take a look at an example from &lt;a href=&#34;https://link.springer.com/book/10.1007/978-3-030-83098-4&#34;&gt;Schuld and Petruccione&lt;/a&gt; where
a parametrized quantum circuit computes a unitary transformation $U$:&lt;/p&gt;

&lt;p&gt;$$U =  \text{Rot}(\theta_1, \theta_2, \theta_3) R_x(x),$$&lt;/p&gt;

&lt;p&gt;where $R_x(x)$ is the rotation operator around the x-axis by an angle $x$, and
$\text{Rot}(\theta_1, \theta_2, \theta_3)$ is a general rotation operator.&lt;/p&gt;

&lt;p&gt;The circuit is schematized below:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;                                                             
    ┌────┐    ┌───────┐   ┌───────────────┐                  
    │|0&amp;gt; ├────│ Rx(x) ├───┤ Rot(θ1,θ2,θ3) ├──── Measurement  
    └────┘    └───────┘   └───────────────┘                  
                                                             &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Initially, the qubit is in the ground state $|0\rangle$.
Then, it is rotated around $X$ axis ($R_x(x)$ operator). And then rotated again.
This time, by a general qubit
rotation $\text{Rot}(\theta_1, \theta_2, \theta_3)$. Finally, we have the measurement operation.&lt;/p&gt;

&lt;div class=&#34;alert alert-info&#34;&gt;
&lt;h4&gt;Rotation Operators&lt;/h4&gt;

Commonly used operators that perform rotation
around $X$, $Y$, and $Z$ axes in the Bloch sphere:

\begin{aligned}
R_x(\phi) &amp;= \begin{pmatrix} \cos(\phi / 2) &amp; -i \sin(\phi / 2) \\\\ -i \sin(\phi / 2) &amp;  \cos(\phi / 2) \end{pmatrix}, \\\\
\end{aligned}

\begin{aligned}
R_y(\phi) &amp;= \begin{pmatrix} \cos(\phi / 2) &amp; -\sin(\phi / 2) \\\\ \sin(\phi / 2) &amp; \cos(\phi / 2) \end{pmatrix}, \\\\
\end{aligned}

\begin{aligned}
R_z(\phi) &amp;= \begin{pmatrix} e^{-i \phi / 2} &amp; 0 \\\\ 0 &amp; e^{i \phi / 2} \end{pmatrix}.
\end{aligned}

If you remember the Hadamard operator $H$ from this
&lt;a href=&#34;https://penkovsky.com/post/qc/&#34;&gt;post&lt;/a&gt;,
it is a special case of $R_y$ operator: $H = R_y(\pi / 2)$.

Feel free to derive the arbitrary qubit rotation operator
$\text{Rot}(\theta_1, \theta_2, \theta_3)$
as an exercise.
&lt;/div&gt;

&lt;p&gt;Therefore, the corresponding quantum model is mathematically described as:&lt;/p&gt;

&lt;p&gt;$$ f_{\theta}(x) = \langle 0 | R_x(x)^\dagger \text{Rot}(\theta_1, \theta_2, \theta_3)^\dagger \sigma_z \text{Rot}(\theta_1, \theta_2, \theta_3) R_x(x) | 0 \rangle.$$&lt;/p&gt;

&lt;p&gt;The variable $x$ is the input data point and $\theta$ are parameters
that we need to optimize such that $f_{\theta}(x)$ approximates
some &lt;em&gt;ground truth&lt;/em&gt; function
$\hat y$.
We don&#39;t know what $\hat y$ is, otherwise we would not need
&lt;em&gt;learning&lt;/em&gt; it. All we have, is a bunch of data points
and we want our model to reasonably represent them.&lt;/p&gt;

&lt;p&gt;Consider the table below:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;data point $x$&lt;/th&gt;
&lt;th&gt;$y$ value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;-0.8238&lt;/td&gt;
&lt;td&gt;-0.56&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;-0.3204&lt;/td&gt;
&lt;td&gt;-0.033&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;0.3083&lt;/td&gt;
&lt;td&gt;0.03&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We want to build a model on the interval $[-1, 1]$,
such that when we have a new value e.g. $x = 0.2$, we can predict
what $f(0.2)$ would be.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Challenge #1&lt;/strong&gt;: Ambiguity of the model. The model is not unique.&lt;/p&gt;

&lt;p&gt;Perhaps, we can approximate
the ground truth with $f(x) = x^3$. But we don&#39;t know that.
For example, $f_\theta(x) = \sin(5 x + \theta)$
where $\theta = \pi / 2$ would fit equally well!
Therefore, we have an ambiguity.
We could try to reduce the ambiguity by collecting more data points.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/fit1.png&#34; width=&#34;400px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Machine learning models are not unique. There exist an infinite number of ways to fit the data.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Let&#39;s imagine that now we have worked hard to collect more data:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;data point&lt;/th&gt;
&lt;th&gt;$y$ value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;-0.8238&lt;/td&gt;
&lt;td&gt;-0.56&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;-0.3204&lt;/td&gt;
&lt;td&gt;-0.033&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;-0.2&lt;/td&gt;
&lt;td&gt;-0.54&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;-0.2&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;0.3083&lt;/td&gt;
&lt;td&gt;0.03&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;-0.8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Challenge #2&lt;/strong&gt;: Noise in the data.&lt;/p&gt;

&lt;p&gt;Indeed,
the $f(x) = \sin(5 x + \pi / 2)$ model
would have perfectly fit the data points if not for the noise.
Note the value of $f(0) = -0.2$, whereas $\sin(\pi / 2) = 1$.
We realize that our data are probably corrupted by noise.
That is $y = \hat y + \epsilon$,
where $\epsilon$ is a random noise.
Therefore, it is very hard to tell whether $f(0) = -0.2$ is an
outlier or a genuine data point.&lt;/p&gt;

&lt;p&gt;One way to resolve the issue is to collect even more data points.
Which often might be very costly or even impossible.
Imagine that every data point is a result of a complex forty-step
chemical reaction. You can&#39;t just run the reaction
a thousand times to get more data points.&lt;/p&gt;

&lt;p&gt;Another way to resolve the issue is to ignore the outliers.
But this might lead to a biased model.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Challenge #3&lt;/strong&gt;: Overfitting.&lt;/p&gt;

&lt;p&gt;Finally, we can use a more complex model, so that
it can fit to the $f(0) = -0.2$ point.
On the other hand, a more complex model might capture the &lt;em&gt;noise&lt;/em&gt;
in the data, and not the &lt;em&gt;signal&lt;/em&gt;.
This would lead to what we call &lt;em&gt;overfitting&lt;/em&gt;.
That is, the model would perform well on the training data
but make poor predictions on new data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Challenge #4&lt;/strong&gt;: Verification.&lt;/p&gt;

&lt;p&gt;To resolve the issue, we may want to &lt;a href=&#34;https://en.wikipedia.org/wiki/Regularization_(mathematics)&#34;&gt;regularize&lt;/a&gt; or use a
simpler model.
But how do we actually know that the model makes good predictions?
We need to validate it on data unseen during training.
In practice this means that we
train the model on a part of the data and validate it on the
remaining part. This gives some approximation of how well
the model generalizes to new data.&lt;/p&gt;

&lt;h2 id=&#34;neural-networks-universal-function-approximators-and-quantum-models&#34;&gt;Neural Networks, Universal Function Approximators, and Quantum Models&lt;/h2&gt;

&lt;p&gt;The power of neural networks comes from their ability to approximate any
reasonable function. As we have seen in this
&lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;post&lt;/a&gt;, we need &lt;em&gt;nonlinear&lt;/em&gt;
transformations over subsequent layers for this to work. However, quantum
transformations are &lt;em&gt;linear&lt;/em&gt;.
So how can we approximate any function with a quantum model
if it is linear by nature? The good news is
that we do not need to mimic the exact behavior of neural networks.
&lt;a href=&#34;https://arxiv.org/abs/2008.08605&#34;&gt;Schuld et al.&lt;/a&gt; showed that quantum models can approximate any
square-integrable function, which is a broad class of functions. The basic idea
was to show that quantum models $f_{\mathbf{\theta}}$ parametrized by
$\mathbf{\theta}$ can be represented as a Fourier-type sum&lt;/p&gt;

&lt;p&gt;$$ f_{\mathbf{\theta}} = \sum_{\mathbf{\omega} \in \Omega} c_{\mathbf{\omega}}(\mathbf{\theta}) e^{i \mathbf{\omega x}}, $$&lt;/p&gt;

&lt;p&gt;where $\Omega$ is the frequency spectrum and $\mathbf{\omega x}$
is the inner product.
And the nonlinearity $e^{i \mathbf{\omega x}}$
comes from &lt;em&gt;encoding&lt;/em&gt; the classical data into the quantum states.
Note also that the functions $f_{\mathbf{\theta}}$ are
periodic. In practice that means that the inputs need to be rescaled to avoid
periodicity.&lt;/p&gt;

&lt;p&gt;Interestingly, the authors show that the frequency spectrum $\Omega$ is solely
determined by the eigenvalues of the data-encoding Hamiltonials, while the
design of the entire circuit (or &lt;em&gt;ansatz&lt;/em&gt;) controls the coefficients $c_{\omega}$.&lt;/p&gt;

&lt;p&gt;An intuitive connection can be established in the following figure:&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/mlp.jpg&#34; width=&#34;480px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Schuld and colleagues demonstrate the connection between neural networks and quantum models through Fourier formalism. The quantum circuit can be seen as a neural network with a single hidden layer.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Now you should be able to understand why talking about &amp;quot;deep quantum neural
networks&amp;quot; is at least misleading. Quantum models are not deep in the sense that
they have multiple layers of nonlinear transformations. However, they are
still universal function approximators in the sense that they can approximate
any square-integrable function with a Fourier-type sum.&lt;/p&gt;

&lt;h2 id=&#34;somewhat-detailed-example&#34;&gt;Somewhat Detailed Example&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;The associated code is on &lt;a href=&#34;https://gitlab.com/quadrant27/qml&#34;&gt;Gitlab&lt;/a&gt; if you want to follow along.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let us consider a simple example where
we want to perform the classification task
(as in the &amp;quot;cat/no cat&amp;quot; task, remember?).
The algorithm we are going to demonstrate belong to the class of
&lt;em&gt;variational quantum algorithms&lt;/em&gt;. It is called variational because we optimize
the parameters $\theta$ of the quantum model
by varying them. The goal of optimization is to
minimize a certain &lt;em&gt;loss&lt;/em&gt; function related to the task at hand.&lt;/p&gt;

&lt;p&gt;The loss (or cost) function we chose for this example is based on the &lt;em&gt;fidelity&lt;/em&gt;
between the quantum state that depends on the data input, and the target state
$\psi_{target}$, which is either $|0\rangle$ or $|1\rangle$.
You may think about the target state as if it were a label $0$ or $1$
in classical machine learning. Fidelity is a measure of how close two
quantum states are. The fidelity between states $|\psi\rangle$ and
$|\phi\rangle$ is defined as their inner product squared:&lt;/p&gt;

&lt;p&gt;$$ F(\psi, \phi) = |\langle \psi | \phi \rangle|^2. $$&lt;/p&gt;

&lt;p&gt;Fidelity represents the overlap or &amp;quot;closeness&amp;quot; between the two states.
Therefore, we want to maximize the fidelity when measuring $|0\rangle$ given
that the input data is a &amp;quot;no cat&amp;quot;. Likewise, we want to maximize the fidelity
when measuring $|1\rangle$ given that the input data is a &amp;quot;cat&amp;quot;,
whatever that means in the context of the dataset.&lt;/p&gt;

&lt;p&gt;The intuitive explanation of this particular
strategy is the following:
We want to find such parameters $\theta$ that after performing a
fixed number of rotations (proportional to &lt;code&gt;num_layers&lt;/code&gt; variable) on the input
data, the obtained vector on the Bloch sphere is close to the initial vector
(ground state $|0\rangle$) for the &amp;quot;no cat&amp;quot; class and far from the
initial vector for the &amp;quot;cat&amp;quot; class. That is, if it actually is a representative
of the &amp;quot;no cat&amp;quot; class, after all the rotations, the state vector should
come back close to the initial state $|0\rangle$. Whereas if it is a
representative of the &amp;quot;cat&amp;quot; class, the state vector should come
close to the state $|1\rangle$.&lt;/p&gt;

&lt;p&gt;We already explained that
the goal of machine learning is to find such a model that not only has a high
accuracy on the training data but also generalizes well to unseen data.
Therefore, we need at least two datasets: one for training and one for
validation.&lt;/p&gt;

&lt;p&gt;As a benchmark, we will use the two spirals dataset from this
&lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;post&lt;/a&gt;. The dataset consists of two
spirals that are intertwined. The goal is to classify the points into two
classes (orange and blue). Imagine that blue points are cats
in some low-dimensional space, if you like.
It does not change the essence of the task.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/two-spirals.png&#34; width=&#34;400px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Two spirals dataset.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;To get you motivated, the figure below illustrates what we are going to
achieve with a quantum model.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/two-spirals-optimized.png&#34; width=&#34;700px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Classification before and after training. Having only 75 parameters, the model achieves perfect classification on both training and validation datasets.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;There are several meta-parameters (or &lt;em&gt;hyperparameters&lt;/em&gt;)
that might impact the performance of the
model. Therefore, we might need to tune them to get reasonably good results.
Andrew Ng recommends using random sampling. This helps to deal
with the &lt;a href=&#34;https://en.wikipedia.org/wiki/Curse_of_dimensionality&#34;&gt;curse of dimensionality&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here is a randomly generated plan of experiments for the three hyperparameters:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;#&lt;/th&gt;
&lt;th&gt;num_layers&lt;/th&gt;
&lt;th&gt;learning_rate&lt;/th&gt;
&lt;th&gt;batch_size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;0.0497&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;0.0147&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;0.0663&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;0.0047&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;0.0053&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;0.0177&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;0.0075&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;0.0889&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;0.0135&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;0.0398&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;29&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.0472&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;0.0274&lt;/td&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now we will train several models (we chose 30 as a reasonable number)
for a small number or epochs (see below) to select
candidates with the best performance (validation accuracy in this case).
Note, that for a more reliable result, one should average the accuracies
over several runs with the same &lt;em&gt;hyperparameters&lt;/em&gt; but different initial
&lt;em&gt;model parameters&lt;/em&gt; $\theta$.&lt;/p&gt;

&lt;p&gt;Having a luxury of simulating the quantum model on a classical computer, we can
employ the gradient descent together with the
&lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;Adam optimizer&lt;/a&gt; to learn the
model parameters. On a real quantum computer, we would need to use something like
the &lt;a href=&#34;https://arxiv.org/abs/1909.02108&#34;&gt;Quantum Natural Gradient&lt;/a&gt; or
&lt;a href=&#34;https://pennylane.ai/qml/glossary/parameter_shift/&#34;&gt;parameter shift rule&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The goal is to minimize the average loss over the training dataset. Our square
of difference loss is minimized when the fidelity maximized (i.e. close to 1).&lt;/p&gt;

&lt;p&gt;$$ \text{loss} = \frac{1}{N} \sum_{i=1}^{N} \left(1 - F(\psi_{\theta}(x_i), \psi_{target}) \right)^2, $$&lt;/p&gt;

&lt;p&gt;where $\psi_{\theta}$ comes from the circuit, $x_i$ is the input data point,
and $N$ is the number of data points in the training set.
Finally, here is the circuit itself:&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://pennylane.ai/_images/universal_layers.png&#34; alt=&#34;Credit: [pennylane.ai](https://pennylane.ai/qml/demos/tutorial_data_reuploading_classifier/).&#34; width=&#34;550px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The variational circuit scheme to learn the spirals dataset.&lt;/h4&gt;
  &lt;p&gt;
    Credit: &lt;a href=&#34;https://pennylane.ai/qml/demos/tutorial_data_reuploading_classifier/&#34;&gt;pennylane.ai&lt;/a&gt;.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;In our version, we perform a number of repetitions (&lt;code&gt;num_layers&lt;/code&gt;) of two operators:
$u(x)$ and $u(\theta)$. The operator
$u(x) := \text{Rot}(x_1 \theta_1, x_2 \theta_2, 0)$ is parametrized by the input
data vector $x := (x_1, x_2)$ and two angles $\theta_{i_1}$ and $\theta_{i_2}$.
While the operator $u(\theta) := \text{Rot}(\theta_3, \theta_4, \theta_5)$ is
only parametrized by the angles $\theta_{i_3}$,
$\theta_{i_4}$, and $\theta_{i_5}$.&lt;/p&gt;

&lt;p&gt;We train models by adapting parameters $\theta_{i=1..\text{num_layers}}$
with gradient descent and the Adam optimizer.
During the parameter search, we train the models on 200 train data samples for 10
epochs each. This is motivated by the need to &lt;strong&gt;reduce the amount of
computation&lt;/strong&gt; during the hyperparameter search.
After training all 30 models, we analyze the results
by sorting the models by the validation accuracy.
The first model resulted in the validation accuracy of 0.8575 after
10 epochs of training. The second model results in the validation accuracy of only 0.7375.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;  accuracy_train  accuracy_val  num_layers  learning_rate  epochs  batch_size
        0.870        0.8575          12         0.0497      10          16
        0.775        0.7375          15         0.0633      10          32
        0.735        0.7100          12         0.0398      10          16
        0.665        0.6450          15         0.0276      10          16
        0.595        0.6050          10         0.0472      10          64&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note that the best model might be different from run to run due to the random
initialization of the model parameters. Therefore, it is a good practice to
average the results over several runs with the same hyperparameters.&lt;/p&gt;

&lt;p&gt;Then we can train our final models on more training data samples (if available)
and for more epochs.
In our case, it was 30 epochs on 400 data samples.
Validation was done on another 400 data samples, not seen during training.
What a good luck to use a synthetic dataset!&lt;/p&gt;

&lt;p&gt;I tried the two top configurations from the list above,
and the best ultimate result was achieved with the second best configuration
(&lt;code&gt;num_layers = 15, learning_rate = 0.0633, batch_size = 32&lt;/code&gt;).
Of course, the results might vary from run to run due to the random initialization
of the model parameters, which is something to keep in mind.&lt;/p&gt;

&lt;p&gt;Here are the optimized parameters $\theta$ for the
architecture with &lt;code&gt;num_layers = 15&lt;/code&gt; repetitions achieving perfect
prediction accuracy on both training and validation datasets.
Those are only $15 \cdot 5 = 75$ model parameters, therefore,
I can conveniently print them below.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;[[ 0.29827245,  0.08220332,  1.42578576,  0.50208184, 1.5928177 ],
 [ 0.05869113,  0.26620008,  1.12377337,  0.46328539, 1.70133469],
 [ 1.18456692, -0.45356308,  0.74022415,  0.21701071, -0.29728818],
 [-0.73229329,  0.90770549,  0.36220917,  0.91383889, 0.04663861],
 [-0.54919759,  0.96878071,  1.39345259,  1.35545392, 0.38011819],
 [ 0.2557679 , -0.32282553,  0.57328026,  1.60893581, 1.21153585],
 [ 1.14139141,  1.09135017,  0.6102359 , -0.55232082, -0.47481543],
 [ 1.36793678,  1.19127662,  0.67343336,  0.34314725, -0.0578214 ],
 [ 1.47484026,  1.01214414,  0.76562758, -0.2116039 , 0.83520595],
 [ 0.47545624, -0.37081129,  0.96669664,  0.05487279, 0.24774081],
 [ 1.48150396, -1.89516311, -0.15641872, -0.09757299, 0.04472809],
 [ 1.76554667, -2.2032729 ,  0.34249646,  0.05324532, 0.62406002],
 [ 1.05227216, -0.94414955,  0.67808506,  0.91553152, 1.03300285],
 [ 0.60005659,  1.34494046, -0.31970111,  0.28673467, 1.3734422 ],
 [ 1.57574681,  0.40458179, -1.87592608, -0.88068899, 0.23475442]]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Compare with 513, 1416, or 2049 parameters in the
&lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;classical neural networks&lt;/a&gt;
that achieve the same or inferior accuracy on validation data.&lt;/p&gt;

&lt;p&gt;Now we can visualize the learned decision boundary:&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/two-spirals-decision-boundary.png&#34; width=&#34;450px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Learned decision boundary.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Even more interesting is to check the fidelity of measuring one of the two
states.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/spirals-fidelity-1.png&#34; width=&#34;450px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Fidelity of measuring $|1\rangle$.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;I would suggest that the model captures the essence of the dataset
quite well.&lt;/p&gt;

&lt;h2 id=&#34;testing-on-ibm-quantum&#34;&gt;Testing on IBM Quantum&lt;/h2&gt;

&lt;p&gt;This all is nice, but is probably worth not much if it does not work on a real
quantum machine. To confirm our results,
I ran a pretrained model on the IBM Brisbane quantum computer.
The characteristics of the QPU (quantum processing unit)
are shown below.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/ibm_brisbane_details.png&#34; width=&#34;650px&#34; /&gt;


&lt;/figure&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/ibm_brisbane.png&#34; width=&#34;650px&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;It is a 127-qubit Eagle type quantum processor. The native gates can be found
&lt;a href=&#34;https://docs.quantum.ibm.com/guides/native-gates#eagle&#34;&gt;here&lt;/a&gt;.
As you can see, there are no universal rotations available.
Therefore, during &lt;a href=&#34;https://penkovsky.com/post/qc/#transpilation&#34;&gt;transpilation&lt;/a&gt;, the
gates are decomposed into the native gates.
That is, the universal rotations will be represented in terms
of $R_z$ (&lt;a href=&#34;https://docs.quantum.ibm.com/api/qiskit/qiskit.circuit.library.RZGate&#34;&gt;RZ&lt;/a&gt;) and $\sqrt X$ (&lt;a href=&#34;https://docs.quantum.ibm.com/api/qiskit/qiskit.circuit.library.SXGate&#34;&gt;SX&lt;/a&gt;) gates.&lt;/p&gt;

&lt;p&gt;For the sake of test, I have validated the model on the first 20 data points
unseen during training.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/spirals_val.png&#34; width=&#34;450px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Data points tested on a real quantum computer.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Below are a few example circuits that were run on the IBM quantum computer. You
can easily verify that the first two have a high fidelity of measuring $|0\rangle$,
while the last two have a high fidelity of measuring $|1\rangle$.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/isa_circuits0-1.png&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Circuits representing the $|0\rangle$ target.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qml/isa_circuits10-11.png&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Circuits representing the $|1\rangle$ target.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;You might be surprised first that the circuits are so simple. However, there is nothing
wrong with that. To run a circuit, we have to provide all the parameters $\theta$ and $x$.
During the &lt;a href=&#34;https://penkovsky.com/post/qc/#transpilation&#34;&gt;transpilation&lt;/a&gt; process,
therefore, the circuit is simplified. And instead of 30 rotations, we have only
one. This single rotation is then represented in terms of the native gates
$R_z$ and $\sqrt X$.
Note also that we can only run a single circuit at a time.&lt;/p&gt;

&lt;p&gt;Using 1024 shots per data point, the workload
consumed 7.6 seconds of the QPU time.
Below are the results summarized in a form of table.
Those are the probabilities of measuring the states $|0\rangle$
and $|1\rangle$ for the 20 data points.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;#&lt;/th&gt;
&lt;th&gt;Proba  0&lt;/th&gt;
&lt;th&gt;Proba  1&lt;/th&gt;
&lt;th&gt;$\hat y$ Label&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.91&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.09&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.93&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.07&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.83&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.17&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.84&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.16&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.86&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.14&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.83&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.17&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.92&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.08&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.74&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.26&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.88&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.12&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.91&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;0.09&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;0.03&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.97&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;0.06&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.94&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;0.03&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.97&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;0.04&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.96&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;0.02&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.98&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;0.09&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.91&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;0.02&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.98&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;0.07&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.93&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;0.04&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.96&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;0.02&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;0.98&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that the model performs well on the unseen data points,
despite the noise in the NISQ device. This is not surprising
since (1) the theoretical fidelities were close to 1, and (2) the model
was simplified to only five native gates during the transpilation process.
Less gates mean less noise.
To reproduce my experiments on a quantum computer,
you can run this &lt;a href=&#34;https://gitlab.com/quadrant27/qml/blob/master/spirals-ibm.ipynb&#34;&gt;notebook&lt;/a&gt; (IBM account required).&lt;/p&gt;

&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;

&lt;p&gt;The article would be not complete without mentioning the limitations of quantum
computing in general and quantum machine learning in particular.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The most important limitation is that currently available NISQ devices are &lt;em&gt;noisy&lt;/em&gt;
and have &lt;em&gt;limited qubit count&lt;/em&gt;. This means that we can&#39;t just run different
quantum algorithms and see what works best. In contrast to
graphical processing units availability,
which arguably led to success in deep learning.&lt;/li&gt;
&lt;li&gt;Cryogenic cooling is required. So you can&#39;t just put a quantum computer on your desk.&lt;/li&gt;
&lt;li&gt;Quantum machine learning is in its infancy. Therefore, there are not many
real-life problems solved with quantum machine learning that cannot be
efficiently solved with classical machine learning.&lt;/li&gt;
&lt;li&gt;Quantum algorithms are &lt;em&gt;not always&lt;/em&gt; faster than classical algorithms.&lt;/li&gt;
&lt;li&gt;Classical machine learning proved to be incredibly successful to solve
real life problems. On the other hand, in today&#39;s quantum computing, problems
are &lt;a href=&#34;https://arxiv.org/abs/2203.01340&#34;&gt;carefully selected&lt;/a&gt; to be provably difficult for classical computers.&lt;/li&gt;
&lt;li&gt;Today&#39;s quantum computers are typically applied to &lt;a href=&#34;https://arxiv.org/abs/2203.01340&#34;&gt;well-structured&lt;/a&gt; problems.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This post illustrates that even single-qubit quantum models can approximate
highly non-linear functions. And this is despite the linear nature of quantum
transformations. This is possible thanks to the encoding of classical data into
quantum states. The repetition of quantum transformations over the input data
increases the frequency spectrum of the quantum model, and therefore its
expressive power. The quantum universal approximation theorem states that
quantum models can approximate any square-integrable function.
Much like in classical neural networks, the universal approximation theorem
does neither provide a recipe how to construct a quantum circuit with sufficient
expressive power, nor how to obtain the parameters to approximate a given
function.&lt;/p&gt;

&lt;p&gt;There are several opportunities to explore in quantum machine learning. One of
them is quantum machine learning with quantum data.
Another one is encoding classical datasets into superposition states.
To exploit, therefore, quantum parallelism and interference, which might be
beneficial for certain tasks.
Finally, the
benefits of entanglement in quantum machine learning are yet to be demonstrated.
The main challenge is to find quantum models that can outperform classical
models on real-world datasets. This is especially true in the NISQ era, where
the number of qubits is limited and the noise is high.&lt;/p&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;pre&gt;
@article{penkovsky2024qml,
 title   = &#34;Gentle Introduction to Quantum Machine Learning&#34;,
 author  = &#34;Penkovsky, Bogdan&#34;,
 journal = &#34;penkovsky.com&#34;,
 year    = &#34;2024&#34;,
 month   = &#34;August&#34;,
 url     = &#34;https://penkovsky.com/post/qml/&#34;
}
&lt;/pre&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.01340&#34;&gt;Is quantum advantage the right goal for quantum machine learning?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2008.08605&#34;&gt;Effect of data encoding on the expressive power of variational quantum-machine-learning models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://link.springer.com/book/10.1007/978-3-030-83098-4&#34;&gt;Machine Learning with Quantum Computers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=XQKV-hpsurs&amp;amp;list=PLUl4u3cNGP60cspQn3N9dYRPiyVWDd80G&amp;amp;index=38&#34;&gt;Expectation values of operators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pennylane.ai/qml/demos/tutorial_data_reuploading_classifier/&#34;&gt;Data re-uploading classifier&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-expval&#34;&gt;The expectation value (marked by the angle brackets) of an operator is the average value of the observable in a given quantum state: $\langle \mathcal{M} \rangle = \langle \psi | \mathcal{M} | \psi \rangle,$ where $| \psi \rangle$ is the quantum state. In practice, you will need to measure a large number of copies of the quantum state and average the results to get the expectation value.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-expval&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Quantum Computing for Hackers</title>
      <link>https://penkovsky.com/post/qc/</link>
      <pubDate>Sat, 13 Apr 2024 15:55:03 +0200</pubDate>
      
      <guid>https://penkovsky.com/post/qc/</guid>
      <description>&lt;p&gt;When I first learned about quantum computing, I thought it will be a long time
before we actually see a quantum computer. Later, in 2019, I attended a
brilliant talk by Alain Aspect who is known for his
&lt;a href=&#34;https://en.wikipedia.org/wiki/Bell_test&#34;&gt;experiments&lt;/a&gt; on Bell&#39;s theorem.
The very same year, Google &lt;a href=&#34;https://www.nature.com/articles/s41586-019-1666-5&#34;&gt;claimed&lt;/a&gt;
to have achieved quantum supremacy. These events made me realize that quantum
computing is not just a theoretical concept. The idea that
sparked my interest. I wanted to understand how is it even possible
that the result does not exist until we measure it.&lt;/p&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Edit 14/04/2024:&lt;/strong&gt; Added results running the quantum OR circuit on a real quantum computer.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit 20/09/2024:&lt;/strong&gt; Comparison table between classical and quantum computing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit 14/10/2024:&lt;/strong&gt; An explanation of how measurement is related to the (absence of) quantum effects.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;In this article, we explain quantum computing with a minimal number of lines of
code. To know how quantum computing works, you don&#39;t always need a quantum
computer. We will simulate a beam splitter, a basic quantum circuit. We will
also show how to express digital circuits with quantum gates. Moreover, we will
run a quantum OR circuit on a real quantum computer and compare the results with
the theoretical ones. Finally, we will get a rough idea how quantum circuits are
compiled and executed on physical quantum hardware.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The post is aimed at people with an engineering
mindset. Some familiarity with linear algebra is
advised. Also please let
me know how this piece can be improved.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;quantum-computing-faq&#34;&gt;Quantum Computing FAQ&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Will I be able to play [your favorite video game here] on a quantum computer?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; No&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Will I be able to play Doom at least?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; No. See &lt;a href=&#34;#expressing-digital-circuits-with-quantum-gates&#34;&gt;Expressing Digital Circuits with Quantum
Gates&lt;/a&gt; section.&lt;/p&gt;

&lt;p&gt;TLDR; Even though any digital circuit &lt;em&gt;can be&lt;/em&gt; expressed in terms of quantum
circuits, there would be a &lt;strong&gt;huge&lt;/strong&gt; overhead. Also you would need a cryostat and
other expensive equipment to prepare quantum states. Making it a prohibitively
expensive quantum computer to only simulate a classical one. This is not to
mention that we live in the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Noisy_intermediate-scale_quantum_era&#34;&gt;NISQ era&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Below is a comparison table between classical and quantum computing:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Classical computing&lt;/th&gt;
&lt;th&gt;Quantum computing&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Units of information&lt;/td&gt;
&lt;td&gt;Bits ($1$ or $0$)&lt;/td&gt;
&lt;td&gt;Qubits (simultaneously containing $1$ &lt;strong&gt;and&lt;/strong&gt; $0$)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Data representation&lt;/td&gt;
&lt;td&gt;Binary format&lt;/td&gt;
&lt;td&gt;Superposition (multiple states at once)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Distinctive features&lt;/td&gt;
&lt;td&gt;Easy to copy information&lt;/td&gt;
&lt;td&gt;Entanglement (correlations)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nature of computation&lt;/td&gt;
&lt;td&gt;Inherently sequential&lt;/td&gt;
&lt;td&gt;Quantum parallelism&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Irreversible&lt;/td&gt;
&lt;td&gt;Reversible (information preservation)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hardware&lt;/td&gt;
&lt;td&gt;Transistors&lt;/td&gt;
&lt;td&gt;Superconducting qubits, trapped ions, photons&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Error correction&lt;/td&gt;
&lt;td&gt;Well established&lt;/td&gt;
&lt;td&gt;Complex; Work in progress&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Major challenges&lt;/td&gt;
&lt;td&gt;von Neumann bottleneck, &lt;a href=&#34;https://en.wikipedia.org/wiki/Amdahl%27s_law&#34;&gt;Amdahl&#39;s law&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;No exact cloning, noise, qubit coherence time&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Universality&lt;/td&gt;
&lt;td&gt;Universal&lt;/td&gt;
&lt;td&gt;Problem-specific (see FAQ above)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nature of computation&lt;/td&gt;
&lt;td&gt;Inherently sequential&lt;/td&gt;
&lt;td&gt;Quantum parallelism&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Output&lt;/td&gt;
&lt;td&gt;Deterministic&lt;/td&gt;
&lt;td&gt;Probabilistic&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nature of computation&lt;/td&gt;
&lt;td&gt;Inherently sequential&lt;/td&gt;
&lt;td&gt;Quantum parallelism&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Practical limitations&lt;/td&gt;
&lt;td&gt;Huge datasets; NP-hard problems&lt;/td&gt;
&lt;td&gt;Largely experimental&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Algorithm examples&lt;/td&gt;
&lt;td&gt;Sorting, dynamic programming&lt;/td&gt;
&lt;td&gt;Shor&#39;s algorithm, Grover&#39;s algorithm&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Magic&lt;/td&gt;
&lt;td&gt;Does not exist&lt;/td&gt;
&lt;td&gt;Does not exist&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Hopefully, this article will clarify some of the points in the table above.&lt;/p&gt;

&lt;h2 id=&#34;qubits&#34;&gt;Qubits&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Nature does not know what you are looking at, and she behaves
the way she is going to behave whether you bother to take down the data or not.
(Richard Feynman)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A qubit is a basic unit of quantum information.
Unlike classical bits that can be either zero or one,
qubits can be in a superposition of states&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-superpos&#34;&gt;&lt;a href=&#34;#fn:fn-superpos&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.
Instead of being just &amp;quot;up&amp;quot; ($|0\rangle$) or &amp;quot;down&amp;quot;, ($|1\rangle$),
a qubit can be in a state 40% up and 60% down.
Or more generally, a qubit can be in a state
$|\psi\rangle = \alpha |0\rangle + \beta |1\rangle$,
where $\alpha$ and $\beta$ are complex numbers. The probability to measure
a qubit in the state $|0\rangle$ is $|\alpha|^2$ and the probability to measure
a qubit in the state $|1\rangle$ is $|\beta|^2$.
A single qubit can be conveniently visualized using the &lt;em&gt;Bloch sphere&lt;/em&gt;.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/Bloch_sphere.png&#34; width=&#34;300px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Block sphere representing a single qubit.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;When we perform &lt;em&gt;any&lt;/em&gt; measurement, a quantum state collapses.
Qubits become classical bits. And therefore the information
about a quantum state is lost during the measurement&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-meas&#34;&gt;&lt;a href=&#34;#fn:fn-meas&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.
There is nothing we can do about that.
A QHack meme well summarizes the situation.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/qmeme.png&#34; width=&#34;350px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;QHack 2024 meme: A qubit collapses when you look at it.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;div class=&#34;alert alert-info&#34;&gt;
&lt;h4&gt;How Measurement is Related to the Final State&lt;/h4&gt;
My current understanding how this works is the following. In order to observe
quantum effects, there should be a certain symmetry, which manifests itself in a
number of &lt;em&gt;indistinguishable&lt;/em&gt; ways that a quantum object can take. If we are
talking about a photon, this can be a number of paths that a photon can take in
a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Double-slit_experiment&#34;&gt;double-slit experiment&lt;/a&gt;.
Once this symmetry is broken, the quantum effects disappear. The measurement
itself is &lt;em&gt;not&lt;/em&gt; a cause of the wave function collapse. It is the symmetry breaking
that is responsible for the absence of quantum effects. Meaning that
the quantum effects are not destroyed by the measurement. Instead, the
&lt;em&gt;ability&lt;/em&gt; to measure anything implies that there must be a certain
distinction between the final or &#34;measured&#34; states
(the result of the absence of symmetry).
This reasoning explains why registering the path of a photon in a double-slit
experiment destroys the interference pattern.
&lt;br&gt;&lt;br&gt;
An alternative explanation is that the measurement itself acts as an
operator that collapses the wave function. I am less convinced by this
explanation. Instead, I would suggest that for you to be able to &#34;look&#34; at a qubit,
the quantum state &lt;em&gt;must&lt;/em&gt; collapse, independently of whether you actually look at it or not.
As Feynman famously said, &#34;Nature does not know what you are looking at, and she behaves
the way she is going to behave whether you bother to take down the data or not.&#34;
&lt;/div&gt;

&lt;h2 id=&#34;minimal-quantum-computing-example-modeling-a-beam-splitter&#34;&gt;Minimal Quantum Computing Example: Modeling a Beam Splitter&lt;/h2&gt;

&lt;p&gt;Here we will create a minimal demonstration of quantum computing.
This demonstration will contain all the stages used in quantum computing.
Which software framework shall we choose? One option is &lt;a href=&#34;https://pennylane.ai/&#34;&gt;Pennylane&lt;/a&gt;. It is
a well-documented software framework. There are plenty of other options, such as
&lt;a href=&#34;https://qiskit.org/&#34;&gt;Qiskit&lt;/a&gt; or &lt;a href=&#34;https://perceval.quandela.net/&#34;&gt;Perceval&lt;/a&gt;. The last one is actually simulating
photonic circuits, which is neat. However, we want to show that there is no magic
involved, so we will use good old Python with Numpy.&lt;/p&gt;

&lt;p&gt;What we are going to do is to simulate an (idealized) beam splitter.
This optical device will implement what we call a &lt;em&gt;Hadamard gate&lt;/em&gt;.
How does a beam splitter work? In classical optics, you send a light beam
with a certain intensity $I$ and it get&#39;s split into two beams of equal
light intensity $\frac 1 2 I$. Beam splitters are typically implemented
by semi-transparent mirrors that let only half of light through, while
reflecting the other half.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/bs.png&#34; width=&#34;300px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Optical beam splitter contains a semi-transparent mirror that lets through some of the light. &lt;a href=&#34;https://physics.stackexchange.com/questions/39577/beam-splitters-direction-of-use&#34;&gt;Credit&lt;/a&gt;&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;That&#39;s great! But what happens in the quantum case? In the quantum case, we
want to deal with individual photons, which are quantum objects&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-quanta&#34;&gt;&lt;a href=&#34;#fn:fn-quanta&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.
As it turns out, things start to work in a strange way on the quantum level.
When we send a single photon through a beam splitter, it &amp;quot;decides&amp;quot; which
way to send the photon in a probabilistic manner! When we have a semi-transparent window
with a 50% reflectivity (a balanced beam-splitter), this means that a photon
will be reflected with a 50% chance.
For more insight, see &lt;a href=&#34;https://en.wikipedia.org/wiki/QED:_The_Strange_Theory_of_Light_and_Matter&#34;&gt;QED&lt;/a&gt; by Richard Feynman.&lt;/p&gt;

&lt;p&gt;So here is a rough sketch how we model a beam splitter:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We send a photon (encoding our qubit).&lt;/li&gt;
&lt;li&gt;We apply a transformation by the beam splitter.&lt;/li&gt;
&lt;li&gt;We obtain a theoretical probability distribution.&lt;/li&gt;
&lt;li&gt;We simulate &amp;quot;measurements&amp;quot;, which way the photon has gone as if we placed a photodetector on each of the two paths.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Congratulations, we know how to simulate quantum computing!
Now, more details. First, we prepare a qubit.
By convention, $|0\rangle = [1, 0]^T$ and $|1\rangle = [0, 1]^T$.
We deal with vectors of two complex numbers.
In the language of quantum computing $|0\rangle$ means &amp;quot;the probability to
measure a photon on the first photodetector is 100% and zero on the second
one&amp;quot;. And as you have figured it out already,
$|1\rangle$ is simply &amp;quot;a 100% chance to measure a photon on the second
photodetector and zero on the first one&amp;quot;. More generally, we use
a Greek letter $\psi$ to denote any quantum state $|\psi\rangle$.
Don&#39;t be afraid of this &amp;quot;quantum physics&amp;quot; notation, it simply means vectors,
squared sum of which is equal to one. That&#39;s it!&lt;/p&gt;

&lt;div class=&#34;alert alert-info&#34;&gt;
&lt;h4&gt;Remark&lt;/h4&gt;
In classical world, &lt;em&gt;amplitudes&lt;/em&gt; are associated with the energy. That is, the
energy transported by a wave is proportional to the square of its amplitude.
For instance, the amplitude of sound waves is related to the intensity of the
sound.
However, the wave amplitude of a quantum mechanical wave does not describe any
real quantity. Quantum mechanical amplitudes are associated with the probability
of observing a particular state (e.g. finding a photon in a certain location).
See also
&lt;a href=&#34;https://ee.stanford.edu/~dabm/QMbook.html&#34;&gt;Quantum Mechanics for Scientists and Engineers&lt;/a&gt;
by David A. B. Miller.
&lt;br&gt;&lt;br&gt;
The probability $P$
is given by the &lt;b&gt;the absolute value squared of the amplitude&lt;/b&gt;:
$P = |\psi|^2$.
For instance, let&#39;s take a quantum state
$|\psi\rangle = |+\rangle := \frac 1 {\sqrt 2} [1, 1]^T$.
Then, the probability distribution
P = $|\frac 1 {\sqrt 2} [1, 1]^T|^2 = \frac 1 2 [1^2, 1^2]^T = [0.5, 0.5]^T$.
That is, we have a 50% change to detect a photon
on either photodetector.
&lt;/div&gt;

&lt;p&gt;Second, we have to model a beam splitter. The beam splitter with 50%
reflectivity is given by the following linear operator:&lt;/p&gt;

&lt;p&gt;$$
H = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 &amp;amp; 1 \\ 1 &amp;amp; -1 \end{pmatrix}.
$$&lt;/p&gt;

&lt;p&gt;Note that these operators are supposed to play nicely with the amplitudes
so that in the end of the experiment all the probabilities sum to one
(conservation of probability)!
Therefore, the only valid operators are
&lt;a href=&#34;https://en.wikipedia.org/wiki/Unitary_transformation&#34;&gt;unitary transformations&lt;/a&gt;
preserving vector length. In other words, the operators are only allowed to
rotate the amplitudes vector.&lt;/p&gt;

&lt;p&gt;Third, to get a probability distribution, we apply unitary operators
to our qubits. Suppose, we send a photon such that we
would measure it on the first photodetector if there was no beam splitter.
That is, we prepare $|0\rangle$.
Then, we apply the $H$ operator:&lt;/p&gt;

&lt;p&gt;$$
H |0\rangle =
  \frac{1}{\sqrt{2}} \begin{pmatrix} 1 &amp;amp; 1 \\ 1 &amp;amp; -1 \end{pmatrix} \begin{pmatrix} 1  \\ 0 \end{pmatrix} =
  \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ 1 \end{pmatrix}.
$$&lt;/p&gt;

&lt;p&gt;Now, we obtain a probability distribution by squaring the amplitude vector.
From the remark above, it is $[0.5, 0.5]^T$.&lt;/p&gt;

&lt;p&gt;Fourth, we simulate measurements by drawing samples from that distribution.
Here is a Python code for the beam splitter modeling.
Once you understand it, everything else in quantum computing is just a
matter of scaling up the number of qubits and applying more gates.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prepare_state&lt;/span&gt;():
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Prepare a qubit in the |0&amp;gt; state
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bs&lt;/span&gt;(state):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Simulate a beam splitter&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    Hadamard &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(Hadamard, state)


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;measure_state&lt;/span&gt;(state, n):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Measure a quantum state n times.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],
        n,
        &lt;span style=&#34;color:#75715e&#34;&gt;# Convert the amplitudes to probabilities&lt;/span&gt;
        p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(state[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(state[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;],
    )


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;():
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;A minimal quantum computing example.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# A qubit in the |0&amp;gt; state&lt;/span&gt;
    state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; prepare_state()
    &lt;span style=&#34;color:#75715e&#34;&gt;# Simulate a beam splitter&lt;/span&gt;
    state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bs(state)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Measure the state&lt;/span&gt;
    n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;
    results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; measure_state(state, n)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Measured {results.sum()} ones out of {n} measurements&amp;#34;&lt;/span&gt;)


&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:
    main()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I run this program several times. Here is what I&#39;ve got&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Measured 493 ones out of 1000 measurements
Measured 476 ones out of 1000 measurements
Measured 504 ones out of 1000 measurements
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you have suspected, quantum computing is probabilistic.&lt;/p&gt;

&lt;h2 id=&#34;expressing-digital-circuits-with-quantum-gates&#34;&gt;Expressing Digital Circuits with Quantum Gates&lt;/h2&gt;

&lt;p&gt;Any combinatorial digital circuit can be simulated with quantum circuits (with
an overhead).&lt;/p&gt;

&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;

&lt;p&gt;Here we briefly introduce Pauli gates, Toffoli gate,
and Kronecker product.
The &lt;a href=&#34;https://en.wikipedia.org/wiki/Pauli_matrices&#34;&gt;Pauli gates&lt;/a&gt; are the following:&lt;/p&gt;

&lt;p&gt;$$
\begin{aligned}
X &amp;amp;= \begin{pmatrix} 0 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{pmatrix}, \&lt;br /&gt;
Y &amp;amp;= \begin{pmatrix} 0 &amp;amp; -i \\ i &amp;amp; 0 \end{pmatrix}, \&lt;br /&gt;
Z &amp;amp;= \begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; -1 \end{pmatrix}.
\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;The Pauli $X$ gate is often denoted by symbol $\oplus$. This gate is the quantum
analogue of the classical NOT gate. It flips the state of a qubit.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Toffoli_gate&#34;&gt;Toffoli gate&lt;/a&gt; is a three-qubit gate that flips the third qubit if the first
two qubits are in the state $|1\rangle$. The Toffoli gate is
given by the following matrix:&lt;/p&gt;

&lt;p&gt;$$
\begin{pmatrix}
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix}.
$$&lt;/p&gt;

&lt;p&gt;Some readers may notice that I skipped the &lt;a href=&#34;https://en.wikipedia.org/wiki/Controlled_NOT_gate&#34;&gt;controlled NOT&lt;/a&gt; (CNOT) gate.
The CNOT gate is applied to two qubits and flips the second qubit if the first
qubit is in the state $|1\rangle$. The CNOT gate is a quantum analogue of the
classical XOR gate. Try to infer the CNOT gate matrix by looking at the Toffoli
gate matrix above.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Kronecker_product&#34;&gt;Kronecker product&lt;/a&gt; of two matrices $A$ and $B$&lt;/p&gt;

&lt;p&gt;$$
{A}\otimes{B} = \begin{pmatrix}
  a_{11} {B} &amp;amp; \cdots &amp;amp; a_{1n}{B} \\ \vdots &amp;amp; \ddots &amp;amp;
  \vdots \\ a_{m1} {B} &amp;amp; \cdots &amp;amp; a_{mn} {B}
\end{pmatrix},
$$&lt;/p&gt;

&lt;p&gt;where $a_{ij}$ are the elements of the matrix $A$ and $B$ is the matrix to be
repeated.
The Kronecker product is useful when we want to apply a single-qubit gate to
multiple qubits. For instance, the Pauli $X$ gate applied to the first of
two qubits is given by&lt;/p&gt;

&lt;p&gt;$$
X \otimes I =
\begin{pmatrix}
0 &amp;amp; 1 \\ 1 &amp;amp; 0
\end{pmatrix} \otimes
\begin{pmatrix}
1 &amp;amp; 0 \\ 0 &amp;amp; 1
\end{pmatrix} =
\begin{pmatrix}
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\ 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0
\end{pmatrix}.
$$&lt;/p&gt;

&lt;p&gt;As we will see in the next section, multiple qubits are represented like musical notes.
Only instead of notes, &amp;quot;wires&amp;quot; represent qubits and the gates are applied to them.
One reads this notation from left to right.&lt;/p&gt;

&lt;h3 id=&#34;quantum-or-circuit&#34;&gt;Quantum OR Circuit&lt;/h3&gt;

&lt;p&gt;Let&#39;s take &lt;strong&gt;OR&lt;/strong&gt; digital gate as an example. The same method can be applied to
emulate any digital gate. Below is an illustration of the classical OR gate.
The output is &lt;code&gt;1&lt;/code&gt; if at least one of the inputs is &lt;code&gt;1&lt;/code&gt;.
The gate is irreversible. That is, the information about the inputs is lost
during the computation. For instance, if we get an output &lt;code&gt;1&lt;/code&gt;, we cannot tell
which pair of inputs produced this output. This behavior is typical
for gates in classical computing.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/quantum-or.png&#34; width=&#34;550px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Classical OR gate and reversible OR gate and their truth tables.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;In contrast, quantum gates are reversible. This means that quantum gates should
work both in forward and also in backward directions. Therefore, we have to
design a reversible gate that preserves information. On the image above, on the
right, we see a reversible OR gate. Can we build a quantum circuit that
implements this reversible OR gate? The answer is yes.&lt;/p&gt;

&lt;p&gt;First, let&#39;s visualize the circuit graphically.
The circuit consists of three qubits. The first two qubits are the inputs $a$
and $b$. The third qubit will contain the output $c&#39;$.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/quantum-or-circuit.gif&#34; width=&#34;550px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Animated quantum &lt;strong&gt;OR&lt;/strong&gt; circuit. The circuit consists of three qubits and Pauli X and Toffoli gates applied to them. The first two qubits are the inputs $a$ and $b$. The third qubit will contain the output.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The idea is first to check if the second (first) qubit is in the state
$|1\rangle$. If it is, we have to flip the third qubit, which is initially in
the state $|0\rangle$. Therefore, we
apply the Pauli $X$ gate to the first (second) qubit first. This will invert the
input: If it was $|0\rangle$, it will become $|1\rangle$. Then, we apply the
Toffoli gate trying to flip the output. The Toffoli gate will flip the third
qubit if the first two qubits are both in the state $|1\rangle$. Before
proceeding to the next attempt, we have to undo the previous $X$ gate. Therefore,
we apply the Pauli $X$ gate to the first (second) to undo the previous $X$ gate
and try again with another input. Finally, we check if both initial inputs were
$|1\rangle$, using the third Toffoli gate. Below is the Python code that
manipulates the quantum states and simulates the quantum circuit from above.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

&lt;span style=&#34;color:#75715e&#34;&gt;# PauliX gate operator applied to the first of three qubits&lt;/span&gt;
X1_3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
&lt;span style=&#34;color:#75715e&#34;&gt;# PauliX gate operator applied to the second of three qubits&lt;/span&gt;
X2_3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]])), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
&lt;span style=&#34;color:#75715e&#34;&gt;# # PauliX gate operator applied to the third of three qubits&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# X3_3 = np.kron(np.kron(np.eye(2), np.eye(2)), np.array([[0, 1], [1, 0]]))&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# Toffoli gate operator&lt;/span&gt;
Toffoli &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(
    [
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],
        [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
    ]
)

states &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    &lt;span style=&#34;color:#75715e&#34;&gt;# |0,0,0&amp;gt; state&lt;/span&gt;
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]),
    &lt;span style=&#34;color:#75715e&#34;&gt;# |0,1,0&amp;gt; state&lt;/span&gt;
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]),
    &lt;span style=&#34;color:#75715e&#34;&gt;# |1,0,0&amp;gt; state&lt;/span&gt;
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]),
    &lt;span style=&#34;color:#75715e&#34;&gt;# |1,1,0&amp;gt; state&lt;/span&gt;
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]),
]

&lt;span style=&#34;color:#75715e&#34;&gt;# After applying OR on first two qubits, the expected outputs are:&lt;/span&gt;
expected_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    &lt;span style=&#34;color:#75715e&#34;&gt;# |0,0,0&amp;gt;&lt;/span&gt;
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]),
    &lt;span style=&#34;color:#75715e&#34;&gt;# |0,1,1&amp;gt;&lt;/span&gt;
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]),
    &lt;span style=&#34;color:#75715e&#34;&gt;# |1,0,1&amp;gt;&lt;/span&gt;
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]),
    &lt;span style=&#34;color:#75715e&#34;&gt;# |1,1,1&amp;gt; state&lt;/span&gt;
    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]),
]


&lt;span style=&#34;color:#75715e&#34;&gt;# Implementing a gate that maps from states to expected_outputs&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# using the following gates: X1_3, X2_3, X3_3, Toffoli&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logic_gate_or&lt;/span&gt;(state):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; Toffoli &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; X2_3 &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; Toffoli &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; X2_3 &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; X1_3 &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; Toffoli &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; X1_3 &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; state


&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, state &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(states):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(logic_gate_or(state))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;allclose(
        logic_gate_or(state), expected_outputs[i]
    ), f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Test failed for state {state}&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This provides a general idea of how quantum circuits can be used to build
digital circuits. An additional constraint is
the requirement for the quantum gates to be reversible.&lt;/p&gt;

&lt;p&gt;Looking from the perspective of simulating digital circuits with quantum gates,
we note a significant overhead. On the other hand, unlike conventional digital
circuits, quantum circuits can accept such inputs as
$a = |+\rangle := \frac 1 {\sqrt 2} \left( |0\rangle + |1\rangle \right).$
Corresponding to a 50% chance to measure either &lt;code&gt;0&lt;/code&gt; or &lt;code&gt;1&lt;/code&gt; on that qubit - the
result of applying a Hadamard gate.
A superposition of inputs is also a valid input!
Here is where the power of quantum computing comes from:
The ability to process multiple inputs at the same time.
This is known as &lt;em&gt;quantum parallelism&lt;/em&gt;, which lies at the heart of many quantum
algorithms.&lt;/p&gt;

&lt;p&gt;Okay, let&#39;s see what happens when we apply the OR gate to a superposition of
inputs. We provide the following inputs:
$a = \frac 1 {\sqrt 2} \left( |0\rangle + |1\rangle \right)$,
$b = |0\rangle$,
$c = |0\rangle$.
To achieve a superposition on the input $a$,
we apply the Hadamard gate to the first out of three qubits:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Hadamard gate&lt;/span&gt;
H &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Hadamard gate when applied to the first of three qubits&lt;/span&gt;
H1_3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kron(H, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))

&lt;span style=&#34;color:#75715e&#34;&gt;# Prepare |0,0,0&amp;gt; state: 100% probability to measure three zero bits.&lt;/span&gt;
state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# Apply the Hadamard gate to the first qubit:&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 50% probability to measure 0 and 50% probability to measure 1&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# on the first qubit.&lt;/span&gt;
state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; H1_3 &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;@&lt;/span&gt; state

&lt;span style=&#34;color:#75715e&#34;&gt;# Apply the OR gate&lt;/span&gt;
state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; logic_gate_or(state)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(state)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is the result:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;[0.70710678 0.         0.         0.         0.         0.70710678
 0.         0.        ]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Or, in other words, the quantum state is
$\left[\frac 1 {\sqrt 2}, 0, 0, 0, 0, \frac 1 {\sqrt 2}, 0, 0\right]$.
Once we square those amplitudes, we get the following probability distribution.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/or-gate-superposition.png&#34; width=&#34;550px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Probability distribution after applying the OR gate to initial state $a=|+\rangle$, $b=|0\rangle$, $c=|0\rangle$.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;This corresponds to a 50% chance to measure classical &lt;code&gt;000&lt;/code&gt; bits and
a 50% chance to measure &lt;code&gt;101&lt;/code&gt;.
Isn&#39;t it nice?&lt;/p&gt;

&lt;p&gt;We were unsure whether the first input was 0 or 1.
And therefore we have encoded this ambivalence into the quantum state
without any difficulties. We were able to run the OR gate on this superposition
of inputs. And as a result, we have processed two inputs at the same time! In
contrast, in the classical case, we would have to run the OR gate twice to
process both possible inputs.&lt;/p&gt;

&lt;p&gt;Of course, if we were to perform the real experiment, we would have to run
several repetitions to estimate the probability distribution. Here is what the
result could look like if we performed 1000 measurements:&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/or-gate-measurement.png&#34; width=&#34;550px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Histogram of the quantum OR gate applied to $a=|+\rangle$, $b=|0\rangle$, $c=|0\rangle$ on a perfect quantum computer.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Of course, we would need to run the experiment many times to get
a better estimate of the probability distribution.
You can also play with the circuit in &lt;a href=&#34;https://algassert.com/quirk#circuit=%7B%22cols%22%3A%5B%5B%22X%22%5D%2C%5B%22%E2%80%A2%22%2C%22%E2%80%A2%22%2C%22X%22%5D%2C%5B%22X%22%2C%22X%22%5D%2C%5B%22%E2%80%A2%22%2C%22%E2%80%A2%22%2C%22X%22%5D%2C%5B1%2C%22X%22%5D%2C%5B%22%E2%80%A2%22%2C%22%E2%80%A2%22%2C%22X%22%5D%5D%7D&#34;&gt;Quirk&lt;/a&gt;!
For instance, what happens when both inputs $a$ and $b$ are in
the superposition $|+\rangle = \frac 1 {\sqrt 2} \left( |0\rangle + |1\rangle \right)$?&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/quantum-or-circuit_2.png&#34; width=&#34;550px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Quantum OR gate applied to $a=b=|+\rangle$, $c=|0\rangle$.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Right, we have a 75% chance to measure &lt;code&gt;1&lt;/code&gt; on the third qubit!
By now, you should have developed a feeling for how quantum computing works.
The drawback, if we can call it that, is that we have to
deal with probabilities. Even though the quantum state exists in a
superposition, that is, in several states simultaneously, we can only measure
one of them at a time.&lt;/p&gt;

&lt;h3 id=&#34;run-on-a-real-quantum-computer&#34;&gt;Run on a Real Quantum Computer&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Excellent, but why don&#39;t we run this on a real quantum computer?&lt;/em&gt; you may ask.
And you will be right! So I went through the trouble to register for an IBMid
to run the circuit on a real &lt;a href=&#34;https://quantum.ibm.com/&#34;&gt;quantum computer&lt;/a&gt;.
And if you want to reproduce my results, you can do it too.
Here is the &lt;a href=&#34;https://gitlab.com/quadrant27/qc/&#34;&gt;code&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-token&#34;&gt;&lt;a href=&#34;#fn:fn-token&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;I ran the quantum OR circuit on &lt;a href=&#34;https://quantum.ibm.com/services/resources?tab=systems&amp;amp;system=ibm_osaka&#34;&gt;ibm_osaka&lt;/a&gt; instance.
And I checked the two cases:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$a = |+\rangle$, $b = |0\rangle$, $c = |0\rangle$.&lt;/li&gt;
&lt;li&gt;$a = b = |+\rangle$, $c = |0\rangle$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/results-qpu1.png&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Real QC measurements of quantum OR gate applied to $a = |+\rangle$, $b=c=|0\rangle$ (ibm_osaka).&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;
&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/results-qpu2.png&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Real QC measurements of quantum OR gate applied to $a=b=|+\rangle$, $c=|0\rangle$ (ibm_osaka).&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;As expected, the results are &lt;a href=&#34;https://en.wikipedia.org/wiki/Noisy_intermediate-scale_quantum_era&#34;&gt;noisy&lt;/a&gt;. Because the quantum computer is not
perfect. Still, we can see that the quantum OR gate behaves as expected. The
probability distribution is close to the theoretical one&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-msb&#34;&gt;&lt;a href=&#34;#fn:fn-msb&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h2 id=&#34;why-can-t-we-simulate-quantum-circuits-with-classical-computers&#34;&gt;Why Can&#39;t We Simulate Quantum Circuits with Classical Computers?&lt;/h2&gt;

&lt;p&gt;This all is well. However, why can&#39;t we just simulate quantum circuits with
classical computers as we have done above? The answer is that we can, when the
number of qubits is small. However, to accurately represent a quantum state of
$n$ qubits we need $2^n$ complex numbers. For example, to accurately represent
an arbitrary quantum state of 100 qubits, we need
$1,267,650,600,228,229,401,496,703,205,376 \approx 10^{30}$ complex numbers!
This exponential state space growth requires an exponentially larger amount of
computational resources.&lt;/p&gt;

&lt;h2 id=&#34;transpilation&#34;&gt;Transpilation&lt;/h2&gt;

&lt;p&gt;OK, so I&#39;ve expressed my quantum circuit in terms of logical
qubits. How it gets executed on physical quantum hardware?&lt;/p&gt;

&lt;p&gt;If you are at the point of asking this question, congratulations for following
along! Here is what happens. There are three stages of the process known a
&lt;em&gt;transpilation&lt;/em&gt;.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Mapping&lt;/li&gt;
&lt;li&gt;Placement&lt;/li&gt;
&lt;li&gt;Routing&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;During the &lt;em&gt;mapping&lt;/em&gt; stage, logical quantum gates are mapped to
natively supported ones. For instance, if we deal with photonics,
quantum gates can be implemented using beam splitters and
phase shifters (check e.g. &lt;a href=&#34;https://arxiv.org/pdf/quant-ph/0112088.pdf&#34;&gt;Ralph CNOT gate&lt;/a&gt;).
And another example: This year&#39;s QHack had a challenge to implement a
&lt;a href=&#34;https://arxiv.org/abs/2205.14081&#34;&gt;wormhole-inspired teleportation protocol&lt;/a&gt;
in terms of the gates that are native to a superconducting device.&lt;/p&gt;

&lt;p&gt;During the &lt;em&gt;placement&lt;/em&gt; stage, quantum circuits are allocated to
certain areas on a physical device. It can happen that your circuit
is too large for a specific device and thereby the circuit has to be
redesigned.&lt;/p&gt;

&lt;p&gt;Finally, during the &lt;em&gt;routing&lt;/em&gt; stage, quantum gates are being
connected by physical wires. Sometimes, portions of a physical
circuit are configured to identity transformations to satisfy
the requirements. And this typically results in higher noise.&lt;/p&gt;

&lt;p&gt;For instance, the quantum OR circuit we have discussed above
looks like this after transpilation to the IBM quantum computer:&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/transpiled.png&#34; width=&#34;600px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Quantum OR circuit translated to native gates.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Notice that our &lt;em&gt;logical&lt;/em&gt; qubits q0, q1, and q2 are mapped to
&lt;em&gt;physical&lt;/em&gt; qubits q33, q39, and q40. I have encircled those physical
qubits on the image below. They are neighbors and therefore, the
routing is much simpler.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/ibm_osaka.png&#34; width=&#34;650px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;ibm_osaka quantum computer.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Overall, if you are familiar with
&lt;a href=&#34;https://en.wikipedia.org/wiki/Field-programmable_gate_array&#34;&gt;FPGAs&lt;/a&gt;,
the process of transpilation is quite similar.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/qc/aspect2019.jpg&#34; alt=&#34;11/10/2019&#34; width=&#34;650px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Alain Aspect at Paris-Saclay: &#39;The result does not exist before it is measured.&#39;&lt;/h4&gt;
  &lt;p&gt;
    11/10/2019
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Quantum computing is a great puzzle. In quantum hardware or in software.
This forces us to think in different terms.
New related fields are also booming. We can think of quantum machine learning,
quantum cryptography, quantum communication, and quantum chemistry.
Note that we have only discussed the case of perfect quantum computers.
Today, we have to deal with &lt;a href=&#34;https://en.wikipedia.org/wiki/Noisy_intermediate-scale_quantum_era&#34;&gt;noisy intermediate-scale quantum&lt;/a&gt; devices.
These devices are not perfect and have a limited number of qubits.
Also we do not really know if there is any fundamental limit to the number of
qubits that can be used in a quantum computer. This is an open question.&lt;/p&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;pre&gt;
@article{penkovsky2024QC,
 title   = &#34;Quantum Computing for Hackers&#34;,
 author  = &#34;Penkovsky, Bogdan&#34;,
 journal = &#34;penkovsky.com&#34;,
 year    = &#34;2024&#34;,
 month   = &#34;April&#34;,
 url     = &#34;https://penkovsky.com/post/qc/&#34;
}
&lt;/pre&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/QED:_The_Strange_Theory_of_Light_and_Matter&#34;&gt;Richard Feynman. Quantum Electrodynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0USje5vTIKs&amp;amp;list=PLUl4u3cNGP60cspQn3N9dYRPiyVWDd80G&amp;amp;index=9&#34;&gt;Understand the notion of probability amplitudes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://quantumatlas.umd.edu/entry/quantum-states/&#34;&gt;Quantum states&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Bell%27s_theorem&#34;&gt;Bell&#39;s theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://archive.org/details/QuantumComputationAndQuantumInformation10thAnniversaryEdition&#34;&gt;Nielsen and Chuang. Quantum Computation And Quantum Information&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://algassert.com/post/1716&#34;&gt;Visualizing 2-Qubit Entanglement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://juliaphysics.github.io/PhysicsTutorials.jl/tutorials/general/quantum_ising/quantum_ising.html&#34;&gt;Quantum Ising Phase Transition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://algassert.com/quirk&#34;&gt;Quirk quantum circuit simulator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-superpos&#34;&gt;A superposition is a linear combination.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-superpos&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-meas&#34;&gt;This is related to the Heisenberg Uncertainty Principle: You cannot measure a quantum state without disturbing it.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-meas&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-quanta&#34;&gt;Photons initially were called &amp;quot;quanta&amp;quot; by Einstein.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-quanta&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-token&#34;&gt;You will also need to register for an account and get an API token to run the code on a quantum computer in the cloud (it&#39;s free).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-token&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-msb&#34;&gt;Qiskit uses different conventions for the order of qubits. For instance, they would write $q2,q1,q0$, while I used $q0,q1,q2$ order. This does not affect the results, just be aware of the order when working with Qiskit.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-msb&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>How To Be More Productive</title>
      <link>https://penkovsky.com/post/productivity/</link>
      <pubDate>Sat, 06 Apr 2024 12:56:34 +0200</pubDate>
      
      <guid>https://penkovsky.com/post/productivity/</guid>
      <description>&lt;p&gt;Many articles have been written on the topic. And yet I am writing another one, as a reminder.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;#create-a-lot-of-free-space&#34;&gt;Create a lot of free space&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;#generate-many-ideas&#34;&gt;Generate many ideas&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;#bring-some-ideas-to-the-very-end&#34;&gt;Bring some ideas to the very end&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;create-a-lot-of-free-space&#34;&gt;Create A Lot Of Free Space&lt;/h2&gt;

&lt;p&gt;There is nothing new here. Obviously, having a very busy schedule has its opportunity cost. And the associated cost is not even reduced creativity. It is reduced productivity. Here is how I realized that.&lt;/p&gt;

&lt;p&gt;A few years ago I started a side project which has substantially altered my schedule. During my PhD and later years, I was accustomed to finishing my working day after 8pm. I enjoyed my work, or so I thought. However, because of the new side project I was forced to finish my day job by 5pm. This way I returned home earlier and had a few hours to spend on my extra project. To my surprise, I was not simply doing “two jobs”. This new schedule boosted my enthusiasm about the day job. And enthusiasm in it’s turn helped to produce better results on that first job. My ideas became also more diverse. And I felt that the days became more meaningful overall.&lt;/p&gt;

&lt;p&gt;One way to look at that experience is to guess that in fact I have become busier. Well, I cannot deny that I had more responsibilities by then. The other way of thinking is that I have created a time slot, a free space, which was beneficial to do something new.&lt;/p&gt;

&lt;p&gt;The act of creating space is also an act of power and of freedom of choice. From this perspective, being “lucky” correlates with that freedom. Call it a serendipity if you will. Psyche journal &lt;a href=&#34;https://psyche.co/guides/how-to-open-up-to-serendipity-and-create-your-own-luck&#34;&gt;article&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-luck&#34;&gt;&lt;a href=&#34;#fn:fn-luck&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; suggests that being lucky is about being alert to the unexpected. In a social experiment, the “lucky” person finds a banknote on a pavement, comes inside a nearby coffee shop, and starts a conversation with a random visitor in there. And that random person happens to be a business man, a new connection. Whereas the “unlucky” person fails to accomplish any of those. My impression is that the “unlucky” person in the experiment does not allow themself for any “free” space in any possible meaning such as time, money, personal freedom, etc.&lt;/p&gt;

&lt;p&gt;Speaking of money. Two years before the 2020 pandemic (and that also implies, before the above article appeared in Psyche journal), I took an airplane when coming from a conference. I cannot call myself a spender. I am typically careful with money, this is my upbringing. However, that time I decided to “upgrade” the airplane ticket. Just for the sake of change. And guess what? I am sitting in the “premium economy” class (not even some fancy “business class”) next to a VP of some quite large company (more than 3000 employees). Honestly, I didn’t care about the position of the person. What I was actually impressed about was how quick was their brain to find analogies in many linguistic questions. And they gave some great advice about creating a start-up.&lt;/p&gt;

&lt;h2 id=&#34;generate-many-ideas&#34;&gt;Generate Many Ideas&lt;/h2&gt;

&lt;p&gt;This one seems so obvious. Yet to me, it was less obvious. If you are like me, then you may enjoy the book by Adam Grant entitled Originals: How Non-Conformists Move the World&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-adam-grant&#34;&gt;&lt;a href=&#34;#fn:fn-adam-grant&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. The author argues that to increase the “chance of success”, one has to generate many ideas. The less obvious consequence perhaps is that the famous pieces of art, the most famous inventions and so on are only very few known contributions of their inventors. The tip of the ideas iceberg.&lt;/p&gt;

&lt;p&gt;If you think you may not enjoy the book, then as a one-sentence summary I will adapt this one, from Chapter 2: “the rule is that you need to generate at least twenty-five ideas to strike gold“. I just opened the latest bookmark and it happened to be this one. Serendipity.&lt;/p&gt;

&lt;p&gt;Critics (those who won’t read) will ask, &lt;em&gt;why twenty-five&lt;/em&gt;? Please read carefully, “at least twenty-five”. Twenty-six. Forty. You name it.&lt;/p&gt;

&lt;p&gt;And one more thing, Adam Grant provides a table of odds of Nobel Prize winning for those scientists that indulge in artistic hobbies. Want to guess? Yes, the odds are higher for those artistically-inclined scientists. Which reinforces the “create a lot of free space” guideline. For example, Richard Feynman won a Nobel prize in physics in 1965. If you knew that fact then you probably know that he also enjoyed playing bongos. An artistic hobby is a free space for thinking.
Similarly, Cal Newport in his book Deep Work: Rules for Focused Success in a Distracted World
insists on the necessity of creating dedicated time slots. This is the time when you are not distracted by anything else.
And this is when you have space to think. And to seed new ideas.&lt;/p&gt;

&lt;h2 id=&#34;bring-some-ideas-to-the-very-end&#34;&gt;Bring Some Ideas To The Very End&lt;/h2&gt;

&lt;p&gt;Speaking about the artistic side of Feynman. He used to consider himself as someone not being able to draw. &lt;em&gt;I am that kind of person, too&lt;/em&gt;, some readers may think. Did you know that at some point in his life, Feynman was taught to draw? Did you also know that this led to Feynman&#39;s solo art exhibition&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-feynman-bio&#34;&gt;&lt;a href=&#34;#fn:fn-feynman-bio&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; under his proper pseudonym?&lt;/p&gt;

&lt;p&gt;The last point I want to make here. By generating at least twenty-five ideas for
a subject of choice, you will have to be quite selective. It is almost sure that
you will not have time to implement all of them to fruition. Yet very probably
the only way to benefit is to bring one of these ideas to completion. Whether
your attempt fails or not, how can you know if the idea was worth it if you haven&#39;t invested your time in it? Finally, the learning experience by writing a few
equations on a figurative black board is not the same as going into the details
of making a real-life experiment. And making an experiment is not the same as
making a working prototype. Which itself does not require the same amount of
effort as scaling this up and making a product that may (or may not) change the
world.&lt;/p&gt;

&lt;h2 id=&#34;modus-operandi&#34;&gt;Modus Operandi&lt;/h2&gt;

&lt;p&gt;Are there any guidelines how to implement the above in everyday life? Here are
a few considerations that I find useful.&lt;/p&gt;

&lt;p&gt;Mark Mortier from 2Circle says that Wellbeing = Productivity. This is quite
self-explanatory. Get back to the basics. Sleep well, eat well, exercise. Once
you&#39;ve got this all right, you can start thinking about the rest.
There is also a related idea that before improving the world, start with yourself.&lt;/p&gt;

&lt;p&gt;James Clear (the author of Atomic Habits) came up with the following
observation: In the long-run, &lt;a href=&#34;https://jamesclear.com/3-2-1/may-12-2022&#34;&gt;prioritization beats
efficiency&lt;/a&gt;. So here is a simple
guideline that helps me in everyday work (I apologize for not remembering the
original source of the idea): There are three modes: &lt;em&gt;Producing&lt;/em&gt; (creative
mode), &lt;em&gt;Networking&lt;/em&gt; (communicating), and &lt;em&gt;Consuming&lt;/em&gt; (e.g. learning, watching,
reading). &lt;em&gt;Networking&lt;/em&gt; and &lt;em&gt;Consuming&lt;/em&gt; can be combined. However, &lt;em&gt;Producing&lt;/em&gt; can
only be done well when not distracted by the other two modes. Don&#39;t let any
meetings distract you from producing whatever you are producing (strategic
planning, writing reports, coding, painting, etc.). Thereby I aim at starting
the day in the &lt;em&gt;Creative&lt;/em&gt; mode, before any meetings, discussions, emails or
any other communication (&lt;em&gt;Networking&lt;/em&gt; mode).&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-luck&#34;&gt;&lt;a href=&#34;https://psyche.co/guides/how-to-open-up-to-serendipity-and-create-your-own-luck&#34;&gt;How to be lucky&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-luck&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-adam-grant&#34;&gt;&lt;a href=&#34;https://www.goodreads.com/book/show/25614523-originals&#34;&gt;Adam Grant. Originals: How Non-Conformists Move the World&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-adam-grant&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-feynman-bio&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Surely_You%27re_Joking,_Mr._Feynman!&#34;&gt;Ralph Leighton and Richard Feynman. Surely You&#39;re Joking, Mr. Feynman!&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-feynman-bio&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Meta-Learning</title>
      <link>https://penkovsky.com/neural-networks/meta-learning/</link>
      <pubDate>Sat, 16 Dec 2023 14:20:00 +0100</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/meta-learning/</guid>
      <description>&lt;p&gt;Breaking news! Artificial intelligence is taking over the world. Or it
is not? Here is what you need to know about a deeper concept
of meta-learning.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Meta-learning&lt;/em&gt; is learning about learning.
Learning how to learn belongs here too.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#models-analyzing-other-models&#34;&gt;Models Analyzing Other Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#updating-neural-network-during-run&#34;&gt;Updating Neural Network During Run&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#self-modifying-learning-algorithms&#34;&gt;Self-Modifying Learning Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;The first thing that pops to mind is &lt;a href=&#34;https://en.wikipedia.org/wiki/Automated_machine_learning&#34;&gt;AutoML&lt;/a&gt;,
a search for the best model architecture. It often includes
data preparation, feature engineering, and hyperparameter search.
Companies like Google adore this approach: First, AutoML requires
a lot of computational resources, and companies like Google have it.
Second, AutoML can make machine learning accessible to non-experts,
enabling companies like Google to sell their compute power to
more customers.&lt;/p&gt;

&lt;p&gt;However, meta-learning is more than AutoML. It is a broad subject.
Here are the articles that have marked my thinking.&lt;/p&gt;

&lt;h2 id=&#34;models-analyzing-other-models&#34;&gt;Models Analyzing Other Models&lt;/h2&gt;

&lt;p&gt;In &lt;a href=&#34;https://openreview.net/pdf?id=cmJiEqniEc&#34;&gt;this work&lt;/a&gt;, Langosco and colleagues
detect whether a &lt;a href=&#34;https://penkovsky.com/neural-networks/day1/&#34;&gt;neural network&lt;/a&gt; has a &lt;em&gt;backdoor&lt;/em&gt;.
A backdoor is a way to modify the input to force a network
to produce an undesirable output. As an extreme example, imagine
a self-driving car that crashes into another car after seeing a malicious
drawing on the road. That drawing would be a neural network&#39;s input
that was misinterpreted to cause a bad decision, which itself led to a crash.
And a backdoor in this case could be a susceptibility of a neural
network to a particular form or texture.&lt;/p&gt;

&lt;p&gt;Therefore, you see, it could be quite hard to manually design such an algorithm
that would detect if a neural network has a backdoor in it.
So it seems natural to use another neural network (which we call a
&lt;em&gt;meta-model&lt;/em&gt;) to analyze the weights of the first one and to detect whether
there is a built-in backdoor or not.&lt;/p&gt;

&lt;p&gt;I think the importance of this work is not only
technical, it also raises the awareness about the
challenges that we &lt;em&gt;will&lt;/em&gt; face when relying on AI. In 2023 AI is
often defined as &amp;quot;allowing computers to learn and solve problems
almost like a person&amp;quot; (&lt;a href=&#34;https://www.bbc.com/news/technology-65855333&#34;&gt;BBC, 01/11/2023&lt;/a&gt;). Which, to be honest, has
almost nothing to do with intelligence&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. And even though
there is no imminent &lt;a href=&#34;https://en.wikipedia.org/wiki/The_Terminator&#34;&gt;Terminator&lt;/a&gt; danger, we need
to beware of malicious human actors out there.&lt;/p&gt;

&lt;p&gt;Here are a &lt;a href=&#34;https://arxiv.org/abs/2301.12780&#34;&gt;few&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2002.05688&#34;&gt;more&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2110.15288&#34;&gt;examples&lt;/a&gt;
&lt;a href=&#34;https://arxiv.org/abs/2002.11448&#34;&gt;of&lt;/a&gt; models analyzing other models.&lt;/p&gt;

&lt;h2 id=&#34;updating-neural-network-during-run&#34;&gt;Updating Neural Network During Run&lt;/h2&gt;

&lt;p&gt;Typical neural network weights are static. That means that once the network is
trained, the weights are fixed and the network stops to learn.
On the other hand, our brains continue to learn during the whole life.
And it makes sense since our brains have evolved to survive in ever-changing
environment. This ability is largely due to the brain&#39;s plasticity, which
enables it to form new connections. What if artificial neural networks were
plastic?&lt;/p&gt;

&lt;p&gt;From the perspective of &lt;a href=&#34;https://penkovsky.com/neural-networks/beyond/&#34;&gt;reinforcement learning&lt;/a&gt;,
meta-learning is about agents that learn from ongoing experience, even
without explicit reward signal. For instance,
a robotic dog was trained to walk on the grass. Now, as it crosses a patch of
sandy terrain, can it adapt its walking gait?
&lt;a href=&#34;https://arxiv.org/abs/2007.02686&#34;&gt;Najarro and Risi&lt;/a&gt; suggest a recipe of an agent that
modifies its behavior based on &lt;em&gt;local&lt;/em&gt; learning. That is, based on the
&lt;a href=&#34;https://penkovsky.com/neural-networks/day1/&#34;&gt;neural network&lt;/a&gt; &lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;layers&#39;&lt;/a&gt;
inputs &lt;em&gt;and&lt;/em&gt; outputs. Using the Hebbian rule (&amp;quot;what fires together wires
together&amp;quot;), the network is updated on the fly. Evolutionary techniques
are employed to train such agents. In a remarkable demonstration, a robot
manages to walk despite one of its legs being damaged. This would be hardly
possible with neural networks having static weights (that is, &amp;quot;normal&amp;quot; neural
networks).&lt;/p&gt;

&lt;p&gt;To capture invariant object representations, &lt;a href=&#34;https://www.nature.com/articles/s41593-023-01460-y&#34;&gt;Halvagal and Zenke&lt;/a&gt;
propose to augment the Hebbian rule to include a predictive term. &amp;quot;It cancels
when the neural activity does not change and, therefore, accurately predicts
future activity,&amp;quot; the authors explain.
The idea resonates with HTM neurons from &lt;a href=&#34;https://link.springer.com/content/pdf/10.1007/s42452-021-04715-0.pdf&#34;&gt;thousand brains theory&lt;/a&gt;,
originally conceptualized by &lt;a href=&#34;https://www.youtube.com/watch?v=-EVqrDlAqYo&amp;amp;t=2075s&#34;&gt;Jeff Hawkins&lt;/a&gt;. Each HTM neuron
predicts its activation. The hypothesis claims that these predictions
of expected inputs allow brains to filter out what has changed in the
environment and what is immediately important to notice. Like a branch cracking.
Suddenly, a wild animal detects a threat in the jungle. Such alertness is
essential for survival in a complex environment.&lt;/p&gt;

&lt;p&gt;&amp;quot;So how about &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;transformers&lt;/a&gt;?&amp;quot; you might ask, &amp;quot;They use attention.&amp;quot;
Yes, transformers technically belong to the category of dynamic neural networks,
too. What happens with GPT models (&lt;em&gt;T&lt;/em&gt; is for transformer of course) is that
when you provide a text prompt, it serves as a context. The &lt;em&gt;attention&lt;/em&gt;
mechanism underpinning the transformer architecture is transforming the neural
network weights, as a function of that context. And that is what makes
transformers flexible.&lt;/p&gt;

&lt;p&gt;By the way don&#39;t be misled thinking that the attention mechanism/dynamically
updated weights is the reason why transformer models are called &lt;em&gt;generative&lt;/em&gt;!
Generative models already exist for decades. Other examples are generative
adversarial networks (GANs), auto-encoders,
&lt;a href=&#34;https://penkovsky.com/neural-networks/day9/&#34;&gt;variational auto-encoders&lt;/a&gt; (VAEs), Hidden Markov
models, etc. The actual reason why all those models are called generative is
learning a &lt;a href=&#34;https://en.wikipedia.org/wiki/Generative_model&#34;&gt;joint distribution&lt;/a&gt;.
Combining a generative model with neural networks is now called
&lt;a href=&#34;https://en.wikipedia.org/wiki/Generative_artificial_intelligence&#34;&gt;Generative AI&lt;/a&gt; (not so elegant, as you can see).
It just happens that the transformer architecture is popular,
and is the first thing associated with &amp;quot;Generative AI&amp;quot; these days.&lt;/p&gt;

&lt;p&gt;Coming back to transformers, &lt;a href=&#34;https://arxiv.org/abs/2109.02869&#34;&gt;Tang and Ha&lt;/a&gt; demonstrate what they call
a &lt;em&gt;sensory neuron&lt;/em&gt;. Based on the attention mechanism, their agents
trained by reinforcement learning are able to quickly re-adapt to the
change of order of sensory stimuli. That is, it does not matter in which
order the observation inputs are provided. Moreover, their agent is not confused
even when the majority of the inputs are masked out.&lt;/p&gt;

&lt;h2 id=&#34;self-modifying-learning-algorithms&#34;&gt;Self-Modifying Learning Algorithms&lt;/h2&gt;

&lt;p&gt;Perhaps this concept is the pinnacle of meta-learning. What can be more
appealing than learning algorithms that modify themselves?
If updating a neural network during run was a &lt;em&gt;first-order&lt;/em&gt; meta-learning,
then updating neural networks that update neural networks would be
already a &lt;em&gt;second-order&lt;/em&gt;. And by induction, neural networks that update their own
weights, as is done for example by &lt;a href=&#34;https://arxiv.org/abs/2202.05780&#34;&gt;Irie and colleagues&lt;/a&gt;, can be
considered an &lt;em&gt;infinite-order&lt;/em&gt; meta-learning.&lt;/p&gt;

&lt;p&gt;Don&#39;t agree? Then shoot me an email!&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The family of meta-learning concepts is vast. This article has
touched a few notable examples. However, as the field continues to
evolve, more interesting work is to appear.
I don&#39;t know how far we are from the so-called &amp;quot;artificial general
intelligence&amp;quot;, however, its distinctive characteristic is extreme adaptivity.
And adaptivity is something that is currently explored by meta-learning
researchers.&lt;/p&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;pre&gt;
@article{penkovsky2023meta,
 title   = &#34;Meta-Learning&#34;,
 author  = &#34;Penkovsky, Bogdan&#34;,
 journal = &#34;penkovsky.com&#34;,
 year    = &#34;2023&#34;,
 month   = &#34;December&#34;,
 url     = &#34;https://penkovsky.com/neural-networks/meta-learning/&#34;
}
&lt;/pre&gt;

&lt;!-- https://www.bbc.com/news/technology-65855333 https://archive.is/BUSha --&gt;

&lt;!--

--&gt;

&lt;!-- https://archive.is/J2QPq --&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;&lt;p&gt;I believe, a truly &amp;quot;intelligent&amp;quot; machine has to be adaptive at least.
And probably it has—in some sense—to be &lt;em&gt;embodied&lt;/em&gt; as well.
What we witness today with ChatGPT is a &lt;em&gt;text-to-text&lt;/em&gt; engine. It&#39;s more
about machine translation than intelligence. Once I asked it to create a
personal training plan for swimming. I&#39;ve got some result, quite far from
what I specified. Does ChatGPT even &lt;em&gt;know&lt;/em&gt; about how to be immersed in the
water and what it may feel like? Certainly not. It managed to
&amp;quot;translate&amp;quot; existing articles and compile a training plan of some kind.
I doubt it could ever substitute a coach who can actually swim.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Day 10: Beyond Supervised Learning</title>
      <link>https://penkovsky.com/neural-networks/beyond/</link>
      <pubDate>Thu, 11 May 2023 21:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/beyond/</guid>
      <description>&lt;p&gt;Ever wondered how machines defeated the best human Go player Lee Sedol in 2016?
A historical moment for the game that was previously considered to be very
tough. What is reinforcement learning that generates so much buzz recently?
Superhuman performance playing arcade &lt;a href=&#34;https://arxiv.org/abs/1312.5602&#34;&gt;Atari games&lt;/a&gt;, real-time &lt;a href=&#34;https://www.nature.com/articles/s41586-021-04301-9&#34;&gt;Tokamak
plasma control&lt;/a&gt;, Google &lt;a href=&#34;https://arxiv.org/abs/2211.07357&#34;&gt;data center cooling&lt;/a&gt;, and
&lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7029011854383284224/&#34;&gt;autonomous chemical synthesis&lt;/a&gt; are all the recent achievements behind
the approach. Let&#39;s dive to learn what empowers &lt;em&gt;deep reinforcement learning&lt;/em&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reinforcement-learning-concepts&#34;&gt;Reinforcement Learning Concepts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reinforcement-learning-hints&#34;&gt;Reinforcement Learning Hints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reinforce&#34;&gt;REINFORCE Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#proximal-policy-optimization&#34;&gt;Proximal Policy Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#alphago-vs-lee-sedol&#34;&gt;AlphaGo vs Lee Sedol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#goodbye&#34;&gt;Goodbye?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#learn-more&#34;&gt;Learn More&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Reinforcement learning (RL) is a machine learning technique that is all about
&lt;em&gt;repetitive&lt;/em&gt; decision making. Well, just like when you go camping. During
your first trip you realize that you need more food and you lack some tools. Next
time, you take some more cereals and dried fruit, a better knife, and a pot.
And after yet several more attempts you invest in better shoes or a backpack
and learn how to arrange your stuff in a neat way. The journeys become longer
and more enjoyable. As you can see, you iterate. You learn from experience. And
you get rewarded.&lt;/p&gt;

&lt;p&gt;No matter how much you can relate yourself to the experiences above, they
contain everything that reinforcement learning has. An &lt;em&gt;agent&lt;/em&gt; is learning from
experience (or from mistakes if you want) by interacting with its environment.
The agent receives some sort of a reward signal in response to its actions. And
that is basically the idea. An idea from psychology? Perhaps.&lt;/p&gt;

&lt;p&gt;In a &lt;a href=&#34;https://en.wikipedia.org/wiki/Supervised_learning&#34;&gt;supervised learning&lt;/a&gt;
setting&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; you would be instructed what equipment to take with you. And you
would need to act exactly as instructed. However, the real life is not like
that. You might have watched a camping channel on YouTube and still struggle to
start a fire. Trying different kinds of approaches yourself, however, improves
your survival skills over time.&lt;/p&gt;

&lt;p&gt;You may also notice that reinforcement learning is actually more general than
supervised learning. Indeed, in supervised learning we usually talk about a
single iteration and apply some sort of ground truth or target signal. However,
let&#39;s take a look at the following example. Imagine, you are a director of AI
at Tesla (those hipsterish cars, you know) and your team trains a self-driving
car based on videos that were previously recorded. Sounds like a supervised
problem with images and labels, right? The car performs well during the same
day, but tomorrow it rains and the car refuses to drive well. What do you do?
You say, perhaps the distribution of images has changed. Let&#39;s collect some
more for a rainy weather. And the model training is repeated. The third day is
very foggy and your team has to collect the data again. And train the model
again. So what happens? Exactly! Iteration. You have an implicit reinforcement
learning loop where it is &lt;em&gt;you&lt;/em&gt; who acts as an agent trying to outsmart the
weather conditions&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-2&#34;&gt;&lt;a href=&#34;#fn:fn-2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;More often than not present decisions will influence the situation, and thus
they will influence &lt;em&gt;future decisions&lt;/em&gt; too. This is perhaps &lt;strong&gt;the biggest
difference from supervised learning&lt;/strong&gt;. Supervised learning conveniently omits
to confess that its main goal is to help &lt;em&gt;making decisions&lt;/em&gt; in &lt;em&gt;real&lt;/em&gt; world.
The most boring vision task you have encountered, classifying &lt;a href=&#34;https://penkovsky.com/neural-networks/day4/&#34;&gt;MNIST
images&lt;/a&gt;, at some point was actually useful for post
offices to automate mail delivery. Similarly, predicting time series might be
helpful getting an idea about climate change or predicting economic downturns.
Whatever supervised learning benchmark you take, in its origin there is some
sort of implication in the real world.&lt;/p&gt;

&lt;p&gt;Unlike supervised learning, reinforcement learning is all about decisions. It
explicitly states the goal of achieving the best overall consequences -- by
maximizing total reward. For instance, to arrive from point A to point B you
may take a car. Depending on which route you will take and how frequently you
will rest, this will affect your trip duration and how tired you will arrive.
Those circumstances may further affect your plans. Decisions almost never occur
in isolation. They will inevitably lead to new decisions. That is why real-life
challenges are often accompanied by reinforcement learning in some form.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A quick note.&lt;/em&gt; People often talk about &lt;em&gt;deep&lt;/em&gt; reinforcement learning. This is
to highlight the presence of neural networks. The fact does not change the
essence of the method. These days almost everyone is doing &lt;em&gt;deep&lt;/em&gt; reinforcement
learning anyway, so I prefer to omit the term. Just wanted to make sure we
stay on the same page. Now, we will focus our attention on the nitty-gritty
details of reinforcement learning.&lt;/p&gt;

&lt;h2 id=&#34;reinforcement-learning-concepts&#34;&gt;Reinforcement Learning Concepts&lt;/h2&gt;

&lt;p&gt;By interacting with environment, an RL agent actually creates its &lt;em&gt;own&lt;/em&gt; unique
dataset, whereas in supervised learning the dataset is predefined.  As the
agent explores its environment and the dataset is being created we apply
backprop to teach our agent similarly to &lt;em&gt;supervised learning&lt;/em&gt;. It turns out
there is a large variety of ways how to do that. The concepts below will give
you a taste about the key ideas from reinforcement learning.&lt;/p&gt;

&lt;h3 id=&#34;policies-states-observations&#34;&gt;Policies, States, Observations&lt;/h3&gt;

&lt;p&gt;A &lt;em&gt;policy&lt;/em&gt; (denoted by $\pi$) is simply a strategy that an agent uses when
responding to changes in the environment. The following notation reads &amp;quot;a policy
parametrized by parameters $\phi$ to take an action $a$ given a state $s$&amp;quot;:&lt;/p&gt;

&lt;p&gt;$$ \pi_{\phi}(a|s). $$&lt;/p&gt;

&lt;p&gt;Typically $\phi$ signifies weights in a neural network (the &lt;em&gt;deep&lt;/em&gt; reinforcement
learning story). In the notation above, by $s$ people usually mean &amp;quot;state&amp;quot;. And
sometimes they actually mean &amp;quot;observations&amp;quot; $o$. The difference between the two
is that &lt;em&gt;observations&lt;/em&gt; are a projection of the complete &lt;em&gt;state&lt;/em&gt;
describing the environment. For example, when learning robotic manipulations
from camera pixels, observations of a robotic hand are only a representation of
the actual environment state from a certain angle. Sometimes people talk about
&amp;quot;completely observable&amp;quot; environments, then $s = o$. The distinction between
$s$ and $o$ does not affect the RL algorithms we are learning about today.&lt;/p&gt;

&lt;h3 id=&#34;on-policy-vs-off-policy&#34;&gt;On-policy vs Off-policy&lt;/h3&gt;

&lt;p&gt;Reinforcement learning algorithms can be split between on-policy and
off-policy. The first ones use &lt;em&gt;trajectories&lt;/em&gt; (experiences)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-3&#34;&gt;&lt;a href=&#34;#fn:fn-3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; generated by the
policy itself, while the second ones use trajectories from some other policies.
For instance, algorithms that use a &lt;em&gt;replay buffer&lt;/em&gt; (such as &lt;a href=&#34;https://arxiv.org/abs/1312.5602&#34;&gt;deep Q networks
playing Atari games&lt;/a&gt;) to store transitions are off-policy algorithms.
Typically, off-policy algorithms have better &lt;em&gt;sample efficiency&lt;/em&gt; compared to
on-policy ones, which makes them attractive when it is costly to generate new
experiences. For instance, when training a physical robot. On the other hand,
on-policy algorithms are often used when acquiring new experiences are cheap. For
instance, in simulation.&lt;/p&gt;

&lt;h3 id=&#34;offline-reinforcement-learning&#34;&gt;Offline Reinforcement Learning&lt;/h3&gt;

&lt;p&gt;Offline RL is a family of algorithms where an RL agent observes past
experiences and tries to figure out a &lt;em&gt;better&lt;/em&gt; policy without interaction with
an environment. Of course this is a very challenging task. Nevertheless, it
has many real-world applications where it could be dangerous or illegal to
apply reinforcement learning experiments. For instance, finding the best
treatment in the medical setting. A doctor would not experiment on a patient
using different drugs because this can lead to health deterioration. Instead,
they may use reinforcement learning techniques applied to &lt;em&gt;previous&lt;/em&gt; records of
other patients to figure out the best prescription (offline setting).&lt;/p&gt;

&lt;h3 id=&#34;discrete-vs-continuous-actions&#34;&gt;Discrete vs Continuous Actions&lt;/h3&gt;

&lt;p&gt;Playing an arcade game using a manipulator with four buttons implies a discrete
action setting (four possible actions). However, in reality there are settings
with infinite or very large number of actions. For instance, robot joints
positions. Certain algorithms can be applicable only to one action type
(&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html&#34;&gt;DQN&lt;/a&gt; can be applied only for discrete and &lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html&#34;&gt;DDPG&lt;/a&gt; only for
continuous actions), whereas certain others can be used for both (e.g.
&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html&#34;&gt;A2C&lt;/a&gt;, &lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html&#34;&gt;PPO&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&#34;deterministic-vs-stochastic-policies&#34;&gt;Deterministic vs Stochastic Policies&lt;/h3&gt;

&lt;p&gt;Certain policies inherently produce deterministic actions (&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html&#34;&gt;DQN&lt;/a&gt;), while
others sample from a learned distribution producing stochastic actions
(&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html&#34;&gt;PPO&lt;/a&gt;). Of course, it is possible to make a deterministic algorithm to
produce stochastic actions (epsilon-greedy exploration) and vice versa. Why
use a stochastic policy? Actually, under stochastic environments optimal policies
are often stochastic. The simplest example is
&lt;a href=&#34;https://en.wikipedia.org/wiki/Rock_paper_scissors&#34;&gt;Rock-Paper-Scissors&lt;/a&gt; game.&lt;/p&gt;

&lt;h3 id=&#34;model-free-vs-model-based&#34;&gt;Model-free vs Model-based&lt;/h3&gt;

&lt;p&gt;Model-based approaches assume a certain environment model. The advantage of this
approach is better &lt;em&gt;sample efficiency&lt;/em&gt;. On the other hand, model-free approaches
may better generalize to unknown environments. In some cases, environment&#39;s
model is learned.&lt;/p&gt;

&lt;h3 id=&#34;sample-efficiency&#34;&gt;Sample Efficiency&lt;/h3&gt;

&lt;p&gt;By sample efficiency we mean using less examples for training.&lt;/p&gt;

&lt;h2 id=&#34;reinforcement-learning-hints&#34;&gt;Reinforcement Learning Hints&lt;/h2&gt;

&lt;p&gt;The goal of reinforcement learning is typically to solve a real-life
challenge. For that purpose you will need to define some interaction protocol
between your agent and its environment and also a reward function.  The reward
function provides a score how well your agent performs.  Typically, it is
beneficial having a &amp;quot;dense&amp;quot; reward so that the agent gets some
information at every time step. This is not always possible and there are
&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/her.html&#34;&gt;methods&lt;/a&gt; to circumvent this issue.  One way to look at &lt;em&gt;reward shaping&lt;/em&gt;
is that RL is your &amp;quot;compiler&amp;quot; and the reward is your understanding of the
problem you are trying to solve.&lt;/p&gt;

&lt;p&gt;To gain some expertise, you may want to start with existing
&lt;a href=&#34;https://github.com/openai/gym&#34;&gt;environments&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-4&#34;&gt;&lt;a href=&#34;#fn:fn-4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; and &lt;a href=&#34;https://stable-baselines3.readthedocs.io&#34;&gt;RL
algorithms&lt;/a&gt;. If your goal is to train a physically embodied robot, you
may want to create your own environment to try out some ideas in simulation.
This will save you some time since running a simulator is typically faster than
real-time robot training.&lt;/p&gt;

&lt;p&gt;The more accurate is the simulator, the better the agent is likely to perform in
real-world. For instance, in &lt;a href=&#34;https://arxiv.org/abs/1804.10332&#34;&gt;Sim-to-Real: Learning Agile Locomotion For
Quadruped Robots&lt;/a&gt; the authors have obtained better results by
creating accurate actuator models and performing latency modeling.&lt;/p&gt;

&lt;p&gt;However, there is always a difference between running an agent on any simulator
and reality. The problem known as &lt;em&gt;reality gap&lt;/em&gt;. There are different techniques
how to reduce this difference. One of them is &lt;a href=&#34;https://arxiv.org/abs/1703.06907&#34;&gt;domain
randomization&lt;/a&gt;. The idea is to train the agent using environments
with randomized parameters. In &lt;a href=&#34;https://proceedings.mlr.press/v100/mehta20a.html&#34;&gt;active domain randomization&lt;/a&gt;, the
&lt;em&gt;active learning&lt;/em&gt; approach is combined: agents are trained more often on environments
where they performed poorly.&lt;/p&gt;

&lt;p&gt;Another technique &lt;em&gt;domain adaptation&lt;/em&gt; suggests making &lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2019/papers/James_Sim-To-Real_via_Sim-To-Sim_Data-Efficient_Robotic_Grasping_via_Randomized-To-Canonical_Adaptation_Networks_CVPR_2019_paper.pdf&#34;&gt;real data look like
those in simulation&lt;/a&gt; or vice versa. You may also want to perform
parameters &lt;em&gt;&lt;a href=&#34;https://journals.sagepub.com/doi/pdf/10.1177/0278364919887447&#34;&gt;fine-tuning&lt;/a&gt;&lt;/em&gt; on your &lt;a href=&#34;https://arxiv.org/abs/1810.05687&#34;&gt;real&lt;/a&gt; robot.&lt;/p&gt;

&lt;p&gt;Note also that if you are training an agent in a simulated environment,
the agent may &amp;quot;overfit&amp;quot; to the environment. That is, it may exhibit unrealistic
(and often undesired) behaviors that still lead to high reward scores.
The agent may try to exploit environment glitches if there are any.&lt;/p&gt;

&lt;p&gt;Having those practical strategies in mind, we are going to the meat of RL.
Below we are discussing an algorithm which constitutes the basis to many modern RL
strategies such as TRPO and &lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html&#34;&gt;PPO&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;reinforce&#34;&gt;REINFORCE&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;REINFORCE&lt;/em&gt;, also called Monte Carlo Policy Gradient, is the simplest from the
&lt;em&gt;policy gradient&lt;/em&gt; algorithms family. The advantage of policy gradients is that
they can learn stochastic policies. This also addresses the
exploration-exploitation dilemma.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;REINFORCE algorithm:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Initialize policy parameters $\phi$.&lt;/li&gt;
&lt;li&gt;Generate trajectories $s_0, a_0, r_1,...,s_{T-1}, a_{T-1}, r_T$ by interacting with environment.&lt;/li&gt;
&lt;li&gt;For every step $t = 0,1,...,T-1$, estimate returns $R_t = \sum_{k=t+1}^T \gamma^{k-t-1} r_k.$&lt;/li&gt;
&lt;li&gt;Optimize agent parameters $\phi \leftarrow \phi + \alpha R_t \nabla \log \pi_{\phi}(a_t|s_t)$.&lt;/li&gt;
&lt;li&gt;Repeat steps 2-5 until convergence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note that when using universal function approximators (that is neural
networks), convergence is not guaranteed. However, in practice
you still have a good chance to train your agent.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;numEpisodes&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Num episodes &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;numEpisodes&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Seed Torch for reproducibility.&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Feel free to remove.&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;manual_seed_L&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;seed&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- Environment seed&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Step 1: Initialize policy parameters&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mkAgent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actionDim&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- We also initialize the optimizer&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mkTrainer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Repeat steps 2-4 for the number of episodes (trajectories)&lt;/span&gt;
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;agent&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;\at&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;reinforce&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conf&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;seed&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;at&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;) (&lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&lt;/span&gt;) [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;numEpisodes&lt;/span&gt;]

  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; ()

&lt;span style=&#34;color:#a6e22e&#34;&gt;reinforce&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cfg&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;seed&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Step 2: Trajectories generation (rollout)&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;reset&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;seed&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;)
  (&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rollout&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;maxSteps&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s0&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Episode &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; - Score &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;sum&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt;)

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Step 3: Estimating returns&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;returnsNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;std&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-8&lt;/span&gt;)

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Step4: Optimize&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cfg&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returnsNorm&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;trajectory-generation&#34;&gt;Trajectory Generation&lt;/h3&gt;

&lt;p&gt;The agent generates a trajectory by interacting with the environment. We call
this a &lt;em&gt;rollout&lt;/em&gt;. By observing the function signature below, we can tell that
the function consumes an integer number, an agent, and environment state. This
integer is simply the maximal number of steps per episode. As a result, the
function will provide the trajectory: observations, actions, and rewards. In
addition, it also provides log probabilities, which we will use to compute our
objective (or loss) before we can optimize parameters in Step 4.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;rollout&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;State&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ([&lt;span style=&#34;color:#66d9ef&#34;&gt;Observation&lt;/span&gt;], [[&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;]], [&lt;span style=&#34;color:#66d9ef&#34;&gt;Reward&lt;/span&gt;], [&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;])
  &lt;span style=&#34;color:#75715e&#34;&gt;-- ^ Observations, actions, rewards, log probabilities&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is how we implement it: we benefit from the excellent &lt;code&gt;unfoldM&lt;/code&gt; function that
has type &lt;code&gt;Monad m =&amp;gt; (s -&amp;gt; m (Maybe (a, s))) -&amp;gt; s -&amp;gt; m [a]&lt;/code&gt;. That is we iterate
as long as the function in the first argument &lt;code&gt;(s -&amp;gt; m (Maybe (a, s)))&lt;/code&gt;
provides a &lt;code&gt;Just&lt;/code&gt; value (and stop when &lt;code&gt;Nothing&lt;/code&gt;).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Haskell libraries provide lots of &amp;quot;pieces of code&amp;quot; or &amp;quot;programming templates&amp;quot;:
functions like &lt;code&gt;map&lt;/code&gt;, &lt;code&gt;foldl&lt;/code&gt;, &lt;code&gt;scanr&lt;/code&gt;, &lt;code&gt;unfoldr&lt;/code&gt;, &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;zipWith&lt;/code&gt;, etc.
All those are compact versions of loops!
Some of those concepts gradually diffuse into
imperative languages (such as C++ and Python).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;rollout&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;L&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;unzip4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unfoldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s0&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Reached max number of steps. Nothing = stop.&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;_agent&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;{&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}, &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;isDone&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;-- The environment is done: stop.&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
           &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
          &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;observations&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;
          (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;Action&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac_&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getAction&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;
          &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;

          &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;ac_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;), (&lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;_agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&amp;#39;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The heart of iteration is in the end: First, observe the environment and
sample actions.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;observations&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;
(&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;Action&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac_&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getAction&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, simulate the environment step:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And finally, prepare the next iteration step by reducing the maximal
number of steps and passing the agent and the new environment state.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;ac_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;), (&lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;_agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&amp;#39;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is how we get an action and a log probability.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;getAction&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unsqueeze&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Return a single discrete action&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Action&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;], &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Evaluate the policy $\pi_{\phi}$:
If no action provided, sample a new action from the learned distribution.
Also get log probabilities for the action.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;probs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;policy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Categorical&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;fromProbs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;probs&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Sample from the categorical distribution:&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- get a tensor of integer values (one sample per observation).&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;shape&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;]
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;estimating-returns&#34;&gt;Estimating Returns&lt;/h3&gt;

&lt;p&gt;After a rollout we (retrospectively) compute how good were our decisions during
the whole trajectory.  The trick is that we start from the last step. That is,
our return $R$ at time step $t$ is our current reward plus a discounted
&lt;em&gt;future&lt;/em&gt; return.&lt;/p&gt;

&lt;p&gt;$$
R_t = r_t + \gamma R_{t+1}.
$$&lt;/p&gt;

&lt;p&gt;This expands into&lt;/p&gt;

&lt;p&gt;$$
R_t = r_t + \gamma (r_{t+1} + \gamma (r_{t+2} + \gamma( ... ))).
$$&lt;/p&gt;

&lt;p&gt;where $r_t$ is the reward at time $t$. The meaning of this expression is the
essence of policy gradient: We evaluate how good were our past decisions with
respect to the future outcomes.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;An intriguing way to look at discount factor $\gamma$ is by using the concept
of terminal state (to put simply, death). At each future step,
the agent can get a reward with probability $\gamma$ and can
die with probability $1 - \gamma$. Therefore, discounting the reward
is akin to incorporating the &amp;quot;fear of death&amp;quot; into RL.
In his &lt;a href=&#34;https://www.youtube.com/watch?v=JHrlF10v2Og&amp;amp;list=PL_iWQOsE6TfX7MaC6C3HcdOf1g337dlC9&#34;&gt;lectures&lt;/a&gt;, S. Levine gives an example of receiving 1000 dollars today
or in million years. In the latter case, the reward is hugely discounted
as it is unlikely that we will be able to receive it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We compute the returns as a function of rewards &lt;code&gt;rs&lt;/code&gt;.  We also use next
terminal states indicators and future value estimators in special cases.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;returns&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:[]&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;]

    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;
       &lt;span style=&#34;color:#75715e&#34;&gt;-- Discounting a future return&lt;/span&gt;
       &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;In policy gradient algorithms we evaluate how good are our past decisions
with respect to the future outcomes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note that we compute the return recursively as in equation above: reward
plus a discounted &lt;em&gt;future&lt;/em&gt; return. Since Haskell is a &lt;em&gt;lazy&lt;/em&gt; programming
language, it is not critical that this value does not exist yet.
Essentially, we promise to compute the list of &lt;em&gt;future&lt;/em&gt; values &lt;code&gt;y = f xs&lt;/code&gt;.
Finally, we prepend current return to the list of future returns
&lt;code&gt;r + γ * (head y) : y&lt;/code&gt;. Fascinating!&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;optimizing-parameters&#34;&gt;Optimizing parameters&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Computing the loss.&lt;/li&gt;
&lt;li&gt;Running a gradient step.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sumAll&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt;
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;final-bits&#34;&gt;Final Bits&lt;/h3&gt;

&lt;p&gt;There are still a few other things to complete the project. Let&#39;s define our
policy network type $\Phi$. Here we have three fully-connected layers. In other
words, two hidden layers.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;pl1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  , &lt;span style=&#34;color:#a6e22e&#34;&gt;pl2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  , &lt;span style=&#34;color:#a6e22e&#34;&gt;pl3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now we can implement the forward pass in a Policy Network:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;policy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;policy&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (   &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pl1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pl2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pl3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;softmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)) &lt;span style=&#34;color:#a6e22e&#34;&gt;state&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;An agent is simply a policy network in Reinforce.
We will update this data type to also accommodate the &lt;em&gt;critic&lt;/em&gt; network
in improved policy gradient later on:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;REINFORCE Trainer type is a single optimizer.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Adam&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A new, untrained agent with random weights&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;mkAgent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;mkAgent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actDim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;samplePhi&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Parameters $\phi \in \Phi$ initialization&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;samplePhi&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;samplePhi&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;)
     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;)
     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actDim&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Initializing the trainer&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;mkTrainer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;mkTrainer&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;par&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flattenParameters&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mkAdam&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.999&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;par&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, let&#39;s train the agent to solve the classic CartPole environment!
See the complete REINFORCE project on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day10/Reinforce.lhs&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;proximal-policy-optimization&#34;&gt;Proximal Policy Optimization&lt;/h2&gt;

&lt;p&gt;REINFORCE algorithm is nice because it is simple. On the other hand,
in practice it has a problem: finding the best meta-parameters, such
as learning rate. Choose a value to low and training needs more samples,
too high and it does not converge. To alleviate this training instability
multiple variations of this algorithm have been proposed. One popular
variation is called Proximal Policy Optimization (PPO). Below we upgrade
REINFORCE to PPO.&lt;/p&gt;

&lt;h3 id=&#34;actor-critic-style&#34;&gt;Actor-Critic Style&lt;/h3&gt;

&lt;p&gt;In REINFORCE we only had a policy network $\pi_{\phi}$. A more advanced
version would be not only to use a policy network (so-called &lt;em&gt;actor&lt;/em&gt;),
but also a value network (&lt;em&gt;critic&lt;/em&gt;). This value network would estimate
how good is the state we are currently in. Naturally, the output of the
critic network is a scalar with this estimated state value.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- Value (Critic) Network type: Three fully-connected layers&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  , &lt;span style=&#34;color:#a6e22e&#34;&gt;l2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  , &lt;span style=&#34;color:#a6e22e&#34;&gt;l3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;-- | Forward pass in a Critic Network&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;critic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;critic&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l3&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;state&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is how we will sample initial network weights:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sampleTheta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;sampleTheta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;)
     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;)
     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To make our life a bit simpler, we can also use the following wrapper when
dealing with raw observations.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- | Get value: Convenience wrapper around `critic` function.&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;value&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;value&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;θ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unsqueeze&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;critic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;θ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob_&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The state value given by the critic network will be used for &lt;em&gt;advantage&lt;/em&gt;
estimation, instead of simply calculating discounted returns.&lt;/p&gt;

&lt;h3 id=&#34;advantage-estimation&#34;&gt;Advantage Estimation&lt;/h3&gt;

&lt;p&gt;As you remember, in policy gradients we optimize neural network
parameters using $\mathbf{A} \cdot \nabla \log \pi_{\phi}(a_t|s_t)$.
In REINFORCE, this term $\mathbf{A} = R_t$ is discounted returns.
This totally makes sense. However, this is not the only option&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-5&#34;&gt;&lt;a href=&#34;#fn:fn-5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Let me introduce advantage $A = r - v$ where $r$ is reward and $v$ is value,
i.e. how good is our action. The advantage tells us how current action is
better than an &lt;em&gt;average&lt;/em&gt; action. Therefore, by optimizing our policy with
respect to advantage, we would improve our actions compared to average. This
would help to reduce &lt;em&gt;variance&lt;/em&gt; of policy gradient.&lt;/p&gt;

&lt;p&gt;In PPO, we typically use a fancy way to estimate the advantage called
generalized advantage estimator (GAE).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;advantages&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dones&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;L&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;zip4&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;L&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;drop&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dones&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;vs&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;L&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;drop&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vs&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;-- vs are current values (denoted by v) and&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;-- (L.drop 1 vs) are future values (denoted by v&amp;#39;)&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Not necessary to reverse the list if using lazy evaluation&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; [(&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Bool&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;)] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;]
    &lt;span style=&#34;color:#75715e&#34;&gt;-- End of list to be reached: same as terminal (auxiliary value)&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;:[]&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;]

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Next state terminal&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Next state non-terminal&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;v&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;delta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;v&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;
       &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;ppo-specifics&#34;&gt;PPO Specifics&lt;/h3&gt;

&lt;p&gt;In REINFORCE, the policy gradient loss function was simply&lt;/p&gt;

&lt;p&gt;$$L(\phi) = -\sum_{t} \log \pi_{\phi}(a_t|s_t) \cdot R_t.$$&lt;/p&gt;

&lt;p&gt;Note the negation sign in front: without it, the loss (to be minimized) becomes
an objective (to be maximized) - earning highest returns&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-6&#34;&gt;&lt;a href=&#34;#fn:fn-6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;p&gt;$$L(\phi) = \sum_{t} \log \pi_{\phi}(a_t|s_t) \cdot R_t.$$&lt;/p&gt;

&lt;p&gt;Now, what distinguishes PPO, it its objective. It consists of three
components: a clipped policy gradient objective (actor network), value loss (critic network),
and entropy bonus. Since the value function is a loss term, it has a minus sign:&lt;/p&gt;

&lt;p&gt;$$L_t^{PPO} = L_t^{CLIP} - c_1 L^{VF} + c_2 S,$$&lt;/p&gt;

&lt;p&gt;where $c_1 = 0.5$ and $c_2=0.01$ are constants. If we are going to minimize
loss instead,&lt;/p&gt;

&lt;p&gt;$$L_t^{PPO} = -L_t^{CLIP} + c_1 L^{VF} - c_2 S = $$
$$ = L_t^{PG} + c_1 L^{VF} - c_2 S.$$&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pg&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vfC&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mulScalar&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;vLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entC&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mulScalar&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;entropyLoss&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, the most interesting part of PPO. If we denote $r_t(\phi)$
the probability ratio
$r_t(\phi) = \frac{\pi_{\phi}(a_t|s_t)}{\pi_{\phi_{\text{old}}}(a_t|s_t)}$.
Then PPO is maximizing the following objective&lt;/p&gt;

&lt;p&gt;$$ L^{CLIP}(\phi) = \mathbb{\hat E}_t \left( \min \left( r_t(\phi) \hat A_t, \text{clip}(r_t(\phi), 1 - \epsilon, 1 + \epsilon) \hat A_t \right) \right).$$&lt;/p&gt;

&lt;p&gt;First, let&#39;s take a look at the clipped objective
$\text{clip}(r_t(\phi), 1 - \epsilon, 1 + \epsilon) \hat A_t$.
Here, we try to restrict how far our policy will move during the policy
gradient update. If advantage $A$ is positive, the objective is clipped at
value $1 + \epsilon$. If advantage $A$ is negative, then the objective is
clipped at $1 - \epsilon$. Finally, we take a min between a clipped and
unclipped objective. Therefore, the final objective is a pessimistic bound on
the unclipped objective (see &lt;a href=&#34;http://arxiv.org/abs/1707.06347&#34;&gt;Schulman et al.&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Now, transforming the objective into a loss: we add a minus sign and
replace min with max:&lt;/p&gt;

&lt;p&gt;$$ L^{PG}(\phi) = \sum_t \max \left( -r_t(\phi) \hat A_t, -\text{clip}(r_t(\phi), 1 - \epsilon, 1 + \epsilon) \hat A_t \right).$$&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clamp&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&amp;#39;&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note that for better numerical properties we typically use &lt;code&gt;logratio&lt;/code&gt;, instead
of &lt;code&gt;ratio&lt;/code&gt; (a log of a ratio is the difference of logs):&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newlogprobs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code&gt;newlogprobs&lt;/code&gt; are calculated by evaluating the new policy.&lt;/p&gt;

&lt;p&gt;Next term $L_t^{VF}$ is often a squared-error loss
$(V_{\theta}(s_t) - V_t^{\text{targ}})^2$.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;vLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;newvalues&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;However, we use &lt;a href=&#34;https://arxiv.org/pdf/2005.12729.pdf&#34;&gt;clipped value loss&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;clippedValueLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newval&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ret&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lossUnclipped&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;newval&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ret&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;clipped&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;clamp&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;newval&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val&lt;/span&gt;))
      &lt;span style=&#34;color:#a6e22e&#34;&gt;lossClipped&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;clipped&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ret&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;lossMax&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lossUnclipped&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lossClipped&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lossMax&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, the entropy bonus $S$ is used in order to stimulate exploration,
i.e. performing the same task by as many ways as possible.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;entropyLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is updated &lt;code&gt;evaluate&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- | Get action, logProb, and entropy tensors&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- ^ Policy weights&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- ^ Observations&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Maybe&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- ^ Action&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;probs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;policy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Categorical&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;fromProbs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;probs&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Maybe&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Categorical&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Categorical&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;shape&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;]
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Putting it all together, we get this &lt;code&gt;optimize&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;acs_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advantages_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  (&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;newlogprobs&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_t&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;acs_t&lt;/span&gt;)

  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newvalues&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;critic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;θ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_t&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newlogprobs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Normalized advantages&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;advantages_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advantages_t&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;std&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advantages_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-8&lt;/span&gt;)

      &lt;span style=&#34;color:#a6e22e&#34;&gt;pg&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;vLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clippedValueLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newvalues&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;entropyLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pg&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vfC&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mulScalar&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;vLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entC&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mulScalar&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;entropyLoss&lt;/span&gt;

  ((&lt;span style=&#34;color:#a6e22e&#34;&gt;θ&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&amp;#39;&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;θ&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;)

  &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;θ&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;See the complete code on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day10/Ppo.hs&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;alphago-vs-lee-sedol&#34;&gt;AlphaGo vs Lee Sedol&lt;/h2&gt;

&lt;p&gt;We started this article with the defeated Go champion Lee Sedol. He played
against software called AlphaGo (version Lee, after him). How &lt;em&gt;actually&lt;/em&gt; did
AlphaGo win? What is &lt;em&gt;self-play&lt;/em&gt; and how does it relate to reinforcement
learning? Below we will address those questions.&lt;/p&gt;

&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;

&lt;p&gt;AlphaGo generates data by playing games against an opponent (since the game of
Go is a two-player game). This opponent is another machine player randomly
chosen from a pool of opponents. In the end of the game one player
wins (reward $r = +1$) and another loses (reward $r = -1$).&lt;/p&gt;

&lt;p&gt;After several games have been played, the player is updated. Then, this new
player is compared to the old one. If the new one wins sufficiently often, it
is then accepted. Iteration by iteration, and the AlphaGo is improved by
playing against itself. This is called a &lt;em&gt;self-play&lt;/em&gt;. Below, we are going into
mode details.&lt;/p&gt;

&lt;h3 id=&#34;monte-carlo-tree-search&#34;&gt;Monte Carlo Tree Search&lt;/h3&gt;

&lt;p&gt;We should introduce a new concept called Monte Carlo Tree Search. Monte Carlo,
if you didn&#39;t know, is the area in the city-state of Monaco. It is also the
European gambling capital. Some rich people like to waste money in the Monte
Carlo casino. The author had a chance to visit it once and can confirm that is
absolutely true.&lt;/p&gt;

&lt;p&gt;Anyway, I digress. Statisticians simply love calling everything &lt;em&gt;Monte Carlo&lt;/em&gt;
when there are random simulations involved. For example, have you noticed that
REINFORCE is also named Monte Carlo Policy Gradient? This is related to
stochastic trajectories generated during rollouts.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/mcts.jpg&#34; alt=&#34;Monte Carlo Tree Search. Source: [Silver *et al.*](http://dx.doi.org/10.1038/nature16961)&#34; width=&#34;690px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;&lt;/h4&gt;
  &lt;p&gt;
    Monte Carlo Tree Search. Source: &lt;a href=&#34;http://dx.doi.org/10.1038/nature16961&#34;&gt;Silver &lt;em&gt;et al.&lt;/em&gt;&lt;/a&gt;
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Monte Carlo Tree Search (MCTS) explores a tree of possible moves and is
continuously refining its understanding of the game state by simulating random
rollouts (also called playouts because of the game aspect). In Monte Carlo
tree, each node is a board state (see Fig. 1). For each board state, we
estimate the &lt;em&gt;value&lt;/em&gt; of this state $Q$. That is how good it is or, in other
words, whether we believe this board position is leading to a win or loss.  The
innovation behind AlphaGo was in combining MCTS with convolutional neural
networks for state value estimation and for selecting the move to play.&lt;/p&gt;

&lt;p&gt;In the first MCTS stage called &lt;em&gt;Selection&lt;/em&gt; (Fig. 1&lt;strong&gt;a&lt;/strong&gt;),
an action is selected to maximize the value $Q$ plus some bonus $u(P)$
that encourages exploration. This bonus is designed such that in the beginning
the algorithm prefers actions with high prior probability $P$ and low
visit count; and eventually it prefers actions with high action value $Q$.
This is achieved by weighting the bonus term by an exploration constant.&lt;/p&gt;

&lt;p&gt;After a certain depth of Monte Carlo tree is reached, the second stage
&lt;em&gt;Evaluation&lt;/em&gt; (Fig. 1&lt;strong&gt;c&lt;/strong&gt;) is performed: current position (leaf node in tree)
is evaluated using the value network. And the actions (game moves) are selected
according to the policy network $\pi$ until the end of the game (terminal state),
which leads to the &lt;em&gt;outcome&lt;/em&gt; $\pm r$.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;em&gt;Backup&lt;/em&gt; is performed (Fig. 1&lt;strong&gt;d&lt;/strong&gt;): the rollout statistics are
updated by adding the outcome in a backward pass through the Monte Carlo tree.
In the end, the value estimate $Q(s,a)$ becomes a weighted sum of the value
network and just obtained rollout statistics. At the end of the search the
algorithm selects an action with the maximum visit count. The authors state
that this is less sensitive to outliers as compared to maximizing action value.&lt;/p&gt;

&lt;p&gt;One more thing: when the number of certain node visits is frequent, the
successor state is added to the tree. This is called &lt;em&gt;Expansion&lt;/em&gt; (Fig. 1&lt;strong&gt;b&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;Coming back to the neural networks you might be pleased to learn that the
policy network $\pi$ was trained using the REINFORCE algorithm you already
know. Each iteration consisted of a minibatch of several games played between
the current policy network $\pi_{\phi}$ and an opponent $\pi_{\phi}-$ using
parameters from the previous iteration. Every 500 iterations, parameters
$\phi$ were saved to the opponent pool (so that there is always a variety
of opponents to choose from).&lt;/p&gt;

&lt;p&gt;The value network was trained to approximate the value function of the RL
policy network $\pi_{\phi}$. This was a regression task. The network was
trained on a dataset of 30 million positions drawn from the self-play.  There
are many interesting technical aspects I suggest to read about in the &lt;a href=&#34;http://dx.doi.org/10.1038/nature16961&#34;&gt;original
publication&lt;/a&gt;. &lt;!-- For instance, invalid game moves are masked out
during the MCTS simulation so that they are never selected. --&gt;&lt;/p&gt;

&lt;p&gt;To summarize, Monte Carlo Tree Search was employed in AlphaGo because an
exhaustive search is simply impossible as the game tree quickly grows too
large. The idea of MCTS combined with neural networks is conceptually simple
and provided sufficient computational resources, it wins.&lt;/p&gt;

&lt;h3 id=&#34;instead-of-conclusion&#34;&gt;Instead of Conclusion&lt;/h3&gt;

&lt;p&gt;Beating the strongest human player is an amazing feat by the DeepMind team.
However, we should not forget that behind the scenes there was operating a
whole data center to support AlphaGo computation. This is about six orders of
magnitude more power consumption compared to the human brain (~20W)!
Devising energy-efficient AI hardware is therefore our
&lt;a href=&#34;https://penkovsky.com/project/edge-ai/&#34;&gt;next milestone&lt;/a&gt; we are heading to.&lt;/p&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;pre&gt;
@article{penkovsky2023RL,
 title   = &#34;Beyond Supervised Learning&#34;,
 author  = &#34;Penkovsky, Bogdan&#34;,
 journal = &#34;penkovsky.com&#34;,
 year    = &#34;2023&#34;,
 month   = &#34;May&#34;,
 url     = &#34;https://penkovsky.com/neural-networks/beyond/&#34;
}
&lt;/pre&gt;

&lt;p&gt;If you like the article please consider sharing it.&lt;/p&gt;

&lt;h2 id=&#34;goodbye&#34;&gt;Goodbye?&lt;/h2&gt;

&lt;p&gt;I have to admit that after all these days we have barely scratched the surface.
Yet, I am happy about the journey we have made.  We have seen how to create
neural networks and to benefit from them; how to estimate model uncertainty;
how to generate new things. And today we have learned how to continuously make
decisions. There are so many more ideas to explore! Reinforcement learning is a
rabbit hole in itself. By the way, did you know that ChatGPT is secretly using
PPO to get better answers?&lt;/p&gt;

&lt;p&gt;Let me know if you have any remarks.&lt;/p&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.davidsilver.uk/wp-content/uploads/2020/03/pg.pdf&#34;&gt;D. Silver. Policy Gradient - Lecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/221402/understanding-the-role-of-the-discount-factor-in-reinforcement-learning&#34;&gt;Understanding the role of the discount factor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/learn/deep-rl-course&#34;&gt;Hugging Face Deep RL Course&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://journals.sagepub.com/doi/pdf/10.1177/0278364919887447&#34;&gt;Learning dexterous in-hand manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1810.05687&#34;&gt;Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cse-robotics.engr.tamu.edu/dshell/cs689/papers/jakobi95noise.pdf&#34;&gt;Noise and The Reality Gap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/blog/deep-rl-pg&#34;&gt;Policy Gradient with PyTorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1707.06347&#34;&gt;Proximal Policy Optimization Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2005.12729.pdf&#34;&gt;Implementation matters in deep policy gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dx.doi.org/10.1038/nature16961&#34;&gt;Mastering the game of Go with deep neural networks and tree search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dx.doi.org/10.1038/nature24270&#34;&gt;Mastering the game of Go without human knowledge&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; } }
});
&lt;/script&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;This is what we were doing all the days before. Supervised learning. That is how it is called. One of my favourite teachers used to quote Molière, &amp;quot;&lt;em&gt;Par ma foi, il y a plus de quarante ans que je dis de la prose, sans que j&#39;en susse rien&lt;/em&gt;&amp;quot; (&amp;quot;These forty years now I&#39;ve been speaking in prose without knowing it!&amp;quot;).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-2&#34;&gt;Honestly, I have no clue how a director of AI works at Tesla. But if you Andrej Karpathy and you are reading this, please share your past experiences. I would appreciate.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-3&#34;&gt;A trajectory is a repetitive sequence of observations and actions.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-4&#34;&gt;In Haskell it is possible to benefit from existing OpenAI Gym environments via &lt;a href=&#34;https://github.com/stites/gym-http-api&#34;&gt;Gym HTTP API&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-4&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-5&#34;&gt;See D. Silver&#39;s Lecture about &lt;a href=&#34;https://www.davidsilver.uk/wp-content/uploads/2020/03/pg.pdf&#34;&gt;Policy Gradients&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-5&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-6&#34;&gt;PyTorch seems to be better at minimizing rather than maximizing.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-6&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Towards Autonomous Synthesis With Deep Reinforcement Learning</title>
      <link>https://penkovsky.com/talk/towards-autonomous-synthesis2022/</link>
      <pubDate>Wed, 31 Aug 2022 20:05:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/talk/towards-autonomous-synthesis2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Day 9: Roaming The Latent Space</title>
      <link>https://penkovsky.com/neural-networks/day9/</link>
      <pubDate>Thu, 11 Aug 2022 10:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/day9/</guid>
      <description>

&lt;p&gt;Imagine you are a designer and you want a new font: A little bit heavier, with
rounder letters, more casual or a little bit more fancy. Could
this font be created just by tuning a handful of parameters?  Or imagine
that you are a fashion designer and you would like to create a new collection
as a mix of previous seasons?  Or that you are a musician desperately looking
for inspiration. How about a new song that mixes your mood and
Beethoven&#39;s Symphony No 3? It turns out, all this is actually possible.  To
better illustrate the concept, here is some music
interpolation:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/G5JT16flZwM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Don&#39;t forget to check out&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day8/&#34;&gt;Day 8: Model Uncertainty Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day7/&#34;&gt;Day 7: Real World Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The complete project is also available &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day9&#34;&gt;on Github&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;the-secret-space&#34;&gt;The Secret Space&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;latent&lt;/em&gt; - present and capable of emerging or developing but not now visible, obvious, active, or symptomatic&lt;/p&gt;

&lt;p&gt;—Webster&#39;s Dictionary&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;autoencoders&#34;&gt;Autoencoders&lt;/h3&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/ae_mlp.png&#34; alt=&#34;A simple autoencoder with latent dimension $L$.&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    A simple autoencoder with latent dimension $L$.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;How do we implement an autoencoder? Let us take a multilayer network from the
image above: $784 \rightarrow 400 \rightarrow L \rightarrow 400 \rightarrow
784$. Where the latent space dimension $L$ is some smaller number such as $20$
or maybe even $2$. The $L$-sized &lt;em&gt;latent&lt;/em&gt; vector $z$ is often called a
&lt;em&gt;bottleneck&lt;/em&gt;. The left part from the bottleck is called an &lt;em&gt;encoder&lt;/em&gt;
$q_{\phi}$ and the part on the right, a &lt;em&gt;decoder&lt;/em&gt; $p_{\theta}$. Where
$\phi$ and $\theta$ are trainable parameters of encoder and decoder,
respectively.&lt;/p&gt;

&lt;p&gt;The encoder takes an input (like an image) and generates a compact
representation, typically a vector. It is also not a mistake to call it a
&lt;em&gt;compressed representation&lt;/em&gt;. The decoder takes this compact representation and
creates an output as close as possible to the original input. Hence the name,
autoencoder. Of course, some information is lost due to the dimensionality
reduction. Therefore, the goal of a autoencoder is to find the most relevant
features to preserve as much information about the input object as possible.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AE&lt;/span&gt;
  { &lt;span style=&#34;color:#75715e&#34;&gt;-- Encoder parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Decoder parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, the whole autoencoder network is&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;ae&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;ae&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Encoder&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Decoder&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l3&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l4&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can also specify the exact dimensions&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;aeConfig&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;AESpec&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Of course, a smaller $L$ (&lt;code&gt;latent_size&lt;/code&gt;), the more information is lost.
Therefore, depending on the application we may want to change this value.
As a rule of thumb, $L$ contains the smallest number of neurons to enforce the
compression. In this article we set $L=2$ so that we can simply reveal our
latent space in two dimensions.&lt;/p&gt;

&lt;h3 id=&#34;variational-autoencoder&#34;&gt;Variational autoencoder&lt;/h3&gt;

&lt;p&gt;The principal difference of variational autoencoders (VAE)
from normal autoencoders is in the bottleneck. Instead of
a compressed input, it estimates a &lt;em&gt;distribution&lt;/em&gt;. In practice, VAE estimates
the mean $\mu$ and the standard deviation $\sigma$ -- normal distribution
parameters. By sampling from that distribution, a new unseen before object can
be generated. Like a new font or a new piece of cloth. Or a face. Or a melody.
Isn&#39;t that nice?&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/vae_mlp.png&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Variational autoencoder. Arrows signify fully-connected layers and vertical bars are data vectors.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt;
  {
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Encoder trainable parameters (phi)&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fcMu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fcSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Decoder trainable parameters (theta)&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc6&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Eq&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;myConfig&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lMu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It can be useful to have separate &lt;code&gt;encode&lt;/code&gt; $q_{\phi}(z|x)$
and &lt;code&gt;decode&lt;/code&gt; $p_{\theta}(x|z)$ functions.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enc_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enc_&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lMu&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lSigma&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l4&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l5&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, the complete variational autoencoder will be&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;vaeForward&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Bool&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;vaeForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;sigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)

  &lt;span style=&#34;color:#a6e22e&#34;&gt;eps&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randnLikeIO&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigma&lt;/span&gt;

  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;z&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;eps&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mul&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;sigma&lt;/span&gt;) `&lt;span style=&#34;color:#a6e22e&#34;&gt;add&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;reconstruction&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;z&lt;/span&gt;

  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;reconstruction&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Pay a special attention to the &lt;em&gt;reparametrization&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;$$\varepsilon \sim \mathcal{N}(0,\,1)$$
$$z = \varepsilon \odot \sigma + \mu$$&lt;/p&gt;

&lt;p&gt;Where $z$ is our latent vector, noise $\varepsilon$ is sampled from the normal
distribution (&lt;code&gt;randnLikeIO&lt;/code&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-2&#34;&gt;&lt;a href=&#34;#fn:fn-2&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;), and $\odot$ is elementwise product. Thanks
to this trick, we can backpropagate through a stochastic layer. See this
excellent &lt;a href=&#34;https://gregorygundersen.com/blog/2018/04/29/reparameterization/&#34;&gt;post&lt;/a&gt; for more details.  There are two differences
between variational and ordinary autoencoder training: (1) the
reparametrization and (2) the loss function, which we cover below.&lt;/p&gt;

&lt;h3 id=&#34;vae-loss-function&#34;&gt;VAE Loss Function&lt;/h3&gt;

&lt;p&gt;The loss function consists of two parts:&lt;/p&gt;

&lt;p&gt;$$ \rm{loss} = \mathbb{L}(x, \hat x) + \rm{D}_\rm{KL} \left(q_\phi(z) || p_\theta(z) \right).$$&lt;/p&gt;

&lt;p&gt;$\mathbb{L}(x, \hat x)$ is the &lt;em&gt;reconstruction loss&lt;/em&gt;.  It decreases
when the decoded output $\hat x$ is closer to the original input $x$.  This is
basically the loss of an ordinary autoencoder. For instance, it can be binary
cross-entropy loss or L2 loss.&lt;/p&gt;

&lt;p&gt;And the second term $\rm{D_{KL}}( \cdot )$ is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&#34;&gt;Kullback-Leibner
divergence&lt;/a&gt;. It tells how much the distribution $p_\theta(z)$ &lt;a href=&#34;https://blog.evjang.com/2016/08/variational-bayes.html&#34;&gt;is
different&lt;/a&gt; from the distribution $q_\phi(z)$.  Or even more
informative is to say that KL divergence tells how much information is lost if
the distribution $p_\theta$ is used to represent $q_\phi$.  From the
original &lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34;&gt;paper&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;$$ -\rm{D_{KL}}\left(q_\phi(z) || p_\theta(z) \right) =\frac 1 2 \sum_{j=1}^J \left( 1 + \log(\sigma_j^2) - \mu_j^2 - \sigma_j^2  \right).$$&lt;/p&gt;

&lt;p&gt;Therefore, the complete VAE loss is&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;vaeLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;vaeLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;recon_x&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reconLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;kld&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;reconLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bceLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;recon_x&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;kld&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sumAll&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pow&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We also include the $\beta \ge 0$ term. When $\beta = 0$ the networks is trained as an
ordinary autoencoder. When $\beta = 1$, we have a classical VAE. And when
$\beta &amp;gt; 1$, we force latent vector &lt;a href=&#34;https://openreview.net/pdf?id=Sy2fzU9gl&#34;&gt;representations
disentanglement&lt;/a&gt;. As we can see from the image below, in case of
disentanglement, there are separate latent variables that encode position,
rotation, and scale. Whereas entangled variables tend to encode all object
properties at the same time. I recommend the excellent &lt;a href=&#34;https://arxiv.org/abs/1606.05579&#34;&gt;article by Higgins et
al.&lt;/a&gt;, which is featuring some insights from neuroscience.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/articles/Higgins16.png&#34; alt=&#34;Disentangled vs entangled latent representations. &amp;lt;small&amp;gt;Image source: [Higgins et al. 2016](https://arxiv.org/abs/1606.05579).&amp;lt;/small&amp;gt;&#34; width=&#34;600px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Disentangled vs entangled latent representations. &lt;small&gt;Image source: &lt;a href=&#34;https://arxiv.org/abs/1606.05579&#34;&gt;Higgins et al. 2016&lt;/a&gt;.&lt;/small&gt;
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The binary cross-entropy loss is defined as&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;bceLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;target&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sumAll&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-10&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;target&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-10&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;target&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We add a small term $10^{-10}$ to avoid numerical errors due to $\log(0)$.&lt;/p&gt;

&lt;h2 id=&#34;visualizing-the-latent-space&#34;&gt;Visualizing the Latent Space&lt;/h2&gt;

&lt;p&gt;Here is how our latent space looks for different values of $\beta$.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/vae_beta_0.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/vae_beta_1.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/vae_beta_4.png&#34; alt=&#34;Test data distributions for different $\beta$ values.&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Test data distributions for different $\beta$ values.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;And here is how we compute that&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    (&lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;myConfig&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getArgs&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;beta = &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt; }
        &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt; }
        &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;cpt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;VAE-Aug2022-beta_%s.ht&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;beta_%s.log&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Starting training...&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnistStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Done&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Saving the trained model&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;save&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cpt&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Restoring the model&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cpt&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Test data distribution in the latent space&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Saving test dataset distribution to &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testLatentSpace&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Where&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;testLatentSpace&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FilePath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;testLatentSpace&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fn&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;testStream&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;recordPoints&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fn&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;recordPoints&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FilePath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ListT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;recordPoints&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enumerateData&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; () &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; () &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;labels&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt;
          (&lt;span style=&#34;color:#a6e22e&#34;&gt;encMu&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;shape&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;encMu&lt;/span&gt;

      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toStr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) [&lt;span style=&#34;color:#a6e22e&#34;&gt;reshape&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#a6e22e&#34;&gt;labels&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;encMu&lt;/span&gt;]
      &lt;span style=&#34;color:#a6e22e&#34;&gt;appendFile&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; ()

    &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt; () &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; ()
    &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; ()

&lt;span style=&#34;color:#a6e22e&#34;&gt;toStr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;String&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;toStr&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; [[&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;]]
        &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;unwords&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;
     &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unlines&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, let&#39;s take a walk around our latent space to get an idea how it looks like inside.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;VAE-Aug2022-beta_1.ht&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;]

        &lt;span style=&#34;color:#75715e&#34;&gt;-- 2D latent space as a Cartesian product&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;zs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [ [&lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;,&lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt; ]

        &lt;span style=&#34;color:#a6e22e&#34;&gt;decoded&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;
                    &lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;:[]&lt;/span&gt;)) &lt;span style=&#34;color:#a6e22e&#34;&gt;zs&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;writeFile&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;latent_space_2D.txt&amp;#34;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;toStr&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;decoded&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/latent_space_21x21.png&#34; alt=&#34;Some examples from 2D latent space.&#34; width=&#34;600px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Some examples from 2D latent space.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Pretty neat! We see gradual transitions between different
digits. Note that these digits are actually &lt;em&gt;generated&lt;/em&gt; by VAE.&lt;/p&gt;

&lt;h2 id=&#34;convnet-vae&#34;&gt;ConvNet VAE&lt;/h2&gt;

&lt;p&gt;While we have built a simple variational autoencoder based on
MLP (&lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;multilayer perceptron&lt;/a&gt;), nothing prevents us
from using other architectures. In fact, let&#39;s build a
&lt;a href=&#34;https://penkovsky.com/neural-networks/day5/&#34;&gt;convolutional&lt;/a&gt; VAE!&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt;
  {
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Encoder trainable parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;conv1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;conv3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fcMu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fcSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Decoder trainable parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Eq&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;myConfig&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)    &lt;span style=&#34;color:#75715e&#34;&gt;-- 1 -&amp;gt; 32 channels; 4 x 4 kernel&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)   &lt;span style=&#34;color:#75715e&#34;&gt;-- 32 -&amp;gt; 64 channels; 4 x 4 kernel&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;-- 64 -&amp;gt; 128 channels; 3 x 3 kernel&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;c1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;c2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;c3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lMu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;t1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;t2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;t3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2d&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;instance&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Randomizable&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv1&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv3&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fcMu&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fcSigma&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv1&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv2&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv3&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enc_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- Reshape vectors [batch_size x 784]&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- into grayscale images of [batch_size x 1 x 28 x 28]&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;reshape&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;]
          &lt;span style=&#34;color:#75715e&#34;&gt;-- Stride 2, padding 0&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c1&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c2&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c3&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flatten&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))

      &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enc_&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lMu&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lSigma&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
         &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reshape&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
         &lt;span style=&#34;color:#75715e&#34;&gt;-- Stride 2, padding 0&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;convTranspose2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;t1&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;convTranspose2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;t2&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;convTranspose2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;t3&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reshape&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;-- Reshape back&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And that is all we need.&lt;/p&gt;

&lt;p&gt;Here is the latent space for $\beta=1$ (normal VAE) using our CNN architecture:&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/latent_space_cnn_beta_1.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;disentanglement&#34;&gt;Disentanglement&lt;/h3&gt;

&lt;p&gt;To better illustrate how parameter $\beta$ encourages disentanglement between
latent representations, let us first increase the latent dimension to $L=10$.
For $\beta=1$ and $\beta=4$ we perform scan along each individual $z$ coordinate.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/latent_space_cnn_beta_1_z10.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/latent_space_cnn_beta_4_z10.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;Indeed, the latent space under $\beta=4$ looks more disentangled compared to
$\beta=1$. We can see e.g. that $z_1$ is the parameter that defines how
&amp;quot;light&amp;quot; or how &amp;quot;bold&amp;quot; is the digit, whereas $z_2$ controls how wide is the
digit. Whereas such individual components for $\beta=1$ are hard to identify.
For instance when $\beta=1$, $z_4$ controls not only how &amp;quot;bold&amp;quot; is the digit,
but also its shape.&lt;/p&gt;

&lt;p&gt;For more details, see this &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/blob/master/day9/data/cnn/visualize.ipynb&#34;&gt;notebook&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Find the complete project and associated data on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day9&#34;&gt;Github&lt;/a&gt;. For
suggestions about the content feel free to open a
&lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/issues&#34;&gt;new issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Variational autoencoder is a great tool in modern deep learning. Manipulating
the latent space allows us not only to &amp;quot;interpolate&amp;quot; between different images
or other objects, but also to perform &lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Peng_Generating_Diverse_Structure_for_Image_Inpainting_With_Hierarchical_VQ-VAE_CVPR_2021_paper.pdf&#34;&gt;inpainting&lt;/a&gt; (adding details to
incomplete images) or even &lt;a href=&#34;https://arxiv.org/abs/1606.05579&#34;&gt;zero shot learning&lt;/a&gt;. The last one is
crucial for the so-called &lt;em&gt;artificial general intelligence&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The loss function is important for VAE training.
If your VAE does not work as expected, the odds
are that the loss function is not implemented correctly. Also check if the
random noise $\varepsilon$ is drawn from the normal distribution.&lt;/p&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;pre&gt;
@article{penkovsky2022VAE,
 title   = &#34;Roaming The Latent Space&#34;,
 author  = &#34;Penkovsky, Bogdan&#34;,
 journal = &#34;penkovsky.com&#34;,
 year    = &#34;2022&#34;,
 month   = &#34;August&#34;,
 url     = &#34;https://penkovsky.com/neural-networks/day9/&#34;
}
&lt;/pre&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34;&gt;Auto-Encoding Variational Bayes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.evjang.com/2016/08/variational-bayes.html&#34;&gt;A Beginner&#39;s Guide to Variational Methods: Mean-Field Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1606.05579&#34;&gt;Early Visual Concept Learning with Unsupervised Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/examples/blob/main/vae/main.py&#34;&gt;Pytorch VAE Implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://magenta.tensorflow.org/music-vae&#34;&gt;Interpolating Music&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openreview.net/pdf?id=Sy2fzU9gl&#34;&gt;β-VAE: Learning Basic Visual Concepts With A Constrained Variational Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gregorygundersen.com/blog/2018/04/29/reparameterization/&#34;&gt;The Reparameterization Trick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1906.00446&#34;&gt;Generating Diverse High-Fidelity Images with VQ-VAE-2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Peng_Generating_Diverse_Structure_for_Image_Inpainting_With_Hierarchical_VQ-VAE_CVPR_2021_paper.pdf&#34;&gt;Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vincentcartillier.github.io/papers/variational-image-inpainting.pdf&#34;&gt;Variational Image Inpainting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;a-technical-sidenote&#34;&gt;A Technical Sidenote&lt;/h2&gt;

&lt;p&gt;Compared to the previous &lt;a href=&#34;https://penkovsky.com/neural-networks/day8/&#34;&gt;day&lt;/a&gt;, the &lt;code&gt;trainLoop&lt;/code&gt; is
slightly modified: First, we rescale the images between 0 and 1.  Second, we
include our new loss function in the &lt;code&gt;step&lt;/code&gt; function.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- Rescale pixel values [0, 255] -&amp;gt; [0, 1.0].&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- This is important as the sigmoid activation in decoder can&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- reach values only between 0 and 1.&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;x&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
      (&lt;span style=&#34;color:#a6e22e&#34;&gt;recon_x&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vaeForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&amp;#39;&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vaeLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;recon_x&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Print loss every 100 batches&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mod&lt;/span&gt;` &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Batch: %d | Loss: %.2f&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;)
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;train&lt;/code&gt; function now uses Adam optimizer from &lt;code&gt;Torch.Optim.CppOptim&lt;/code&gt;, which
tends to be faster compared to &lt;code&gt;mkAdam&lt;/code&gt; we used previously.  This is not very
different from mkAdam-based training, except that the learning rate is
specified as &lt;code&gt;Cpp.adamLr&lt;/code&gt; parameter and not as a &lt;code&gt;trainLoop&lt;/code&gt; parameter (ignored
when passed to &lt;code&gt;runStep&lt;/code&gt;).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;initOptimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;adamOpt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;

    (&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foldLoop&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optState&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dsetOpt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt;)
      &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optState&lt;/span&gt;) &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;dsetOpt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;workers&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;workers&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Adam optimizer parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;adamOpt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;def&lt;/span&gt;
          { &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamLr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;learningRate&lt;/span&gt;,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamBetas&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.999&lt;/span&gt;),
            &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamEps&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-8&lt;/span&gt;,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamWeightDecay&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamAmsgrad&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;
          } &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;
          &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;AdamOptions&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;learningRate&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Double&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;learningRate&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I used a compiled version instead of a notebook since the network training
worked much faster (the bottleneck was in training data mini-batches loading).
Also I have trained networks with &lt;code&gt;Torch.Optim.CppOptim&lt;/code&gt;. It is slightly faster
compared to &lt;code&gt;mkAdam&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I was also wondering why I get large values out of the encoder. It turns out
that this is because &lt;code&gt;relu&lt;/code&gt; function is unbounded. You may want to replace
&lt;code&gt;relu&lt;/code&gt; with &lt;code&gt;Torch.tanh&lt;/code&gt; and visualize the latent space again.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-2&#34;&gt;We use &lt;code&gt;sigma&lt;/code&gt; as an argument to &lt;code&gt;randnLikeIO&lt;/code&gt; so that the resulting random tensor has the same shape as &lt;code&gt;sigma&lt;/code&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Day 8: Model Uncertainty Estimation</title>
      <link>https://penkovsky.com/neural-networks/day8/</link>
      <pubDate>Sat, 23 Apr 2022 17:20:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/day8/</guid>
      <description>

&lt;p&gt;Wouldn&#39;t it be nice if the model also told us which predictions are not
reliable? Can this be done even on unseen data? The good news is yes, and even
on new, completely unseen data. It is also simple to implement in
practice.  A canonical example is in a medical setting. By measuring model
uncertainty, the doctor can learn how reliable is their AI-assisted patient&#39;s
diagnosis.  This allows the doctor to make a better informed decision whether
to trust the model or not. And potentially save someone&#39;s life.&lt;/p&gt;

&lt;p&gt;Today we build upon &lt;a href=&#34;https://penkovsky.com/neural-networks/day7/&#34;&gt;Day 7&lt;/a&gt; and we continue our
journey with Hasktorch:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We will introduce a Dropout layer.&lt;/li&gt;
&lt;li&gt;We will compute on a graphics processing unit (GPU).&lt;/li&gt;
&lt;li&gt;We will also show how to load and save models.&lt;/li&gt;
&lt;li&gt;We will train with &lt;a href=&#34;https://penkovsky.com/neural-networks/day2&#34;&gt;Adam&lt;/a&gt; optimizer.&lt;/li&gt;
&lt;li&gt;And finally we will talk about model uncertainty estimation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The complete project is also available &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day8&#34;&gt;on Github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;dropout-layer&#34;&gt;Dropout Layer&lt;/h2&gt;

&lt;p&gt;Neural networks, as any other model with many parameters, tend to overfit. By overfitting I mean
&amp;quot;&lt;a href=&#34;https://en.wikipedia.org/wiki/Overfitting&#34;&gt;fail to fit to additional data or predict future observations reliably&lt;/a&gt;&amp;quot;. Let us consider a classical example below.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/Overfitting.png&#34; alt=&#34;Overfitting. &amp;lt;small&amp;gt;Credit [Ignacio Icke](https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/480px-Overfitting.svg.png), [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)&amp;lt;/small&amp;gt;&#34; width=&#34;400px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Overfitting. &lt;small&gt;Credit &lt;a href=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/480px-Overfitting.svg.png&#34;&gt;Ignacio Icke&lt;/a&gt;, &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;CC BY-SA 4.0&lt;/a&gt;&lt;/small&gt;
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The green line is a decision boundary created by an overfitted model.
We see that the model tries to memorize every possible data point.
However, it fails to generalize. To ameliorate the situation, we perform
a so-called &lt;em&gt;regularization&lt;/em&gt;. That is a technique that helps to prevent
overfitting. In the image above, the black line is a decision boundary of a
regularized model.&lt;/p&gt;

&lt;p&gt;One of regularization techniques for artificial neural networks is called
&lt;a href=&#34;https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf&#34;&gt;dropout&lt;/a&gt;
or &lt;a href=&#34;https://en.wikipedia.org/wiki/Dilution_(neural_networks)&#34;&gt;dilution&lt;/a&gt;.
Its principle of operation is quite simple.  During neural network training, we
randomly disconnect a fraction of neurons with some probability.  It turns out
that dropout conditioning results in more reliable neural network models.&lt;/p&gt;

&lt;h2 id=&#34;a-neural-network-with-dropout&#34;&gt;A Neural Network with Dropout&lt;/h2&gt;

&lt;p&gt;The data structures &lt;code&gt;MLP&lt;/code&gt; (learnable parameters) and &lt;code&gt;MLPSpec&lt;/code&gt; (number of
neurons) remain unchanged.  However, we will need to modify the &lt;code&gt;mlp&lt;/code&gt; function
(full network) to include a Dropout layer. If we inspect
&lt;code&gt;dropout :: Double -&amp;gt; Bool -&amp;gt; Tensor -&amp;gt; IO Tensor&lt;/code&gt;
type, we see that it accepts three arguments: a &lt;code&gt;Double&lt;/code&gt; probability of
dropout, a &lt;code&gt;Bool&lt;/code&gt; that turns this layer on or off, and a data &lt;code&gt;Tensor&lt;/code&gt;.
Typically, we turn the dropout on during the training and off during the
inference stage.&lt;/p&gt;

&lt;p&gt;However, the biggest distinction between e.g. &lt;code&gt;relu&lt;/code&gt;
function and &lt;code&gt;dropout&lt;/code&gt; is that &lt;code&gt;relu :: Tensor -&amp;gt; Tensor&lt;/code&gt;
is a &lt;em&gt;pure&lt;/em&gt; function, i.e. it does not have any &#39;side-effects&#39;.
This means that every time when we call a pure function,
the result will be the same.
This is not the case with &lt;code&gt;dropout&lt;/code&gt; that relies on an
(external) random number generator, and therefore returns
a new result each time.
Therefore, its outcome is an &lt;code&gt;IO Tensor&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One has to pay a particular attention to those &lt;code&gt;IO&lt;/code&gt; functions, because they can
change the state in the external world. This can be printing text on the
screen, deleting a file, or launching missiles. Typically, we prefer to keep
functions pure whenever possible, as function purity improves the reasoning
about the program: It is a child&#39;s play to refactor (reorganize) a program
consisting only of pure functions.&lt;/p&gt;

&lt;p&gt;I find the so-called &lt;em&gt;do-notation&lt;/em&gt; to be the most natural way to combine both
pure functions and those with side-effects.  The pure equations can be grouped
under &lt;code&gt;let&lt;/code&gt; keyword(s), while the side-effects are summoned with a special &lt;code&gt;&amp;lt;-&lt;/code&gt;
glue. This is how we integrate &lt;code&gt;dropout&lt;/code&gt; in &lt;code&gt;mlp&lt;/code&gt;. Note that now the
outcome of &lt;code&gt;mlp&lt;/code&gt; also becomes an &lt;code&gt;IO Tensor&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Bool&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;isStochastic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- This subnetwork encapsulates the composition&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- of pure functions&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sub1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- The dropout is applied to the output&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- of the subnetwork&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dropout&lt;/span&gt;
          &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;   &lt;span style=&#34;color:#75715e&#34;&gt;-- Dropout probability&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;isStochastic&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- Activate Dropout when in stochastic mode&lt;/span&gt;
          (&lt;span style=&#34;color:#a6e22e&#34;&gt;sub1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;-- Apply dropout to&lt;/span&gt;
                     &lt;span style=&#34;color:#75715e&#34;&gt;-- the output of `relu` in layer 2&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Another linear layer&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Finally, logSoftmax, which is numerically more stable&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- compared to simple log(softmax(x2))&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSoftmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;x2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For model uncertainty estimation, it is empirically recommended to keep the
dropout probability anywhere between 0.1 and 0.2.&lt;/p&gt;

&lt;h2 id=&#34;computing-on-a-gpu&#34;&gt;Computing on a GPU&lt;/h2&gt;

&lt;p&gt;To transfer data onto a GPU, we use &lt;code&gt;toDevice :: ... =&amp;gt; Device -&amp;gt; a -&amp;gt; a&lt;/code&gt;.
Below are helper methods to traverse data structures containing tensors
(e.g. &lt;code&gt;MLP&lt;/code&gt;) to convert those between devices.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forall&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;HasTypes&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Device&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DType&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;device&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dtype&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;over&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;types&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;) (&lt;span style=&#34;color:#a6e22e&#34;&gt;toDevice&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;device&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forall&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;HasTypes&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;over&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;types&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;) (&lt;span style=&#34;color:#a6e22e&#34;&gt;toDevice&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Device&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;CPU&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Below is a shortcut to transfer data to &lt;code&gt;cuda:0&lt;/code&gt; device, assuming the &lt;code&gt;Float&lt;/code&gt;
type.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Device&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;CUDA&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The train loop is almost the same as in the previous post, except a few changes.
First, we convert training data to GPU with &lt;code&gt;toLocalModel&#39;&lt;/code&gt; (assuming that the
model itself was already converted to GPU).
Second, &lt;code&gt;predic &amp;lt;- mlp model isTrain input&lt;/code&gt; is an &lt;code&gt;IO&lt;/code&gt; action.
Third, we manage optimizer&#39;s internal state&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LearningRate&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ListT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;model0&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt0&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enumerateData&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;isTrain&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;label&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;isTrain&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;nllLoss&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;label&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Print loss every 100 batches&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mod&lt;/span&gt;` &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Batch: %d | Loss: %.2f&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;)
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;model0&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt0&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We also modify the &lt;code&gt;train&lt;/code&gt; function to use Adam optimizer with &lt;code&gt;mkAdam&lt;/code&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;0&lt;/code&gt; is the initial iteration number (then internally increased by the optimizer).&lt;/li&gt;
&lt;li&gt;We provide &lt;code&gt;beta1&lt;/code&gt; and &lt;code&gt;beta2&lt;/code&gt; values.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;flattenParameters net0&lt;/code&gt; are needed to get the shapes of the trained parameters momenta. See also &lt;a href=&#34;https://penkovsky.com/neural-networks/day2&#34;&gt;Day 2&lt;/a&gt; for more details.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    (&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foldLoop&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optState&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dsetOpt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt;)
      &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optState&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;dsetOpt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;workers&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;workers&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-4&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- Learning rate&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mkAdam&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta2&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;flattenParameters&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;)
    &lt;span style=&#34;color:#a6e22e&#34;&gt;beta1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;beta2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.999&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is a function to get model accuracy:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;accuracy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ListT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;accuracy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enumerateData&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;)
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;total&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;labels&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Compute predictions&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;argmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt; 
                     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;

      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;correct&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt;
                        &lt;span style=&#34;color:#75715e&#34;&gt;-- Sum those elements&lt;/span&gt;
                        &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sumDim&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int64&lt;/span&gt;
                        &lt;span style=&#34;color:#75715e&#34;&gt;-- Find correct predictions&lt;/span&gt;
                        &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;eq&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;labels&lt;/span&gt;

      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;shape&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;correct&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;total&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;-- When done folding, compute the accuracy&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;total&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fromIntegral&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fromIntegral&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;total&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Initial errors and totals&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;testAccuracy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;testAccuracy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;testStream&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;accuracy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Below we provide the MLP specification: number of neurons in each layer.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;saving-and-loading-the-model&#34;&gt;Saving and Loading the Model&lt;/h2&gt;

&lt;p&gt;Before we can save the model, we have to make the weight tensors dependent
first:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;save&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FilePath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;save&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;save&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toDependent&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flattenParameters&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The inverse is true for model loading. We also replace
parameters in a newly generated model with the one we
have just loaded:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FilePath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fpath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;params&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mapM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;makeIndependent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fpath&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;replaceParameters&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;params&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Load the MNIST data:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Train a new model:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- A train &amp;#34;loader&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt; }
&lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnistStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Saving the model:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;save&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weights.bin&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To load a pretrained model:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weights.bin&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can verify the model&#39;s accuracy:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- A test &amp;#34;loader&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt; }

&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testAccuracy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accuracy &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;Accuracy 0.9245&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The accuracy is not tremendous, but it can be improved by introducing
&lt;a href=&#34;https://penkovsky.com/neural-networks/day4&#34;&gt;batch norm&lt;/a&gt;,
&lt;a href=&#34;https://penkovsky.com/neural-networks/day5&#34;&gt;convolutional layers&lt;/a&gt;, and
training longer. We are about to discuss model uncertainty estimation and
this accuracy is good enough.&lt;/p&gt;

&lt;h2 id=&#34;predictive-entropy&#34;&gt;Predictive Entropy&lt;/h2&gt;

&lt;p&gt;Model uncertainties are obtained as:&lt;/p&gt;

&lt;p&gt;$$
\begin{equation}
\mathbb{H}(y|\mathbf{x}) = -\sum_c p(y = c|\mathbf{x}) \log p(y = c|\mathbf{x}),
\end{equation}
$$&lt;/p&gt;

&lt;p&gt;where $y$ is label, $\mathbf{x}$ – input image, $c$ – class, $p$ – probability.&lt;/p&gt;

&lt;p&gt;We call $\mathbb{H}$ &lt;a href=&#34;https://towardsdatascience.com/2-easy-ways-to-measure-your-image-classification-models-uncertainty-1c489fefaec8&#34;&gt;predictive entropy&lt;/a&gt;.
And it is the very dropout technique that helps us to estimate those
uncertainties.  All we need to do is to collect several predictions in the
stochastic mode (i.e. dropout enabled) and apply the formula from above.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;predictiveEntropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;predictiveEntropy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predictions&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epsilon&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-45&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;meanDim&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predictions&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epsilon&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;negate&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sumAll&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;visualizing-softmax-predictions&#34;&gt;Visualizing Softmax Predictions&lt;/h2&gt;

&lt;p&gt;To get a better feeling what model outputs look like, it would be nice to
visualize the softmax output as a histogram or a bar chart. For instance&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;bar&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apples&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;oranges&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kiwis&amp;#34;&lt;/span&gt;] [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;apples  ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 50.00
oranges ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 100.00
kiwis   ▉▉▉▉▉▉▉▉▉▉▉▉▋ 25.00&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, we would like to display an image, the predictive entropy, and the softmax
output, followed by prediction and ground truth.  To transform logSoftmax into
softmax, we use the following identity:&lt;/p&gt;

&lt;p&gt;$$
\begin{equation}
e^{\ln(\rm{softmax}(x))} = \rm{softmax}(x),
\end{equation}
$$&lt;/p&gt;

&lt;p&gt;that is &lt;code&gt;softmax = exp. logSoftmax&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;repeatN&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;preds&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forM&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;repeatN&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- logSoftmax -&amp;gt; softmax&lt;/span&gt;
                                     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predictiveEntropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;preds&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Select only the images with high entropy&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;dispImage&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;putStr&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entropy &amp;#34;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- exp. logSoftmax = softmax&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;bar&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;]) (&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flattenAll&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; [&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;])
      &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Model        : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;argmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt;)
      &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ground Truth : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note that below we show only some of those images the model is uncertain about
(entropy &amp;gt; 0.9)&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; {&lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;}
&lt;span style=&#34;color:#a6e22e&#34;&gt;forM_&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getItem&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;     +%       
     %        
     *        
    #-  +%%=  
    %  %%  %  
    % %+   #  
    % %    *  
    %  % :%   
    #*:=%#    
     -%=.     
              
              
Entropy 1.044228
0 ▉▏ 0.01
1 ▏ 0.00
2 ▋ 0.01
3 ▏ 0.00
4 ▉ 0.01
5 ▍ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.70
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.21
9 ▉▉▉▋ 0.05
Model        : Tensor Int64 [1] [ 6]
Ground Truth : Tensor Int64 [1] [ 6]
              
              
      .#%#.   
    %%+:      
     %        
     %..      
    ##-#%.    
         -%   
          :%  
           +  
    -     .%  
    @%+*%%+   
              
              
Entropy 1.2909155
0 ▏ 0.00
1 ▏ 0.00
2 ▍ 0.00
3 ▉▉▉▉▉▉▉▉ 0.07
4 ▏ 0.00
5 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.44
6 ▏ 0.00
7 ▍ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.47
9 ▉▏ 0.01
Model        : Tensor Int64 [1] [ 8]
Ground Truth : Tensor Int64 [1] [ 5]
              
              
              
     =-     = 
     #-    =# 
     %-    #  
    +%     %  
    %.    .%  
   ##     .*  
   %%%%%#%#.  
   .      %   
              
              
              
Entropy 1.3325933
0 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.19
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.46
5 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▊ 0.18
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▊ 0.16
7 ▏ 0.00
8 ▏ 0.00
9 ▏ 0.00
Model        : Tensor Int64 [1] [ 4]
Ground Truth : Tensor Int64 [1] [ 4]
              
              
       *:     
     :%%*     
    #- -+     
       -      
       #      
      +:      
      #    =. 
     #.  =%:  
     *.*%-    
    #%%:      
              
              
Entropy 1.2533671
0 ▉ 0.01
1 ▉▉▍ 0.03
2 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.38
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.54
4 ▏ 0.00
5 ▋ 0.01
6 ▏ 0.00
7 ▏ 0.00
8 ▉▉▋ 0.03
9 ▏ 0.00
Model        : Tensor Int64 [1] [ 3]
Ground Truth : Tensor Int64 [1] [ 2]
              
              
              
     +##-     
     *   :    
     =        
     %  =     
     %  %     
     -= @     
      = %     
        %     
        %     
        %     
              
Entropy 0.9308149
0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▉ 0.01
4 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.29
5 ▍ 0.00
6 ▏ 0.00
7 ▎ 0.00
8 ▉▎ 0.02
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.67
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
              
        #     
      % #     
      % *     
      % =     
     %%@%     
     *  %     
        %     
        %     
        %     
        =     
              
Entropy 1.39582
0 ▏ 0.00
1 ▉▍ 0.01
2 ▏ 0.00
3 ▉▉▉▉▉▊ 0.06
4 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.48
5 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▋ 0.17
6 ▉▉▉▉ 0.04
7 ▏ 0.00
8 ▉▋ 0.02
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.22
Model        : Tensor Int64 [1] [ 4]
Ground Truth : Tensor Int64 [1] [ 4]
              
              
              
      .#%@    
      %%%%=   
     +%. %#   
      %%%%:   
       %%%    
      -%%     
     -%%      
    .%%       
    %%-       
    %*        
              
Entropy 1.0009595
0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▉▊ 0.02
4 ▏ 0.00
5 ▎ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.35
8 ▉ 0.01
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.62
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
              
              
     %##%     
    :%+%%.    
    -%  %:    
    -%  %+    
     +  %+    
        %+    
        %+    
        %#    
        %%    
        .+    
Entropy 1.0057298
0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▉▉▍ 0.03
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.33
8 ▏ 0.00
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.63
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 7]
              
              
              
   %%%%%      
      .%      
      %.      
    =%%%+     
    %   %# -  
         %%.  
        *%-   
       %:%    
      %-%=    
      %%-     
              
Entropy 1.0500848
0 ▉▉▉▉▍ 0.07
1 ▎ 0.00
2 ▎ 0.00
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.79
4 ▉▉▊ 0.04
5 ▉▉▉▎ 0.05
6 ▏ 0.00
7 ▍ 0.01
8 ▎ 0.00
9 ▉▊ 0.03
Model        : Tensor Int64 [1] [ 3]
Ground Truth : Tensor Int64 [1] [ 3]
              
              
              
     :*       
      %       
      %%      
      :%      
       %*     
       +*     
        %     
        %     
        %     
        =     
              
Entropy 1.590256
0 ▏ 0.00
1 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.36
2 ▏ 0.00
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.10
4 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.32
5 ▉▉▉▎ 0.02
6 ▏ 0.00
7 ▎ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.12
9 ▉▉▉▉▉▉▉▉▉▉▍ 0.07
Model        : Tensor Int64 [1] [ 1]
Ground Truth : Tensor Int64 [1] [ 1]
              
              
              
    =   =     
    %%%%%.    
      :%%     
       %*     
    .%%%%%%%%+
      %%%*:   
      %%      
      %%      
      %%      
      %%      
              
Entropy 0.9592192
0 ▏ 0.00
1 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▊ 0.28
2 ▋ 0.01
3 ▍ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▍ 0.01
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.67
8 ▏ 0.00
9 ▉▉▏ 0.03
Model        : Tensor Int64 [1] [ 7]
Ground Truth : Tensor Int64 [1] [ 7]
              
              
              
      =%#*    
    :%%- .#   
    %%   :%   
   .%    #=   
         %    
       %%#    
     -%%%%    
     %%%.%    
     #%  *+   
          :   
              
Entropy 1.0005924
0 ▍ 0.00
1 ▏ 0.00
2 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.48
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.47
8 ▉▉▉▋ 0.03
9 ▉▎ 0.01
Model        : Tensor Int64 [1] [ 2]
Ground Truth : Tensor Int64 [1] [ 2]
              
              
      -       
    :%%%-     
   :%   %     
   +:   :%-   
  -%     *%   
  *:      %*  
  ==      *%  
   *      :%  
   #::..:*%%  
    :%*%%-:   
              
              
Entropy 1.3647958
0 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.50
1 ▏ 0.00
2 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.23
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.23
4 ▏ 0.00
5 ▉▉▉▏ 0.03
6 ▏ 0.00
7 ▏ 0.00
8 ▏ 0.00
9 ▉▍ 0.01
Model        : Tensor Int64 [1] [ 0]
Ground Truth : Tensor Int64 [1] [ 0]
              
              
              
      %-      
       :%     
        #     
    -%#%*     
   ::  @%.    
   *  %  #.   
    %%    %   
           %  
            % 
              
              
Entropy 1.1518966
0 ▉▉▉▎ 0.06
1 ▍ 0.01
2 ▊ 0.01
3 ▏ 0.00
4 ▉▉▊ 0.05
5 ▏ 0.00
6 ▏ 0.00
7 ▏ 0.00
8 ▍ 0.01
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.86
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 2]
              
              
              
    =%%%%+    
   .#. =#%    
   %*   %#    
   #.   .%    
   .#   *%:   
    .%%%- =   
           #  
           #  
      -%% =%  
       =%%#   
              
Entropy 1.1256037
0 ▉▊ 0.02
1 ▏ 0.00
2 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.29
3 ▎ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.59
9 ▉▉▉▉▉▉▉▉▎ 0.10
Model        : Tensor Int64 [1] [ 8]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
      --%:    
     .   %    
         %:   
     ** .%    
      *%%.    
      %%*%    
     %*  %    
     %   %    
     %  %:    
     %%%:     
              
              
Entropy 1.0862491
0 ▏ 0.00
1 ▉▉▋ 0.03
2 ▉▉▉▉▉ 0.05
3 ▏ 0.00
4 ▏ 0.00
5 ▋ 0.01
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.42
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.50
9 ▏ 0.00
Model        : Tensor Int64 [1] [ 8]
Ground Truth : Tensor Int64 [1] [ 8]
              
              
              
        %%    
        %%    
       *%#    
      :%%-    
      .%%     
      %%+     
     +%%      
     *%+      
     =%=      
      =:      
              
Entropy 1.0085171
0 ▏ 0.00
1 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.81
2 ▎ 0.00
3 ▍ 0.01
4 ▎ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▏ 0.16
8 ▎ 0.01
9 ▍ 0.01
Model        : Tensor Int64 [1] [ 1]
Ground Truth : Tensor Int64 [1] [ 1]
              
              
              
    -@@:      
   -#  +:     
   #-   %     
    %: ..-    
     +%=*%    
       .%%    
        %*    
        %%    
        %%    
        %.    
              
Entropy 1.5438546
0 ▏ 0.00
1 ▏ 0.00
2 ▉▉▉▉ 0.03
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.14
4 ▉▉▉▉▉▊ 0.05
5 ▊ 0.01
6 ▏ 0.00
7 ▉▉▉▉▊ 0.04
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.31
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.42
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Reflecting on softmax outputs above we can state that&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Softmax output alone is not enough to estimate the model uncertainty. We can observe wrong predictions even when the margin between the top and second-best guess is large.&lt;/li&gt;
&lt;li&gt;Sometimes prediction and ground truth coincide. So why the entropy is high? We actually need to inspect such cases in more details.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first point is well illustrated by this example:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;              
              
              
      %-      
       :%     
        #     
    -%#%*     
   ::  @%.    
   *  %  #.   
    %%    %   
           %  
            % 
              
              
Entropy 1.1518966
0 ▉▉▉▎ 0.06
1 ▍ 0.01
2 ▊ 0.01
3 ▏ 0.00
4 ▉▉▊ 0.05
5 ▏ 0.00
6 ▏ 0.00
7 ▏ 0.00
8 ▍ 0.01
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.86
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 2]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To illustrate the last point, let us take a closer look at cases with high
entropy. By running several realizations of the stochatic model, we can verify
if the model has any &amp;quot;doubt&amp;quot; by selecting different answers.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;repeatN&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pred&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forM&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;repeatN&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- logSoftmax -&amp;gt; softMax&lt;/span&gt;
                                     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predictiveEntropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;pred&amp;#39;&lt;/span&gt;

  &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;dispImage&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStr&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entropy &amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;forM_&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred&amp;#39;&lt;/span&gt; ( &lt;span style=&#34;color:#a6e22e&#34;&gt;\pred&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bar&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;]) (&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flattenAll&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; [&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;]) )
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Model        : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;argmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ground Truth : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first example from above (dataset index &lt;code&gt;11&lt;/code&gt;) gives this:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&amp;#39;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getItem&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt;) &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;              
              
     +%       
     %        
     *        
    #-  +%%=  
    %  %%  %  
    % %+   #  
    % %    *  
    %  % :%   
    #*:=%#    
     -%=.     
              
              
Entropy 1.1085687

0 ▎ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.90
7 ▏ 0.00
8 ▉▉▉▉▉▍ 0.10
9 ▏ 0.00

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▋ 0.01
1 ▏ 0.00
2 ▏ 0.00
3 ▎ 0.01
4 ▉▉▉▏ 0.05
5 ▏ 0.00
6 ▉▉▎ 0.04
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.86
9 ▉▎ 0.02

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▉▉▉▉▍ 0.04
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▉▉▉▉▉▉▉▉▉▉▏ 0.09
5 ▉▏ 0.01
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▋ 0.30
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.12
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.43

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▉▏ 0.02
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▏ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.80
7 ▏ 0.00
8 ▉▉▉▉▉▉▋ 0.10
9 ▉▉▉▉▎ 0.07

0 ▉▉▉▉▍ 0.04
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▉▉▉▉▉▉▉▉▉▉▏ 0.09
5 ▉▏ 0.01
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▋ 0.30
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.12
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.43
Model        : Tensor Int64 [1] [ 6]
Ground Truth : Tensor Int64 [1] [ 6]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Wow! The model sometimes &amp;quot;sees&amp;quot; digit 6, sometimes digit 8, and sometimes digit
9! For the contrast, here is how predictions with low entropy typically look
like.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&amp;#39;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getItem&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt;) &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;              
              
              
   #%%*****   
      ::: %   
         %:   
        :%    
        #:    
       :%     
       %.     
      #=      
     :%.      
     =#       
Entropy 4.8037423e-4

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00
Model        : Tensor Int64 [1] [ 7]
Ground Truth : Tensor Int64 [1] [ 7]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The model always &amp;quot;sees&amp;quot; digit 7. That is why the predictive entropy is low.
Note that the results are model-dependent. Therefore we also
share the weights for reproducibility. However, every realization of the
stochastic model might still be different, especially in those cases where the
entropy is high.&lt;/p&gt;

&lt;p&gt;Find the complete project on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day8&#34;&gt;Github&lt;/a&gt;. For suggestions about the content
feel free to open a
&lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/issues&#34;&gt;new issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;I hope you are now convinced that model&#39;s uncertainty estimation is an invaluable tool. This simple technique is essential when applying deep learning for real-life decision making. This post also develops on how to use Hasktorch library in practice. Notably, it is very straightforward to run computations on a GPU. Overall, Hasktorch can be used for real-world deep learning. The code is well-structured and relies on a mature Torch library. On the other hand, it would be desirable to capture high-level patterns so that the user does not need to think about low-level concepts such as dependent and independent tensors, for example. The end user should be able to simply apply &lt;code&gt;save net &amp;quot;weights.bin&amp;quot;&lt;/code&gt; and &lt;code&gt;mynet &amp;lt;- load &amp;quot;weights.bin&amp;quot;&lt;/code&gt; without any indirections. The same reasoning applies to the &lt;code&gt;trainLoop&lt;/code&gt;, i.e. the user does not need to reinvent it every time. Eventually, a higher-level package on top of Hasktorch should capture the best practices, similar to &lt;a href=&#34;https://www.pytorchlightning.ai/&#34;&gt;PyTorch Lightning&lt;/a&gt; or &lt;a href=&#34;https://github.com/fastai/fastai&#34;&gt;fast.ai&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now your turn: explore image recognition with &lt;a href=&#34;https://github.com/hasktorch/hasktorch/blob/master/examples/alexNet/AlexNet.hs&#34;&gt;AlexNet&lt;/a&gt; convolutional network and have fun!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit 27/04/2022:&lt;/strong&gt; The original version from 23/04 did not correctly handle
optimizer&#39;s internal state. Therefore, &lt;code&gt;train&lt;/code&gt; and &lt;code&gt;trainLoop&lt;/code&gt; were fixed.
You will find the updated notebook on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day8&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1207.0580.pdf&#34;&gt;Improving neural networks by preventing
co-adaptation of feature detectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf&#34;&gt;Dropout: A Simple Way to Prevent Neural Networks from
Overfitting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://xuwd11.github.io/Dropout_Tutorial_in_PyTorch/&#34;&gt;Tutorial: Dropout as Regularization and Bayesian Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/2-easy-ways-to-measure-your-image-classification-models-uncertainty-1c489fefaec8&#34;&gt;Two Simple Ways To Measure Your Model’s Uncertainty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf&#34;&gt;Uncertainty in Deep Learning, Yarin Gal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hasktorch/hasktorch/tree/master/examples/alexNet&#34;&gt;AlexNet example in Hasktorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;Previously, there was no need to handle &lt;code&gt;GD&lt;/code&gt; optimizer&#39;s internal state. This is not true in a more general case. For instance, &lt;a href=&#34;https://hasktorch.github.io/hasktorch/html/src/Torch.Optim.html#adam&#34;&gt;Adam&lt;/a&gt; keeps track of momenta and iterations for bias adjustment.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Day 7: Real World Deep Learning</title>
      <link>https://penkovsky.com/neural-networks/day7/</link>
      <pubDate>Mon, 18 Apr 2022 22:55:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/day7/</guid>
      <description>

&lt;p&gt;So far we have explored neural networks almost in the vacuum. Although we have
provided some illustrations for better clarity, relying an existing framework
would allow us to benefit from the knowledge of previous contributors. One such
framework is called &lt;a href=&#34;https://github.com/hasktorch/hasktorch&#34;&gt;Hasktorch&lt;/a&gt;. Among
the practical reasons to use Hasktorch is relying on a mature &lt;a href=&#34;https://pytorch.org/docs/stable/torch.html&#34;&gt;Torch&lt;/a&gt;
Tensor library. Another good reason is strong GPU acceleration, which is
necessary for almost any serious deep learning project. Finally, standard
interfaces rather than reinventing the wheel will help to reduce the
boilerplate.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Fun fact: one of Hasktorch
&lt;a href=&#34;https://github.com/hasktorch/hasktorch/graphs/contributors&#34;&gt;contributors&lt;/a&gt; is
Adam Paszke, the original author of Pytorch.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Today&#39;s post is also based on&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;Day 2: What Do Hidden Layers Do?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day4/&#34;&gt;Day 4: The Importance Of Batch Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day5/&#34;&gt;Day 5: Convolutional Neural Networks Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The source code from this post is available &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day7&#34;&gt;on Github&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;the-basics&#34;&gt;The Basics&lt;/h2&gt;

&lt;p&gt;The easiest way &lt;a href=&#34;https://github.com/hasktorch/hasktorch#getting-started&#34;&gt;to start&lt;/a&gt;
with Hasktorch is via &lt;a href=&#34;https://www.docker.com/get-started/&#34;&gt;Docker&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;  docker run --gpus all -it --rm -p &lt;span style=&#34;color:#ae81ff&#34;&gt;8888&lt;/span&gt;:8888 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    -v &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;pwd&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;:/home/ubuntu/data &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    htorch/hasktorch-jupyter:latest-cu11&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, you may open &lt;code&gt;localhost:8888&lt;/code&gt; in your browser to access &lt;a href=&#34;https://jupyter.org/&#34;&gt;Jupyterlab&lt;/a&gt;
notebooks. Note that you need to select &lt;code&gt;Haskell&lt;/code&gt; kernel when creating a new notebook.&lt;/p&gt;

&lt;p&gt;If you have never used Torch library before, you may also want to review this
&lt;a href=&#34;https://hasktorch.github.io/tutorial/02-tensors.html&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;mnist-example&#34;&gt;MNIST Example&lt;/h2&gt;

&lt;p&gt;Let&#39;s take the familiar MNIST example and see how it can be implemented
&lt;a href=&#34;https://github.com/hasktorch/hasktorch/tree/master/examples/mnist-mlp&#34;&gt;in Hasktorch&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;imports&#34;&gt;Imports&lt;/h3&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE DeriveAnyClass #-}&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE DeriveGeneric #-}&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE MultiParamTypeClasses #-}&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE RecordWildCards #-}&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE ScopedTypeVariables #-}&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Control.Exception.Safe
  ( &lt;span style=&#34;color:#66d9ef&#34;&gt;SomeException&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;),
    &lt;span style=&#34;color:#a6e22e&#34;&gt;try&lt;/span&gt;,
  )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Control.Monad ( &lt;span style=&#34;color:#a6e22e&#34;&gt;forM_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt;, (&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt;) )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Control.Monad.Cont ( &lt;span style=&#34;color:#66d9ef&#34;&gt;ContT&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;) )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; GHC.Generics
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Pipes &lt;span style=&#34;color:#66d9ef&#34;&gt;hiding&lt;/span&gt; ( (&lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt;) )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;qualified&lt;/span&gt; Pipes.Prelude &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; P
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Torch
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Torch.Serialize
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Torch.Typed.Vision ( &lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;qualified&lt;/span&gt; Torch.Vision &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; V
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Prelude &lt;span style=&#34;color:#66d9ef&#34;&gt;hiding&lt;/span&gt; ( &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; )&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The most notable import is the &lt;code&gt;Torch&lt;/code&gt; module itself. There are also related
helpers such &lt;code&gt;Torch.Vision&lt;/code&gt; to handle image data. The function &lt;code&gt;initMnist&lt;/code&gt; has
type&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MnistData&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;MnistData&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The function is loading MNIST train and test datasets, similar to &lt;code&gt;loadMNIST&lt;/code&gt;
from previous posts.&lt;/p&gt;

&lt;p&gt;It might be also useful to pay attention to
&lt;a href=&#34;https://hackage.haskell.org/package/pipes&#34;&gt;&lt;code&gt;Pipes&lt;/code&gt;&lt;/a&gt; module. It is an
alternative to previously used &lt;code&gt;Streamly&lt;/code&gt;, which also allows building
streaming components.&lt;/p&gt;

&lt;p&gt;We also import functions from &lt;code&gt;Control.Monad&lt;/code&gt;, which are useful for IO
operations.&lt;/p&gt;

&lt;p&gt;Finally, we hide &lt;code&gt;exp&lt;/code&gt; function in favor of Torch &lt;code&gt;exp&lt;/code&gt;, which operates on
tensors (arrays)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; rather than floating point scalars:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;defining-neural-network-architecture&#34;&gt;Defining Neural Network Architecture&lt;/h3&gt;

&lt;p&gt;First we define a neural network data structure that contains trained
parameters (neural network weights). In the simplest case, it can be a
multilayer perceptron (MLP).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This MLP contains three linear layers. Next, we may define a data structure
that specifies the number of neurons in each layer:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Eq&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, we can define a neural network as a function, similar as we did on
&lt;a href=&#34;https://penkovsky.com/neural-networks/day5/&#34;&gt;Day 5&lt;/a&gt; with a &amp;quot;reversed&amp;quot; composition operator
&lt;code&gt;(~&amp;gt;)&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;g&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;g&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Layer 1&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Layer 2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Layer 3&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSoftmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We finish by a (log) softmax layer reducing the tensor&#39;s dimension 1 (&lt;code&gt;Dim 1&lt;/code&gt;).
Derivatives of &lt;code&gt;linear&lt;/code&gt;, &lt;code&gt;relu&lt;/code&gt;, and &lt;code&gt;logSoftmax&lt;/code&gt; are already handled by Torch
library.&lt;/p&gt;

&lt;h3 id=&#34;initial-weights&#34;&gt;Initial Weights&lt;/h3&gt;

&lt;p&gt;How do we generate initial random weights? As you may remember from
&lt;a href=&#34;https://penkovsky.com/neural-networks/day5/&#34;&gt;Day 5&lt;/a&gt;, we could create a function such as this one:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;randNetwork&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
  &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randLinear&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Sz2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randLinear&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Sz2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randLinear&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Sz2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;
     &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; {  &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt;
          , &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt;
          , &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt;
          }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In our example we do almost the same, except we benefit from
&lt;a href=&#34;http://learnyouahaskell.com/functors-applicative-functors-and-monoids&#34;&gt;applicative functors&lt;/a&gt; and
&lt;a href=&#34;https://github.com/hasktorch/hasktorch/blob/0269df6b3c7fdfa3f25a8c8e315b6188214c57ca/hasktorch/src/Torch/NN.hs#L201&#34;&gt;&lt;code&gt;Randomizable&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;instance&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Randomizable&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt;)
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt;)
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We say above that &lt;code&gt;MLP&lt;/code&gt; is an instance of the &lt;code&gt;Randomizable&lt;/code&gt; typeclass,
parametrized by &lt;code&gt;MLPSpec&lt;/code&gt;. All we needed to define this instance was to
implement a &lt;code&gt;sample&lt;/code&gt; function. To generate initial MLP weights, later we can
simply write&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;train-loop&#34;&gt;Train Loop&lt;/h3&gt;

&lt;p&gt;The core of the neural network training is &lt;code&gt;trainLoop&lt;/code&gt;, which enables a single
training &amp;quot;epoch&amp;quot;. Let us first inspect its type signature.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ListT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This signifies that the function accepts an initial neural network
configuration, an optimizer, and a dataset. The optimizer can be a gradient
descent (GD), Adam, or other
&lt;a href=&#34;https://hasktorch.github.io/hasktorch/html/Torch-Optim.html&#34;&gt;optimizer&lt;/a&gt;.
The result of the function is a new MLP configuration, as a result of IO call.
IO is necessary for instance if we want to print the loss after each iteration.
Now, let&#39;s take a look at the implementation:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enumerateData&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;First, we enumerate the dataset with &lt;code&gt;enumerateData&lt;/code&gt;. Then, we iterate over (fold)
the batches. The &lt;code&gt;step&lt;/code&gt; function is an analogy to a step in the gradient descent
algorithm:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;label&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;nllLoss&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;label&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Print loss every 50 batches&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mod&lt;/span&gt;` &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Iteration: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; | Loss: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt;
      (&lt;span style=&#34;color:#a6e22e&#34;&gt;newParam&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-3&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newParam&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We calculate a
&lt;a href=&#34;https://hasktorch.github.io/hasktorch/html/Torch-Functional.html#v:nllLoss-39-&#34;&gt;negative log likelihood loss&lt;/a&gt;
&lt;code&gt;nllLoss&#39;&lt;/code&gt; between the ground truth label and the output
of our MLP. Note that &lt;code&gt;model&lt;/code&gt; is the parameter, i.e. weights of the MLP
network. Then, we take advantage of the iteration number &lt;code&gt;iter&lt;/code&gt; to print the
loss every 50 iterations. Finally, we perform a gradient descent step using our
optimizer via
&lt;code&gt;runStep :: ... =&amp;gt; model -&amp;gt; optimizer -&amp;gt; Loss -&amp;gt; LearningRate -&amp;gt; IO (model, optimizer)&lt;/code&gt;
and keep only new model &lt;code&gt;newParam&lt;/code&gt;. The learning rate here is &lt;code&gt;1e-3&lt;/code&gt;, but can
be eventually changed.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;done&lt;/code&gt; function is (trivial in this case) finalization of &lt;code&gt;foldM&lt;/code&gt;
iterations over the MLP model and &lt;code&gt;begin&lt;/code&gt; are the initial weights (we use &lt;code&gt;pure&lt;/code&gt;
to satisfy the type
&lt;a href=&#34;https://hackage.haskell.org/package/pipes-4.3.16/docs/src/Pipes.Prelude.html#foldM&#34;&gt;&lt;code&gt;m x&lt;/code&gt;&lt;/a&gt;
requirement).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;putting-it-all-together&#34;&gt;Putting It All Together&lt;/h3&gt;

&lt;p&gt;The remaining part is simple. We load the data into batches,
specify the number of neurons in our MLP, choose an optimizer,
and initialize the random weights.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; {&lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt;}
      &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; {&lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;}
      &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GD&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, we train the network for 5 epochs:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foldLoop&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\model&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, we may examine the model on test images&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;forM_&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;displayImages&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getItem&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnist&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For this purpose may use a function such as&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImages&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImages&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;dispImage&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Model        : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;argmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ground Truth : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;running&#34;&gt;Running&lt;/h3&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;Iteration: 0 | Loss: Tensor Float []  12.3775   
Iteration: 50 | Loss: Tensor Float []  1.0952   
Iteration: 100 | Loss: Tensor Float []  0.5626   
Iteration: 150 | Loss: Tensor Float []  0.6660   
Iteration: 200 | Loss: Tensor Float []  0.4771   
Iteration: 0 | Loss: Tensor Float []  0.5012   
Iteration: 50 | Loss: Tensor Float []  0.4058   
Iteration: 100 | Loss: Tensor Float []  0.3095   
Iteration: 150 | Loss: Tensor Float []  0.4237   
Iteration: 200 | Loss: Tensor Float []  0.3433   
Iteration: 0 | Loss: Tensor Float []  0.3671   
Iteration: 50 | Loss: Tensor Float []  0.3206   
Iteration: 100 | Loss: Tensor Float []  0.2467   
Iteration: 150 | Loss: Tensor Float []  0.3420   
Iteration: 200 | Loss: Tensor Float []  0.2737   
Iteration: 0 | Loss: Tensor Float []  0.3054   
Iteration: 50 | Loss: Tensor Float []  0.2779   
Iteration: 100 | Loss: Tensor Float []  0.2161   
Iteration: 150 | Loss: Tensor Float []  0.2933   
Iteration: 200 | Loss: Tensor Float []  0.2289   
Iteration: 0 | Loss: Tensor Float []  0.2693   
Iteration: 50 | Loss: Tensor Float []  0.2530   
Iteration: 100 | Loss: Tensor Float []  0.1979   
Iteration: 150 | Loss: Tensor Float []  0.2616   
Iteration: 200 | Loss: Tensor Float []  0.1986   
              
              
              
              
   #%%*****   
      ::: %   
         %:   
        :%    
        #:    
       :%     
       %.     
      #=      
     :%.      
     =#       
Model        : Tensor Int64 [1] [ 7]
Ground Truth : Tensor Int64 [1] [ 7]
              
              
     %%%#     
    %#  %     
    .  #%     
      :%:     
      %+      
     *%       
     %=       
    %%        
    %%%%++%%%=
     ==%%=.   
              
              
Model        : Tensor Int64 [1] [ 2]
Ground Truth : Tensor Int64 [1] [ 2]
              
              
        .-    
        =     
        %     
       .#     
       =:     
       @      
       #      
      ++      
      %:      
      %       
              
              
Model        : Tensor Int64 [1] [ 1]
Ground Truth : Tensor Int64 [1] [ 1]
              
              
       %.     
      *%-     
     %%%%#    
    :%%+:%-   
    %%   -%.  
    %    .@+  
    %    %%.  
    %   #%*   
    %%%%%%    
    :%%%-     
              
              
Model        : Tensor Int64 [1] [ 0]
Ground Truth : Tensor Int64 [1] [ 0]
              
              
              
     =    +   
     %    %   
    +.    %   
    %    %:   
    +    %    
    %--=*%    
     :: +%    
        =%    
        =%    
        *     
              
Model        : Tensor Int64 [1] [ 4]
Ground Truth : Tensor Int64 [1] [ 4]
              
              
              
        %@    
        @:    
       =@     
       @%     
       @      
      :@      
      %#      
      @       
      @       
      +       
              
Model        : Tensor Int64 [1] [ 1]
Ground Truth : Tensor Int64 [1] [ 1]
              
              
              
     %     %  
    %     %   
   +#    -+   
   +%*::*%    
    :%==%+    
        %     
       ++     
       %      
       %-+    
       *      
              
Model        : Tensor Int64 [1] [ 4]
Ground Truth : Tensor Int64 [1] [ 4]
              
              
              
      +       
     %%+      
    .%*%%     
    -: *%     
    -#-%%.    
     %% =#    
         %    
         .%   
          #.  
           %  
              
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
         ..=. 
      .%%%%%% 
     ::%+:    
    %         
   %          
   %=         
   %%%%%%+    
     :%%%%    
      %%%%    
       %#     
              
              
Model        : Tensor Int64 [1] [ 6]
Ground Truth : Tensor Int64 [1] [ 5]
              
              
              
              
      +%%%#   
    +%*  .%%  
   :%.  .#%+  
    %@%%%%*   
       +%-    
      -%#     
      %%      
     %%       
     %=       
     @        
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
       ==:    
     %%**%%   
    .%    %:  
    *-    +#  
    %     :#  
    #     :#  
   -#     +#  
   -#    .%   
    #   +%:   
    #%%%%=    
              
              
Model        : Tensor Int64 [1] [ 0]
Ground Truth : Tensor Int64 [1] [ 0]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;See the complete project on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day7&#34;&gt;Github&lt;/a&gt;. For suggestions about the content
feel free to open a
&lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/issues&#34;&gt;new issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Today we have learned the basics of Hasktorch library. The most important is that
the principles from our previous days still apply. Therefore, the transition to
the new library was quite straightforward. With a few minor changes, this example
could be run on a &lt;a href=&#34;https://penkovsky.com/neural-networks/day8/&#34;&gt;graphics processing unit&lt;/a&gt; accelerator.&lt;/p&gt;

&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;

&lt;p&gt;Hasktorch:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://hasktorch.github.io/tutorial/02-tensors.html&#34;&gt;Hasktorch tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hasktorch/hasktorch/tree/master/examples&#34;&gt;Hasktorch examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://hasktorch.org/docs.html&#34;&gt;Hasktorch documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://learnyouahaskell.com/functors-applicative-functors-and-monoids&#34;&gt;Applicative functors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker containers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.docker.com/get-started/&#34;&gt;Getting started with Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Tensor&#34;&gt;Tensors&lt;/a&gt; are represented by n-dimensional arrays.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Quadcopter From Scratch: FPV Upgrade</title>
      <link>https://penkovsky.com/post/fpv-quad/</link>
      <pubDate>Thu, 17 Feb 2022 00:10:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/post/fpv-quad/</guid>
      <description>

&lt;p&gt;It has been a while since I was thinking about upgrading
&lt;a href=&#34;https://penkovsky.com/post/quad/&#34;&gt;my drone&lt;/a&gt; to a first person view version
aka &lt;em&gt;FPV&lt;/em&gt;. The idea was placing a camera for video streaming in real time. My
first attempt was with a small raspi board and streaming image data from a raspi
camera via WiFi.  Because of the latency, range, and complicated setup this
solution was not very practical.&lt;/p&gt;

&lt;p&gt;Therefore, I decided to make a &amp;quot;real&amp;quot; FPV drone.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The jargon and some technical details were explained in the previous post.
Before you continue, you may want to read it first:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/post/quad/&#34;&gt;A Quadcopter From Scratch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;fpv-components&#34;&gt;FPV Components&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Part&lt;/th&gt;
&lt;th&gt;Qty&lt;/th&gt;
&lt;th&gt;Unit W. (g)&lt;/th&gt;
&lt;th&gt;Price (EUR)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;FPV micro camera&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;8.6*&lt;/td&gt;
&lt;td&gt;50.67&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Video transmitter (analog)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;12*&lt;/td&gt;
&lt;td&gt;47.92&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;MMCX antenna&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;3.1&lt;/td&gt;
&lt;td&gt;10.23&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;FPV monitor or goggles&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;106.31&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;small&gt;* Weight without cables.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Note that you can easily find cheaper versions of those. For instance,
a camera and VTX combo can cost under 40 EUR in total.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/quad3.jpg&#34; alt=&#34;Basic FPV: Connecting camera directly to VTX&#34; width=&#34;600&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Basic FPV: Connecting camera directly to VTX
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Technically these components are enough to build an autonomous FPV system.
As seen above, I have connected the camera to the VTX (video transmitter), which
was powered directly from a 3S battery (12.6 V). The FPV test flight was
successful. Then, I found some space for further improvement.
So I experimented with additional components.  If you are about to build a quad from
the ground up, you may want to consider those. These parts make it much easier
to build a new copter.&lt;/p&gt;

&lt;h3 id=&#34;optional-components&#34;&gt;Optional Components&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Part&lt;/th&gt;
&lt;th&gt;Qty&lt;/th&gt;
&lt;th&gt;Unit W. (g)&lt;/th&gt;
&lt;th&gt;Price (EUR)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;F4-based flight controller + ESC stack&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;6 + 10*&lt;/td&gt;
&lt;td&gt;65.70&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Carbon fiber frame&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;107&lt;/td&gt;
&lt;td&gt;28.07&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Micro receiver&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1.7&lt;/td&gt;
&lt;td&gt;15.76&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Pink propellers (5040)&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;11.27&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;small&gt;* Weight without connector wires.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;The flight controller&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; stack gave several advantages.  First, a more powerful
processor. Second, there was no need in additional UBEC, i.e. the flight
controller was connected to the battery. Third, the controller provided an OSD
(on-screen display) that could transmit flight information such as battery
level or link quality (RSSI, LQ) in real time. I also find it overall
convenient soldering VTX and camera wires directly to the flight
controller&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-2&#34;&gt;&lt;a href=&#34;#fn:fn-2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. And don&#39;t forget included silicon vibration dampeners!
It is called a stack because of the flight controller and 4-in-1 ESC vertical
integration. This implies a standard way to place and connect the two.
Besides, the ESC already came with a XT60 connector to solder.&lt;/p&gt;

&lt;p&gt;A carbon fiber frame instead of a 3D-printed one is a bit more ergonomic. For
instance, it already has standard emplacement for four M2 screws to attach the
VTX and a support for the VTX camera. Overall it results in a cleaner, slim
build.  Commercial frames are strong enough to support a light X-shape, whereas
the 3D-printed frame I used previously had a slightly bulky H-shape.
Surprisingly, the weight of the new frame was about the same (107g vs 110g).
Last but not least the commercial frame was already supplied with a set of screws
and standoffs.&lt;/p&gt;

&lt;p&gt;The FS-iA10B receiver was quite bulky, so I have replaced it with a smaller
one. If you are choosing a transmitter-receiver system, then you may want to
consider a long-range TBS CrossFire or &lt;a href=&#34;https://github.com/ExpressLRS/ExpressLRS&#34;&gt;ExpressLRS&lt;/a&gt;. The last one
is cheaper because it is open-source, by the way. In both cases you avoid the
problem of loosing the control because of the range. Believe me, I know how
it feels bathing a copter in a lake!&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/quad4.jpg&#34; alt=&#34;F4 controller in a carbon fiber frame&#34; width=&#34;640&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    F4 controller in a carbon fiber frame
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;There was no particular utility in pink propellers, but the older ones were
worn out and had to be replaced anyway. The four motors, batteries, the radio
transmitter, &amp;quot;velcro&amp;quot; fasteners, and motor-antivibration pads were taken from
the previous build. There was no separate UBEC part anymore.&lt;/p&gt;

&lt;p&gt;This is how it feels to fly analog FPV. Signal interferences are visible,
but the latency is only about 6ms!&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/fpv-06-02.gif&#34; width=&#34;420&#34; /&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://fpv-freerider.itch.io/fpv-freerider&#34;&gt;FPV FreeRider simulator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=391D5dX7LKg&#34;&gt;Lessons how to fly an FPV drone&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;Powered by Betaflight software.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-2&#34;&gt;A pro tip: They recommend twisting the wires to reduce the interference.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Hardware-Efficient Stochastic Binary CNN Architectures for Near-Sensor Computing</title>
      <link>https://penkovsky.com/publication/stochastic-binary-cnn/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0100</pubDate>
      
      <guid>https://penkovsky.com/publication/stochastic-binary-cnn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Autonomous Factory</title>
      <link>https://penkovsky.com/project/autonomous-factory/</link>
      <pubDate>Thu, 14 Oct 2021 07:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/project/autonomous-factory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reservoir computing with biocompatible organic electrochemical networks for brain-inspired biosignal classification</title>
      <link>https://penkovsky.com/publication/biocompatible-reservoir-computing/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/publication/biocompatible-reservoir-computing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Quadcopter From Scratch</title>
      <link>https://penkovsky.com/post/quad/</link>
      <pubDate>Sun, 09 May 2021 11:33:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/post/quad/</guid>
      <description>

&lt;p&gt;Recently NASA has made the first powered flight on Mars.
They have deployed a drone called &lt;a href=&#34;https://en.wikipedia.org/wiki/Ingenuity_(helicopter)&#34;&gt;Ingenuity&lt;/a&gt;
costing about $85 million. The helicopter was able to fly
on about ten meters altitude (as of May, 7)
over the surface of the Red Planet.&lt;/p&gt;

&lt;p&gt;Coincidently, I have also built a flying drone.
This looked like a good challenge and an opportunity to
learn about unmanned aerial vehicles (UAVs).&lt;/p&gt;

&lt;p&gt;Here is what I learned.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/copter.gif&#34; alt=&#34;Ingenuity helicopter hovering on Mars (2021). Image credit: NASA/JPL-Caltech.&#34; width=&#34;590&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Ingenuity helicopter hovering on Mars (2021). Image credit: NASA/JPL-Caltech.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#parts&#34;&gt;Parts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assembling-a-drone&#34;&gt;Assembling a Drone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#some-of-the-challenges-i-have-faced&#34;&gt;Some of the Challenges I Have Faced&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;parts&#34;&gt;Parts&lt;/h2&gt;

&lt;p&gt;What you will essentially need is propellers, motors, and some way to power and control them.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/parts-flat.jpg&#34; alt=&#34;Our quadcopter parts&#34; width=&#34;700&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Our quadcopter parts
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Part&lt;/th&gt;
&lt;th&gt;Qty&lt;/th&gt;
&lt;th&gt;Unit W. (g)&lt;/th&gt;
&lt;th&gt;Weight (g)&lt;/th&gt;
&lt;th&gt;Price (EUR)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Arm (printed)&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;52&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Arm support (printed)&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3.5&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Base (v1.1) (printed)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Top (v1.1) (printed)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/ZOP-Power-11_1V-1100mAh-65C-3S-Lipo-Battery-XT60-Plug-p-1085893.html&#34;&gt;1100 mAh Battery 3S&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;117&lt;/td&gt;
&lt;td&gt;117&lt;/td&gt;
&lt;td&gt;14.72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2300 KV Motors 2204&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;14.02&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/Racerstar-RS20Ax4-20A-4-in-1-Blheli_S-Opto-ESC-2-4S-Support-Dshot150-Dshot300-for-RC-FPV-Racing-Drone-p-1068210.html&#34;&gt;ESC (4 in 1)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;24.84&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/F3-Flight-Controller-6-DOF-or-10-DOF-for-RC-Multirotor-FPV-Racing-Drone-p-1010232.html&#34;&gt;F3 flight controller&lt;/a&gt;*&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;18.87&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Radio receiver (FS-iA10B)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;17.6&lt;/td&gt;
&lt;td&gt;17.6&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/DC-DC-Converter-Step-Down-Module-UBEC-3A-5V-or-12V-BEC-For-RC-Airplane-FPV-for-RC-Drone-FPV-Racing-p-981978.html&#34;&gt;UBEC 3A 5V&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;3.13&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Wires*&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Bolts and nuts*&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;&amp;lt;10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/10-Pairs-GEPRC-5040-V2-5-Inch-3-Blade-Propeller-Transparent-Color-For-RC-Multirotor-FPV-Racing-Drone-p-1169484.html&#34;&gt;5040 Propellers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;7.38&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/Suleve-M3NH12-50Pcs-M3-Nylon-Hex-Hexagonal-Female-Thread-PCB-Standoff-Spacers-2025303540mm-p-1262027.html&#34;&gt;Nylon spacers 40 mm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;5.72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/10PCS-Eachine-Lipo-Battery-Tie-Down-Strap-260mm-For-FPV-RC-Drone-p-1137622.html&#34;&gt;&amp;quot;Velcro&amp;quot; fasteners&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2-3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;1.63&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/Amass-XT60-Male-Female-Plug-Connector-12AWG-10cm-Power-Cable-p-1155466.html&#34;&gt;XT60 connector&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;3.27&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/4-PCS-22XX-Series-Motor-Silicone-Anti-vibration-Pad-in-for-RC-Drone-FPV-Racing-Drone-p-1153904.html&#34;&gt;Motor anti-vibration pads&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2.01&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Total**&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;418.6&lt;/td&gt;
&lt;td&gt;124.59&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;small&gt;* Approximate weight.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;** Total price without LiPo charger (iMAX B6), radio transmitter, and
camera. You can reuse those from other projects.  The prices are given for
indicative purpose only. The parts are not guaranteed to be optimal or
cheapest.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;The 3D printed frame was downloaded from Thingiverse: design called
&lt;a href=&#34;https://www.thingiverse.com/thing:629338&#34;&gt;Peon230&lt;/a&gt;. Initially I printed everything in PLA. However, I have found
out that, when crashing, base and top parts tend to break. Now, I use nylon
for those two parts: they are lighter in nylon and do not break so easily.  By
the way, I did not use glue for platform adhesion when printing with PLA&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.
Printing directly on the glass platform gave parts a shiny finish.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/3dprinting.gif&#34; alt=&#34;Fabricating quadcopter frame. Overall it took 11 hours to print all the parts.&#34; width=&#34;520&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Fabricating quadcopter frame. Overall it took 11 hours to print all the parts.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;some-jargon&#34;&gt;Some Jargon&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ESC&lt;/strong&gt; = electronic speed controller. Those translate control pulses coming
from the flight controller into voltage actually driving motors. The ESC I used
in this build contains actually four ESCs, permitting to control all four
motors. That reduces the copter&#39;s weight, which is great.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UBEC&lt;/strong&gt; = universal battery elimination circuit (DC-DC converter). Helped me
to use a single battery both for the motors (12 V) and for the flight
controller (5 V). UBECs are switching converters and they are recommended over
linear DC converters, which dissipate a lot of heat when stepping down the
voltage.&lt;/p&gt;

&lt;p&gt;(Battery) &lt;strong&gt;3S&lt;/strong&gt; = 3 cells. Each cell contributes 3.7 V, therefore 11.1 V
total. I used a battery with capacity of 1100 mAh. This battery gave me up to
15 minutes to fly.&lt;/p&gt;

&lt;p&gt;Motor characteristics. &lt;strong&gt;2300 KV&lt;/strong&gt;: 2300 revolutions per minute (RPMs) per volt
(with no load attached to that motor). Therefore, at 12 volts, these motors are
expected to achieve 12 * 2300 = 27600 RPMs. &lt;strong&gt;2204&lt;/strong&gt;: 22  is the rotor diameter
and 04 is the stator height. Larger motors give you more torque, which is
related to the uplift force you want to generate. This is especially important
when considering the vehicle&#39;s weight.  Racing drones have high thrust to
weight ratio enhancing their maneuverability and ability to rapidly accelerate
Camera drones, on the other hand, have lower thrust to weight ratio making them
more stable and easier to pilot.&lt;/p&gt;

&lt;h3 id=&#34;battery-safety&#34;&gt;Battery Safety&lt;/h3&gt;

&lt;!-- Speaking about the battery, --&gt;

&lt;p&gt;The nominal voltage of a lithium-polymer (LiPo) battery cell (3.7 V) is
actually closer to its storage voltage (3.8 V). When a battery cell is fully
charged, it reaches 4.2 V. The battery should never be overcharged because of
an explosion/fire hazard. Also discharging under 3 V is not recommended as the
battery may break. It is a good idea using a balance charger that controls each
cell individually. &lt;strong&gt;Be careful with your batteries&lt;/strong&gt;. There exist special
safety bags designed for LiPo charging.  Never charge your batteries
unattended.&lt;/p&gt;

&lt;!-- The video below gives an idea what can happen if such battery is
improperly handled.


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/CnNId0mDnBo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 --&gt;

&lt;h2 id=&#34;assembling-a-drone&#34;&gt;Assembling a Drone&lt;/h2&gt;

&lt;h3 id=&#34;soldering-motor-wires&#34;&gt;Soldering Motor Wires&lt;/h3&gt;

&lt;p&gt;First of all we need to make sure that our electronic part (flight controller, ESCs, motors, etc.) works properly.
We solder three wires of each motor directly to ESCs.
Please pay attention to the motor wiring as neighboring motors rotate
&lt;em&gt;in opposite directions&lt;/em&gt;.
Then, we solder an XT60 battery connector.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/4Ry7khyMQZo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;In parallel to motors we solder a UBEC, not shown on the video&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-2&#34;&gt;&lt;a href=&#34;#fn:fn-2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.
We connect UBEC to power the flight controller from the same battery.&lt;/p&gt;

&lt;p&gt;Here is an example diagram how the flight controller can be connected to the
receiver via the iBus protocol. It is also shown how the four motor outputs are
connected to electronic speed controllers. Usually ground (black) wires are
connected to the ESCs for the ground reference&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-3&#34;&gt;&lt;a href=&#34;#fn:fn-3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. If you decide to power
the flight controller from ESCs (provided that your ESCs have BEC circuits), it
is not recommended to provide more then one VCC (typically red) wire. In my
configuration I do not power the flight controller from ESCs. Instead, I use a
separate UBEC connected to the battery in parallel.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/diag-ibus.png&#34; alt=&#34;Wiring the receiver and, flight controller, and motor ESCs&#34; width=&#34;590&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Wiring the receiver and, flight controller, and motor ESCs
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The diagram above also illustrates the direction of the motor rotation. Pay
attention as it is equally important to install the appropriate propellers
before the flight. Crucially, all four propellers will have to push the air
down. It is also a good idea to test every motor individually (without
propellers of course) to verify if signals are arriving to the correct motors
(see &lt;a href=&#34;#tuning-the-flight-controller&#34;&gt;Tuning the Flight Controller&lt;/a&gt; section
below).&lt;/p&gt;

&lt;h3 id=&#34;complete-build&#34;&gt;Complete Build&lt;/h3&gt;

&lt;p&gt;In this video we assemble the frame from earlier printed parts.  We put motors,
ESCs, flight controller, and the receiver on the frame.  The flight controller
is bolted on top of the 4-in-1 ESC.  Then, we connect the radio receiver to the
flight controller.  We also connect flight controller output wires to ESCs.  We
could solder everything instead, but these connections are already good for the
test. We test connection with a transmitter and the motors. We finalize the build
by putting the remaining part of the frame on top.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/kusp-hsykl8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Please also note that it is crucial that your final build is tight.  No wire,
nothing should be in the way of your propellers.&lt;/p&gt;

&lt;h3 id=&#34;tuning-the-flight-controller&#34;&gt;Tuning the Flight Controller&lt;/h3&gt;

&lt;p&gt;While your UAV may seem functional, it is probably not yet ready to fly. In
fact, the flight controller is probably the most important part, it acts as a
&amp;quot;quadcopter&#39;s brain&amp;quot;. The controller interprets the received radio commands and
the data coming from its sensors, most notably from the inertia measurement
unit (IMU), to stabilize and steer the vehicle. In fact, without a flight
controller it would be virtually impossible for a human to pilot a quadcopter.&lt;/p&gt;

&lt;p&gt;To make sure the copter interprets the flight situation adequately, the
controller has to be properly calibrated. This includes calibrating the IMU and
compass. It is also important to verify that the remote control commands are
properly interpreted. And that the appropriate motors are activated. To perform
these individual checks and calibrations, I used
&lt;a href=&#34;http://cleanflight.com&#34;&gt;Clean Flight&lt;/a&gt; software. However, there exist multiple
alternative options, such as &lt;a href=&#34;https://betaflight.com/&#34;&gt;Beta Flight&lt;/a&gt;, which is a
popular fork of Clean Flight.&lt;/p&gt;

&lt;h2 id=&#34;some-of-the-challenges-i-have-faced&#34;&gt;Some of the Challenges I Have Faced&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Vibrations on captured videos from the quadcopter turned out to be mostly because of slightly damaged propellers (after emergency landings)&lt;/li&gt;
&lt;li&gt;The best way to position antennas turned out to be along the body. This way they don&#39;t get into the way if crashing.&lt;/li&gt;
&lt;li&gt;Regulations. In Europe, you need to obtain a special permission to fly a drone. Also there are very strict limitations where you can fly as a hobbyist.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am still learning to fly this thing.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/kVYTW7eJe7k&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;



&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/7OXhmJnP2sY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;h2 id=&#34;next-episode&#34;&gt;Next Episode&lt;/h2&gt;

&lt;p&gt;Learn how to &lt;a href=&#34;https://penkovsky.com/post/fpv-quad/&#34;&gt;upgrade to FPV&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Ingenuity_(helicopter)&#34;&gt;Ingenuity helicopter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cleanflight.com&#34;&gt;Clean Flight&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://fpv-freerider.itch.io/fpv-freerider&#34;&gt;FPV FreeRider simulator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=391D5dX7LKg&#34;&gt;Lessons how to fly an FPV drone&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;It is always advised to apply 3d printing glue for nylon prints because of high warping forces of this material.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-2&#34;&gt;I used UBEC in the second build. In the first build, I had a separate battery and a linear step-up DC converter to power the flight controller.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-3&#34;&gt;Since I use a 4-in-1 ESC, it is a single ground wire.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Optical Computing Applications</title>
      <link>https://penkovsky.com/talk/optical-computing-applications2021/</link>
      <pubDate>Wed, 21 Apr 2021 15:40:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/talk/optical-computing-applications2021/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
