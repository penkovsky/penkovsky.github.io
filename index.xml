<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bogdan Penkovsky, PhD on Bogdan Penkovsky, PhD</title>
    <link>https://penkovsky.com/</link>
    <description>Recent content in Bogdan Penkovsky, PhD on Bogdan Penkovsky, PhD</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Bogdan Penkovsky 2024</copyright>
    <lastBuildDate>Thu, 02 Jul 2020 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Meta-Learning</title>
      <link>https://penkovsky.com/neural-networks/meta-learning/</link>
      <pubDate>Sat, 16 Dec 2023 14:20:00 +0100</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/meta-learning/</guid>
      <description>&lt;p&gt;Breaking news! Artificial intelligence is taking over the world. Or it
is not? Here is what you need to know about a deeper concept
of meta-learning.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Meta-learning&lt;/em&gt; is learning about learning.
Learning how to learn belongs here too.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#models-analyzing-other-models&#34;&gt;Models Analyzing Other Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#updating-neural-network-during-run&#34;&gt;Updating Neural Network During Run&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#self-modifying-learning-algorithms&#34;&gt;Self-Modifying Learning Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;The first thing that pops to mind is &lt;a href=&#34;https://en.wikipedia.org/wiki/Automated_machine_learning&#34;&gt;AutoML&lt;/a&gt;,
a search for the best model architecture. It often includes
data preparation, feature engineering, and hyperparameter search.
Companies like Google adore this approach: First, AutoML requires
a lot of computational resources, and companies like Google have it.
Second, AutoML can make machine learning accessible to non-experts,
enabling companies like Google to sell their compute power to
more customers.&lt;/p&gt;

&lt;p&gt;However, meta-learning is more than AutoML. It is a broad subject.
Here are the articles that have marked my thinking.&lt;/p&gt;

&lt;h2 id=&#34;models-analyzing-other-models&#34;&gt;Models Analyzing Other Models&lt;/h2&gt;

&lt;p&gt;In &lt;a href=&#34;https://openreview.net/pdf?id=cmJiEqniEc&#34;&gt;this work&lt;/a&gt;, Langosco and colleagues
detect whether a &lt;a href=&#34;https://penkovsky.com/neural-networks/day1/&#34;&gt;neural network&lt;/a&gt; has a &lt;em&gt;backdoor&lt;/em&gt;.
A backdoor is a way to modify the input to force a network
to produce an undesirable output. As an extreme example, imagine
a self-driving car that crashes into another car after seeing a malicious
drawing on the road. That drawing would be a neural network&#39;s input
that was misinterpreted to cause a bad decision, which itself led to a crash.
And a backdoor in this case could be a susceptibility of a neural
network to a particular form or texture.&lt;/p&gt;

&lt;p&gt;Therefore, you see, it could be quite hard to manually design such an algorithm
that would detect if a neural network has a backdoor in it.
So it seems natural to use another neural network (which we call a
&lt;em&gt;meta-model&lt;/em&gt;) to analyze the weights of the first one and to detect whether
there is a built-in backdoor or not.&lt;/p&gt;

&lt;p&gt;I think the importance of this work is not only
technical, it also raises the awareness about the
challenges that we &lt;em&gt;will&lt;/em&gt; face when relying on AI. In 2023 AI is
often defined as &amp;quot;allowing computers to learn and solve problems
almost like a person&amp;quot; (&lt;a href=&#34;https://www.bbc.com/news/technology-65855333&#34;&gt;BBC, 01/11/2023&lt;/a&gt;). Which, to be honest, has
almost nothing to do with intelligence&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. And even though
there is no imminent &lt;a href=&#34;https://en.wikipedia.org/wiki/The_Terminator&#34;&gt;Terminator&lt;/a&gt; danger, we need
to beware of malicious human actors out there.&lt;/p&gt;

&lt;p&gt;Here are a &lt;a href=&#34;https://arxiv.org/abs/2301.12780&#34;&gt;few&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2002.05688&#34;&gt;more&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2110.15288&#34;&gt;examples&lt;/a&gt;
&lt;a href=&#34;https://arxiv.org/abs/2002.11448&#34;&gt;of&lt;/a&gt; models analyzing other models.&lt;/p&gt;

&lt;h2 id=&#34;updating-neural-network-during-run&#34;&gt;Updating Neural Network During Run&lt;/h2&gt;

&lt;p&gt;Typical neural network weights are static. That means that once the network is
trained, the weights are fixed and the network stops to learn.
On the other hand, our brains continue to learn during the whole life.
And it makes sense since our brains have evolved to survive in ever-changing
environment. This ability is largely due to the brain&#39;s plasticity, which
enables it to form new connections. What if artificial neural networks were
plastic?&lt;/p&gt;

&lt;p&gt;From the perspective of &lt;a href=&#34;https://penkovsky.com/neural-networks/beyond/&#34;&gt;reinforcement learning&lt;/a&gt;,
meta-learning is about agents that learn from ongoing experience, even
without explicit reward signal. For instance,
a robotic dog was trained to walk on the grass. Now, as it crosses a patch of
sandy terrain, can it adapt its walking gait?
&lt;a href=&#34;https://arxiv.org/abs/2007.02686&#34;&gt;Najarro and Risi&lt;/a&gt; suggest a recipe of an agent that
modifies its behavior based on &lt;em&gt;local&lt;/em&gt; learning. That is, based on the
&lt;a href=&#34;https://penkovsky.com/neural-networks/day1/&#34;&gt;neural network&lt;/a&gt; &lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;layers&#39;&lt;/a&gt;
inputs &lt;em&gt;and&lt;/em&gt; outputs. Using the Hebbian rule (&amp;quot;what fires together wires
together&amp;quot;), the network is updated on the fly. Evolutionary techniques
are employed to train such agents. In a remarkable demonstration, a robot
manages to walk despite one of its legs being damaged. This would be hardly
possible with neural networks having static weights (that is, &amp;quot;normal&amp;quot; neural
networks).&lt;/p&gt;

&lt;p&gt;To capture invariant object representations, &lt;a href=&#34;https://www.nature.com/articles/s41593-023-01460-y&#34;&gt;Halvagal and Zenke&lt;/a&gt;
propose to augment the Hebbian rule to include a predictive term. &amp;quot;It cancels
when the neural activity does not change and, therefore, accurately predicts
future activity,&amp;quot; the authors explain.
The idea resonates with HTM neurons from &lt;a href=&#34;https://link.springer.com/content/pdf/10.1007/s42452-021-04715-0.pdf&#34;&gt;thousand brains theory&lt;/a&gt;,
originally conceptualized by &lt;a href=&#34;https://www.youtube.com/watch?v=-EVqrDlAqYo&amp;amp;t=2075s&#34;&gt;Jeff Hawkins&lt;/a&gt;. Each HTM neuron
predicts its activation. The hypothesis claims that these predictions
of expected inputs allow brains to filter out what has changed in the
environment and what is immediately important to notice. Like a branch cracking.
Suddenly, a wild animal detects a threat in the jungle. Such alertness is
essential for survival in a complex environment.&lt;/p&gt;

&lt;p&gt;&amp;quot;So how about &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;transformers&lt;/a&gt;?&amp;quot; you might ask, &amp;quot;They use attention.&amp;quot;
Yes, transformers technically belong to the category of dynamic neural networks,
too. What happens with GPT models (&lt;em&gt;T&lt;/em&gt; is for transformer of course) is that
when you provide a text prompt, it serves as a context. The &lt;em&gt;attention&lt;/em&gt;
mechanism underpinning the transformer architecture is transforming the neural
network weights, as a function of that context. And that is what makes
transformers flexible.&lt;/p&gt;

&lt;p&gt;By the way don&#39;t be misled thinking that the attention mechanism/dynamically
updated weights is the reason why transformer models are called &lt;em&gt;generative&lt;/em&gt;!
Generative models already exist for decades. Other examples are generative
adversarial networks (GANs), auto-encoders,
&lt;a href=&#34;https://penkovsky.com/neural-networks/day9/&#34;&gt;variational auto-encoders&lt;/a&gt; (VAEs), Hidden Markov
models, etc. The actual reason why all those models are called generative is
learning a &lt;a href=&#34;https://en.wikipedia.org/wiki/Generative_model&#34;&gt;joint distribution&lt;/a&gt;.
Combining a generative model with neural networks is now called
&lt;a href=&#34;https://en.wikipedia.org/wiki/Generative_artificial_intelligence&#34;&gt;Generative AI&lt;/a&gt; (not so elegant, as you can see).
It just happens that the transformer architecture is popular,
and is the first thing associated with &amp;quot;Generative AI&amp;quot; these days.&lt;/p&gt;

&lt;p&gt;Coming back to transformers, &lt;a href=&#34;https://arxiv.org/abs/2109.02869&#34;&gt;Tang and Ha&lt;/a&gt; demonstrate what they call
a &lt;em&gt;sensory neuron&lt;/em&gt;. Based on the attention mechanism, their agents
trained by reinforcement learning are able to quickly re-adapt to the
change of order of sensory stimuli. That is, it does not matter in which
order the observation inputs are provided. Moreover, their agent is not confused
even when the majority of the inputs are masked out.&lt;/p&gt;

&lt;h2 id=&#34;self-modifying-learning-algorithms&#34;&gt;Self-Modifying Learning Algorithms&lt;/h2&gt;

&lt;p&gt;Perhaps this concept is the pinnacle of meta-learning. What can be more
appealing than learning algorithms that modify themselves?
If updating a neural network during run was a &lt;em&gt;first-order&lt;/em&gt; meta-learning,
then updating neural networks that update neural networks would be
already a &lt;em&gt;second-order&lt;/em&gt;. And by induction, neural networks that update their own
weights, as is done for example by &lt;a href=&#34;https://arxiv.org/abs/2202.05780&#34;&gt;Irie and colleagues&lt;/a&gt;, can be
considered an &lt;em&gt;infinite-order&lt;/em&gt; meta-learning.&lt;/p&gt;

&lt;p&gt;Don&#39;t agree? Then shoot me an email!&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The family of meta-learning concepts is vast. This article has
touched a few notable examples. However, as the field continues to
evolve, more interesting work is to appear.
I don&#39;t know how far we are from the so-called &amp;quot;artificial general
intelligence&amp;quot;, however, its distinctive characteristic is extreme adaptivity.
And adaptivity is something that is currently explored by meta-learning
researchers.&lt;/p&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;pre&gt;
@article{penkovsky2023meta,
 title   = &#34;Meta-Learning&#34;,
 author  = &#34;Penkovsky, Bogdan&#34;,
 journal = &#34;penkovsky.com&#34;,
 year    = &#34;2023&#34;,
 month   = &#34;December&#34;,
 url     = &#34;https://penkovsky.com/neural-networks/meta-learning/&#34;
}
&lt;/pre&gt;

&lt;!-- https://www.bbc.com/news/technology-65855333 https://archive.is/BUSha --&gt;

&lt;!--

--&gt;

&lt;!-- https://archive.is/J2QPq --&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;&lt;p&gt;I believe, a truly &amp;quot;intelligent&amp;quot; machine has to be adaptive at least.
And probably it has—in some sense—to be &lt;em&gt;embodied&lt;/em&gt; as well.
What we witness today with ChatGPT is a &lt;em&gt;text-to-text&lt;/em&gt; engine. It&#39;s more
about machine translation than intelligence. Once I asked it to create a
personal training plan for swimming. I&#39;ve got some result, quite far from
what I specified. Does ChatGPT even &lt;em&gt;know&lt;/em&gt; about how to be immersed in the
water and what it may feel like? Certainly not. It managed to
&amp;quot;translate&amp;quot; existing articles and compile a training plan of some kind.
I doubt it could ever substitute a coach who can actually swim.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Day 10: Beyond Supervised Learning</title>
      <link>https://penkovsky.com/neural-networks/beyond/</link>
      <pubDate>Thu, 11 May 2023 21:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/beyond/</guid>
      <description>&lt;p&gt;Ever wondered how machines defeated the best human Go player Lee Sedol in 2016?
A historical moment for the game that was previously considered to be very
tough. What is reinforcement learning that generates so much buzz recently?
Superhuman performance playing arcade &lt;a href=&#34;https://arxiv.org/abs/1312.5602&#34;&gt;Atari games&lt;/a&gt;, real-time &lt;a href=&#34;https://www.nature.com/articles/s41586-021-04301-9&#34;&gt;Tokamak
plasma control&lt;/a&gt;, Google &lt;a href=&#34;https://arxiv.org/abs/2211.07357&#34;&gt;data center cooling&lt;/a&gt;, and
&lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7029011854383284224/&#34;&gt;autonomous chemical synthesis&lt;/a&gt; are all the recent achievements behind
the approach. Let&#39;s dive to learn what empowers &lt;em&gt;deep reinforcement learning&lt;/em&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reinforcement-learning-concepts&#34;&gt;Reinforcement Learning Concepts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reinforcement-learning-hints&#34;&gt;Reinforcement Learning Hints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reinforce&#34;&gt;REINFORCE Algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#proximal-policy-optimization&#34;&gt;Proximal Policy Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#alphago-vs-lee-sedol&#34;&gt;AlphaGo vs Lee Sedol&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#goodbye&#34;&gt;Goodbye?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#learn-more&#34;&gt;Learn More&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Reinforcement learning (RL) is a machine learning technique that is all about
&lt;em&gt;repetitive&lt;/em&gt; decision making. Well, just like when you go camping. During
your first trip you realize that you need more food and you lack some tools. Next
time, you take some more cereals and dried fruit, a better knife, and a pot.
And after yet several more attempts you invest in better shoes or a backpack
and learn how to arrange your stuff in a neat way. The journeys become longer
and more enjoyable. As you can see, you iterate. You learn from experience. And
you get rewarded.&lt;/p&gt;

&lt;p&gt;No matter how much you can relate yourself to the experiences above, they
contain everything that reinforcement learning has. An &lt;em&gt;agent&lt;/em&gt; is learning from
experience (or from mistakes if you want) by interacting with its environment.
The agent receives some sort of a reward signal in response to its actions. And
that is basically the idea. An idea from psychology? Perhaps.&lt;/p&gt;

&lt;p&gt;In a &lt;a href=&#34;https://en.wikipedia.org/wiki/Supervised_learning&#34;&gt;supervised learning&lt;/a&gt;
setting&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; you would be instructed what equipment to take with you. And you
would need to act exactly as instructed. However, the real life is not like
that. You might have watched a camping channel on YouTube and still struggle to
start a fire. Trying different kinds of approaches yourself, however, improves
your survival skills over time.&lt;/p&gt;

&lt;p&gt;You may also notice that reinforcement learning is actually more general than
supervised learning. Indeed, in supervised learning we usually talk about a
single iteration and apply some sort of ground truth or target signal. However,
let&#39;s take a look at the following example. Imagine, you are a director of AI
at Tesla (those hipsterish cars, you know) and your team trains a self-driving
car based on videos that were previously recorded. Sounds like a supervised
problem with images and labels, right? The car performs well during the same
day, but tomorrow it rains and the car refuses to drive well. What do you do?
You say, perhaps the distribution of images has changed. Let&#39;s collect some
more for a rainy weather. And the model training is repeated. The third day is
very foggy and your team has to collect the data again. And train the model
again. So what happens? Exactly! Iteration. You have an implicit reinforcement
learning loop where it is &lt;em&gt;you&lt;/em&gt; who acts as an agent trying to outsmart the
weather conditions&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-2&#34;&gt;&lt;a href=&#34;#fn:fn-2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;More often than not present decisions will influence the situation, and thus
they will influence &lt;em&gt;future decisions&lt;/em&gt; too. This is perhaps &lt;strong&gt;the biggest
difference from supervised learning&lt;/strong&gt;. Supervised learning conveniently omits
to confess that its main goal is to help &lt;em&gt;making decisions&lt;/em&gt; in &lt;em&gt;real&lt;/em&gt; world.
The most boring vision task you have encountered, classifying &lt;a href=&#34;https://penkovsky.com/neural-networks/day4/&#34;&gt;MNIST
images&lt;/a&gt;, at some point was actually useful for post
offices to automate mail delivery. Similarly, predicting time series might be
helpful getting an idea about climate change or predicting economic downturns.
Whatever supervised learning benchmark you take, in its origin there is some
sort of implication in the real world.&lt;/p&gt;

&lt;p&gt;Unlike supervised learning, reinforcement learning is all about decisions. It
explicitly states the goal of achieving the best overall consequences -- by
maximizing total reward. For instance, to arrive from point A to point B you
may take a car. Depending on which route you will take and how frequently you
will rest, this will affect your trip duration and how tired you will arrive.
Those circumstances may further affect your plans. Decisions almost never occur
in isolation. They will inevitably lead to new decisions. That is why real-life
challenges are often accompanied by reinforcement learning in some form.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A quick note.&lt;/em&gt; People often talk about &lt;em&gt;deep&lt;/em&gt; reinforcement learning. This is
to highlight the presence of neural networks. The fact does not change the
essence of the method. These days almost everyone is doing &lt;em&gt;deep&lt;/em&gt; reinforcement
learning anyway, so I prefer to omit the term. Just wanted to make sure we
stay on the same page. Now, we will focus our attention on the nitty-gritty
details of reinforcement learning.&lt;/p&gt;

&lt;h2 id=&#34;reinforcement-learning-concepts&#34;&gt;Reinforcement Learning Concepts&lt;/h2&gt;

&lt;p&gt;By interacting with environment, an RL agent actually creates its &lt;em&gt;own&lt;/em&gt; unique
dataset, whereas in supervised learning the dataset is predefined.  As the
agent explores its environment and the dataset is being created we apply
backprop to teach our agent similarly to &lt;em&gt;supervised learning&lt;/em&gt;. It turns out
there is a large variety of ways how to do that. The concepts below will give
you a taste about the key ideas from reinforcement learning.&lt;/p&gt;

&lt;h3 id=&#34;policies-states-observations&#34;&gt;Policies, States, Observations&lt;/h3&gt;

&lt;p&gt;A &lt;em&gt;policy&lt;/em&gt; (denoted by $\pi$) is simply a strategy that an agent uses when
responding to changes in the environment. The following notation reads &amp;quot;a policy
parametrized by parameters $\phi$ to take an action $a$ given a state $s$&amp;quot;:&lt;/p&gt;

&lt;p&gt;$$ \pi_{\phi}(a|s). $$&lt;/p&gt;

&lt;p&gt;Typically $\phi$ signifies weights in a neural network (the &lt;em&gt;deep&lt;/em&gt; reinforcement
learning story). In the notation above, by $s$ people usually mean &amp;quot;state&amp;quot;. And
sometimes they actually mean &amp;quot;observations&amp;quot; $o$. The difference between the two
is that &lt;em&gt;observations&lt;/em&gt; are a projection of the complete &lt;em&gt;state&lt;/em&gt;
describing the environment. For example, when learning robotic manipulations
from camera pixels, observations of a robotic hand are only a representation of
the actual environment state from a certain angle. Sometimes people talk about
&amp;quot;completely observable&amp;quot; environments, then $s = o$. The distinction between
$s$ and $o$ does not affect the RL algorithms we are learning about today.&lt;/p&gt;

&lt;h3 id=&#34;on-policy-vs-off-policy&#34;&gt;On-policy vs Off-policy&lt;/h3&gt;

&lt;p&gt;Reinforcement learning algorithms can be split between on-policy and
off-policy. The first ones use &lt;em&gt;trajectories&lt;/em&gt; (experiences)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-3&#34;&gt;&lt;a href=&#34;#fn:fn-3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; generated by the
policy itself, while the second ones use trajectories from some other policies.
For instance, algorithms that use a &lt;em&gt;replay buffer&lt;/em&gt; (such as &lt;a href=&#34;https://arxiv.org/abs/1312.5602&#34;&gt;deep Q networks
playing Atari games&lt;/a&gt;) to store transitions are off-policy algorithms.
Typically, off-policy algorithms have better &lt;em&gt;sample efficiency&lt;/em&gt; compared to
on-policy ones, which makes them attractive when it is costly to generate new
experiences. For instance, when training a physical robot. On the other hand,
on-policy algorithms are often used when acquiring new experiences are cheap. For
instance, in simulation.&lt;/p&gt;

&lt;h3 id=&#34;offline-reinforcement-learning&#34;&gt;Offline Reinforcement Learning&lt;/h3&gt;

&lt;p&gt;Offline RL is a family of algorithms where an RL agent observes past
experiences and tries to figure out a &lt;em&gt;better&lt;/em&gt; policy without interaction with
an environment. Of course this is a very challenging task. Nevertheless, it
has many real-world applications where it could be dangerous or illegal to
apply reinforcement learning experiments. For instance, finding the best
treatment in the medical setting. A doctor would not experiment on a patient
using different drugs because this can lead to health deterioration. Instead,
they may use reinforcement learning techniques applied to &lt;em&gt;previous&lt;/em&gt; records of
other patients to figure out the best prescription (offline setting).&lt;/p&gt;

&lt;h3 id=&#34;discrete-vs-continuous-actions&#34;&gt;Discrete vs Continuous Actions&lt;/h3&gt;

&lt;p&gt;Playing an arcade game using a manipulator with four buttons implies a discrete
action setting (four possible actions). However, in reality there are settings
with infinite or very large number of actions. For instance, robot joints
positions. Certain algorithms can be applicable only to one action type
(&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html&#34;&gt;DQN&lt;/a&gt; can be applied only for discrete and &lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html&#34;&gt;DDPG&lt;/a&gt; only for
continuous actions), whereas certain others can be used for both (e.g.
&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html&#34;&gt;A2C&lt;/a&gt;, &lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html&#34;&gt;PPO&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&#34;deterministic-vs-stochastic-policies&#34;&gt;Deterministic vs Stochastic Policies&lt;/h3&gt;

&lt;p&gt;Certain policies inherently produce deterministic actions (&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html&#34;&gt;DQN&lt;/a&gt;), while
others sample from a learned distribution producing stochastic actions
(&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html&#34;&gt;PPO&lt;/a&gt;). Of course, it is possible to make a deterministic algorithm to
produce stochastic actions (epsilon-greedy exploration) and vice versa. Why
use a stochastic policy? Actually, under stochastic environments optimal policies
are often stochastic. The simplest example is
&lt;a href=&#34;https://en.wikipedia.org/wiki/Rock_paper_scissors&#34;&gt;Rock-Paper-Scissors&lt;/a&gt; game.&lt;/p&gt;

&lt;h3 id=&#34;model-free-vs-model-based&#34;&gt;Model-free vs Model-based&lt;/h3&gt;

&lt;p&gt;Model-based approaches assume a certain environment model. The advantage of this
approach is better &lt;em&gt;sample efficiency&lt;/em&gt;. On the other hand, model-free approaches
may better generalize to unknown environments. In some cases, environment&#39;s
model is learned.&lt;/p&gt;

&lt;h3 id=&#34;sample-efficiency&#34;&gt;Sample Efficiency&lt;/h3&gt;

&lt;p&gt;By sample efficiency we mean using less examples for training.&lt;/p&gt;

&lt;h2 id=&#34;reinforcement-learning-hints&#34;&gt;Reinforcement Learning Hints&lt;/h2&gt;

&lt;p&gt;The goal of reinforcement learning is typically to solve a real-life
challenge. For that purpose you will need to define some interaction protocol
between your agent and its environment and also a reward function.  The reward
function provides a score how well your agent performs.  Typically, it is
beneficial having a &amp;quot;dense&amp;quot; reward so that the agent gets some
information at every time step. This is not always possible and there are
&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/her.html&#34;&gt;methods&lt;/a&gt; to circumvent this issue.  One way to look at &lt;em&gt;reward shaping&lt;/em&gt;
is that RL is your &amp;quot;compiler&amp;quot; and the reward is your understanding of the
problem you are trying to solve.&lt;/p&gt;

&lt;p&gt;To gain some expertise, you may want to start with existing
&lt;a href=&#34;https://github.com/openai/gym&#34;&gt;environments&lt;/a&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-4&#34;&gt;&lt;a href=&#34;#fn:fn-4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; and &lt;a href=&#34;https://stable-baselines3.readthedocs.io&#34;&gt;RL
algorithms&lt;/a&gt;. If your goal is to train a physically embodied robot, you
may want to create your own environment to try out some ideas in simulation.
This will save you some time since running a simulator is typically faster than
real-time robot training.&lt;/p&gt;

&lt;p&gt;The more accurate is the simulator, the better the agent is likely to perform in
real-world. For instance, in &lt;a href=&#34;https://arxiv.org/abs/1804.10332&#34;&gt;Sim-to-Real: Learning Agile Locomotion For
Quadruped Robots&lt;/a&gt; the authors have obtained better results by
creating accurate actuator models and performing latency modeling.&lt;/p&gt;

&lt;p&gt;However, there is always a difference between running an agent on any simulator
and reality. The problem known as &lt;em&gt;reality gap&lt;/em&gt;. There are different techniques
how to reduce this difference. One of them is &lt;a href=&#34;https://arxiv.org/abs/1703.06907&#34;&gt;domain
randomization&lt;/a&gt;. The idea is to train the agent using environments
with randomized parameters. In &lt;a href=&#34;https://proceedings.mlr.press/v100/mehta20a.html&#34;&gt;active domain randomization&lt;/a&gt;, the
&lt;em&gt;active learning&lt;/em&gt; approach is combined: agents are trained more often on environments
where they performed poorly.&lt;/p&gt;

&lt;p&gt;Another technique &lt;em&gt;domain adaptation&lt;/em&gt; suggests making &lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2019/papers/James_Sim-To-Real_via_Sim-To-Sim_Data-Efficient_Robotic_Grasping_via_Randomized-To-Canonical_Adaptation_Networks_CVPR_2019_paper.pdf&#34;&gt;real data look like
those in simulation&lt;/a&gt; or vice versa. You may also want to perform
parameters &lt;em&gt;&lt;a href=&#34;https://journals.sagepub.com/doi/pdf/10.1177/0278364919887447&#34;&gt;fine-tuning&lt;/a&gt;&lt;/em&gt; on your &lt;a href=&#34;https://arxiv.org/abs/1810.05687&#34;&gt;real&lt;/a&gt; robot.&lt;/p&gt;

&lt;p&gt;Note also that if you are training an agent in a simulated environment,
the agent may &amp;quot;overfit&amp;quot; to the environment. That is, it may exhibit unrealistic
(and often undesired) behaviors that still lead to high reward scores.
The agent may try to exploit environment glitches if there are any.&lt;/p&gt;

&lt;p&gt;Having those practical strategies in mind, we are going to the meat of RL.
Below we are discussing an algorithm which constitutes the basis to many modern RL
strategies such as TRPO and &lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html&#34;&gt;PPO&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;reinforce&#34;&gt;REINFORCE&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;REINFORCE&lt;/em&gt;, also called Monte Carlo Policy Gradient, is the simplest from the
&lt;em&gt;policy gradient&lt;/em&gt; algorithms family. The advantage of policy gradients is that
they can learn stochastic policies. This also addresses the
exploration-exploitation dilemma.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;REINFORCE algorithm:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Initialize policy parameters $\phi$.&lt;/li&gt;
&lt;li&gt;Generate trajectories $s_0, a_0, r_1,...,s_{T-1}, a_{T-1}, r_T$ by interacting with environment.&lt;/li&gt;
&lt;li&gt;For every step $t = 0,1,...,T-1$, estimate returns $R_t = \sum_{k=t+1}^T \gamma^{k-t-1} r_k.$&lt;/li&gt;
&lt;li&gt;Optimize agent parameters $\phi \leftarrow \phi + \alpha R_t \nabla \log \pi_{\phi}(a_t|s_t)$.&lt;/li&gt;
&lt;li&gt;Repeat steps 2-5 until convergence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note that when using universal function approximators (that is neural
networks), convergence is not guaranteed. However, in practice
you still have a good chance to train your agent.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;numEpisodes&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Num episodes &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;numEpisodes&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Seed Torch for reproducibility.&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Feel free to remove.&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;manual_seed_L&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;seed&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;42&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- Environment seed&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Step 1: Initialize policy parameters&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mkAgent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actionDim&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- We also initialize the optimizer&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mkTrainer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Repeat steps 2-4 for the number of episodes (trajectories)&lt;/span&gt;
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;agent&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;\at&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;reinforce&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conf&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;seed&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;at&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;) (&lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&lt;/span&gt;) [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;numEpisodes&lt;/span&gt;]

  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; ()

&lt;span style=&#34;color:#a6e22e&#34;&gt;reinforce&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cfg&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;seed&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Step 2: Trajectories generation (rollout)&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;reset&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;seed&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;)
  (&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rollout&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;maxSteps&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s0&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Episode &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; - Score &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;sum&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt;)

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Step 3: Estimating returns&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;returnsNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;std&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-8&lt;/span&gt;)

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Step4: Optimize&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cfg&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returnsNorm&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;trainer&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;trajectory-generation&#34;&gt;Trajectory Generation&lt;/h3&gt;

&lt;p&gt;The agent generates a trajectory by interacting with the environment. We call
this a &lt;em&gt;rollout&lt;/em&gt;. By observing the function signature below, we can tell that
the function consumes an integer number, an agent, and environment state. This
integer is simply the maximal number of steps per episode. As a result, the
function will provide the trajectory: observations, actions, and rewards. In
addition, it also provides log probabilities, which we will use to compute our
objective (or loss) before we can optimize parameters in Step 4.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;rollout&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;State&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ([&lt;span style=&#34;color:#66d9ef&#34;&gt;Observation&lt;/span&gt;], [[&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;]], [&lt;span style=&#34;color:#66d9ef&#34;&gt;Reward&lt;/span&gt;], [&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;])
  &lt;span style=&#34;color:#75715e&#34;&gt;-- ^ Observations, actions, rewards, log probabilities&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is how we implement it: we benefit from the excellent &lt;code&gt;unfoldM&lt;/code&gt; function that
has type &lt;code&gt;Monad m =&amp;gt; (s -&amp;gt; m (Maybe (a, s))) -&amp;gt; s -&amp;gt; m [a]&lt;/code&gt;. That is we iterate
as long as the function in the first argument &lt;code&gt;(s -&amp;gt; m (Maybe (a, s)))&lt;/code&gt;
provides a &lt;code&gt;Just&lt;/code&gt; value (and stop when &lt;code&gt;Nothing&lt;/code&gt;).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Haskell libraries provide lots of &amp;quot;pieces of code&amp;quot; or &amp;quot;programming templates&amp;quot;:
functions like &lt;code&gt;map&lt;/code&gt;, &lt;code&gt;foldl&lt;/code&gt;, &lt;code&gt;scanr&lt;/code&gt;, &lt;code&gt;unfoldr&lt;/code&gt;, &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;zipWith&lt;/code&gt;, etc.
All those are compact versions of loops!
Some of those concepts gradually diffuse into
imperative languages (such as C++ and Python).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;rollout&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;L&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;unzip4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unfoldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s0&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Reached max number of steps. Nothing = stop.&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;_agent&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;{&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}, &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;isDone&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;-- The environment is done: stop.&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
           &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
          &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;observations&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;
          (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;Action&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac_&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getAction&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;
          &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;

          &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;ac_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;), (&lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;_agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&amp;#39;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The heart of iteration is in the end: First, observe the environment and
sample actions.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;observations&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;
(&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;Action&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac_&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getAction&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, simulate the environment step:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Env&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_s&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And finally, prepare the next iteration step by reducing the maximal
number of steps and passing the agent and the new environment state.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;ac_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;), (&lt;span style=&#34;color:#a6e22e&#34;&gt;_maxSteps&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;_agent&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&amp;#39;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is how we get an action and a log probability.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;getAction&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unsqueeze&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Return a single discrete action&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Action&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;], &lt;span style=&#34;color:#a6e22e&#34;&gt;logprob&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Evaluate the policy $\pi_{\phi}$:
If no action provided, sample a new action from the learned distribution.
Also get log probabilities for the action.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;probs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;policy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Categorical&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;fromProbs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;probs&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Sample from the categorical distribution:&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- get a tensor of integer values (one sample per observation).&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;shape&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;]
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;estimating-returns&#34;&gt;Estimating Returns&lt;/h3&gt;

&lt;p&gt;After a rollout we (retrospectively) compute how good were our decisions during
the whole trajectory.  The trick is that we start from the last step. That is,
our return $R$ at time step $t$ is our current reward plus a discounted
&lt;em&gt;future&lt;/em&gt; return.&lt;/p&gt;

&lt;p&gt;$$
R_t = r_t + \gamma R_{t+1}.
$$&lt;/p&gt;

&lt;p&gt;This expands into&lt;/p&gt;

&lt;p&gt;$$
R_t = r_t + \gamma (r_{t+1} + \gamma (r_{t+2} + \gamma( ... ))).
$$&lt;/p&gt;

&lt;p&gt;where $r_t$ is the reward at time $t$. The meaning of this expression is the
essence of policy gradient: We evaluate how good were our past decisions with
respect to the future outcomes.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;An intriguing way to look at discount factor $\gamma$ is by using the concept
of terminal state (to put simply, death). At each future step,
the agent can get a reward with probability $\gamma$ and can
die with probability $1 - \gamma$. Therefore, discounting the reward
is akin to incorporating the &amp;quot;fear of death&amp;quot; into RL.
In his &lt;a href=&#34;https://www.youtube.com/watch?v=JHrlF10v2Og&amp;amp;list=PL_iWQOsE6TfX7MaC6C3HcdOf1g337dlC9&#34;&gt;lectures&lt;/a&gt;, S. Levine gives an example of receiving 1000 dollars today
or in million years. In the latter case, the reward is hugely discounted
as it is unlikely that we will be able to receive it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We compute the returns as a function of rewards &lt;code&gt;rs&lt;/code&gt;.  We also use next
terminal states indicators and future value estimators in special cases.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;returns&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:[]&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;]

    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;
       &lt;span style=&#34;color:#75715e&#34;&gt;-- Discounting a future return&lt;/span&gt;
       &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;In policy gradient algorithms we evaluate how good are our past decisions
with respect to the future outcomes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note that we compute the return recursively as in equation above: reward
plus a discounted &lt;em&gt;future&lt;/em&gt; return. Since Haskell is a &lt;em&gt;lazy&lt;/em&gt; programming
language, it is not critical that this value does not exist yet.
Essentially, we promise to compute the list of &lt;em&gt;future&lt;/em&gt; values &lt;code&gt;y = f xs&lt;/code&gt;.
Finally, we prepend current return to the list of future returns
&lt;code&gt;r + γ * (head y) : y&lt;/code&gt;. Fascinating!&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;optimizing-parameters&#34;&gt;Optimizing parameters&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Computing the loss.&lt;/li&gt;
&lt;li&gt;Running a gradient step.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sumAll&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt;
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;final-bits&#34;&gt;Final Bits&lt;/h3&gt;

&lt;p&gt;There are still a few other things to complete the project. Let&#39;s define our
policy network type $\Phi$. Here we have three fully-connected layers. In other
words, two hidden layers.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;pl1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  , &lt;span style=&#34;color:#a6e22e&#34;&gt;pl2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  , &lt;span style=&#34;color:#a6e22e&#34;&gt;pl3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now we can implement the forward pass in a Policy Network:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;policy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;policy&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (   &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pl1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pl2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pl3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;softmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)) &lt;span style=&#34;color:#a6e22e&#34;&gt;state&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;An agent is simply a policy network in Reinforce.
We will update this data type to also accommodate the &lt;em&gt;critic&lt;/em&gt; network
in improved policy gradient later on:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;REINFORCE Trainer type is a single optimizer.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Adam&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A new, untrained agent with random weights&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;mkAgent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;mkAgent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actDim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;samplePhi&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Parameters $\phi \in \Phi$ initialization&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;samplePhi&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;samplePhi&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;)
     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;)
     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;actDim&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Initializing the trainer&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;mkTrainer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;mkTrainer&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;par&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flattenParameters&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mkAdam&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.999&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;par&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, let&#39;s train the agent to solve the classic CartPole environment!
See the complete REINFORCE project on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day10/Reinforce.lhs&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;proximal-policy-optimization&#34;&gt;Proximal Policy Optimization&lt;/h2&gt;

&lt;p&gt;REINFORCE algorithm is nice because it is simple. On the other hand,
in practice it has a problem: finding the best meta-parameters, such
as learning rate. Choose a value to low and training needs more samples,
too high and it does not converge. To alleviate this training instability
multiple variations of this algorithm have been proposed. One popular
variation is called Proximal Policy Optimization (PPO). Below we upgrade
REINFORCE to PPO.&lt;/p&gt;

&lt;h3 id=&#34;actor-critic-style&#34;&gt;Actor-Critic Style&lt;/h3&gt;

&lt;p&gt;In REINFORCE we only had a policy network $\pi_{\phi}$. A more advanced
version would be not only to use a policy network (so-called &lt;em&gt;actor&lt;/em&gt;),
but also a value network (&lt;em&gt;critic&lt;/em&gt;). This value network would estimate
how good is the state we are currently in. Naturally, the output of the
critic network is a scalar with this estimated state value.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- Value (Critic) Network type: Three fully-connected layers&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  , &lt;span style=&#34;color:#a6e22e&#34;&gt;l2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  , &lt;span style=&#34;color:#a6e22e&#34;&gt;l3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;-- | Forward pass in a Critic Network&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;critic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;critic&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;state&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l3&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;state&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is how we will sample initial network weights:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sampleTheta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;sampleTheta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obsDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;)
     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt;)
     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hiddenDim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To make our life a bit simpler, we can also use the following wrapper when
dealing with raw observations.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- | Get value: Convenience wrapper around `critic` function.&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;value&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Theta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;value&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;θ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unsqueeze&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;critic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;θ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ob_&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The state value given by the critic network will be used for &lt;em&gt;advantage&lt;/em&gt;
estimation, instead of simply calculating discounted returns.&lt;/p&gt;

&lt;h3 id=&#34;advantage-estimation&#34;&gt;Advantage Estimation&lt;/h3&gt;

&lt;p&gt;As you remember, in policy gradients we optimize neural network
parameters using $\mathbf{A} \cdot \nabla \log \pi_{\phi}(a_t|s_t)$.
In REINFORCE, this term $\mathbf{A} = R_t$ is discounted returns.
This totally makes sense. However, this is not the only option&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-5&#34;&gt;&lt;a href=&#34;#fn:fn-5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Let me introduce advantage $A = r - v$ where $r$ is reward and $v$ is value,
i.e. how good is our action. The advantage tells us how current action is
better than an &lt;em&gt;average&lt;/em&gt; action. Therefore, by optimizing our policy with
respect to advantage, we would improve our actions compared to average. This
would help to reduce &lt;em&gt;variance&lt;/em&gt; of policy gradient.&lt;/p&gt;

&lt;p&gt;In PPO, we typically use a fancy way to estimate the advantage called
generalized advantage estimator (GAE).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;advantages&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dones&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;L&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;zip4&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rs&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;L&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;drop&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dones&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;vs&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;L&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;drop&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vs&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;-- vs are current values (denoted by v) and&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;-- (L.drop 1 vs) are future values (denoted by v&amp;#39;)&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Not necessary to reverse the list if using lazy evaluation&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; [(&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Bool&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;)] &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; [&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;]
    &lt;span style=&#34;color:#75715e&#34;&gt;-- End of list to be reached: same as terminal (auxiliary value)&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;:[]&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;]

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Next state terminal&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Next state non-terminal&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;v&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;delta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;r&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;v&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;v&lt;/span&gt;
       &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;γ&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;ppo-specifics&#34;&gt;PPO Specifics&lt;/h3&gt;

&lt;p&gt;In REINFORCE, the policy gradient loss function was simply&lt;/p&gt;

&lt;p&gt;$$L(\phi) = -\sum_{t} \log \pi_{\phi}(a_t|s_t) \cdot R_t.$$&lt;/p&gt;

&lt;p&gt;Note the negation sign in front: without it, the loss (to be minimized) becomes
an objective (to be maximized) - earning highest returns&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-6&#34;&gt;&lt;a href=&#34;#fn:fn-6&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;p&gt;$$L(\phi) = \sum_{t} \log \pi_{\phi}(a_t|s_t) \cdot R_t.$$&lt;/p&gt;

&lt;p&gt;Now, what distinguishes PPO, it its objective. It consists of three
components: a clipped policy gradient objective (actor network), value loss (critic network),
and entropy bonus. Since the value function is a loss term, it has a minus sign:&lt;/p&gt;

&lt;p&gt;$$L_t^{PPO} = L_t^{CLIP} - c_1 L^{VF} + c_2 S,$$&lt;/p&gt;

&lt;p&gt;where $c_1 = 0.5$ and $c_2=0.01$ are constants. If we are going to minimize
loss instead,&lt;/p&gt;

&lt;p&gt;$$L_t^{PPO} = -L_t^{CLIP} + c_1 L^{VF} - c_2 S = $$
$$ = L_t^{PG} + c_1 L^{VF} - c_2 S.$$&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pg&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vfC&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mulScalar&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;vLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entC&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mulScalar&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;entropyLoss&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, the most interesting part of PPO. If we denote $r_t(\phi)$
the probability ratio
$r_t(\phi) = \frac{\pi_{\phi}(a_t|s_t)}{\pi_{\phi_{\text{old}}}(a_t|s_t)}$.
Then PPO is maximizing the following objective&lt;/p&gt;

&lt;p&gt;$$ L^{CLIP}(\phi) = \mathbb{\hat E}_t \left( \min \left( r_t(\phi) \hat A_t, \text{clip}(r_t(\phi), 1 - \epsilon, 1 + \epsilon) \hat A_t \right) \right).$$&lt;/p&gt;

&lt;p&gt;First, let&#39;s take a look at the clipped objective
$\text{clip}(r_t(\phi), 1 - \epsilon, 1 + \epsilon) \hat A_t$.
Here, we try to restrict how far our policy will move during the policy
gradient update. If advantage $A$ is positive, the objective is clipped at
value $1 + \epsilon$. If advantage $A$ is negative, then the objective is
clipped at $1 - \epsilon$. Finally, we take a min between a clipped and
unclipped objective. Therefore, the final objective is a pessimistic bound on
the unclipped objective (see &lt;a href=&#34;http://arxiv.org/abs/1707.06347&#34;&gt;Schulman et al.&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Now, transforming the objective into a loss: we add a minus sign and
replace min with max:&lt;/p&gt;

&lt;p&gt;$$ L^{PG}(\phi) = \sum_t \max \left( -r_t(\phi) \hat A_t, -\text{clip}(r_t(\phi), 1 - \epsilon, 1 + \epsilon) \hat A_t \right).$$&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clamp&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ratio&amp;#39;&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note that for better numerical properties we typically use &lt;code&gt;logratio&lt;/code&gt;, instead
of &lt;code&gt;ratio&lt;/code&gt; (a log of a ratio is the difference of logs):&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newlogprobs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code&gt;newlogprobs&lt;/code&gt; are calculated by evaluating the new policy.&lt;/p&gt;

&lt;p&gt;Next term $L_t^{VF}$ is often a squared-error loss
$(V_{\theta}(s_t) - V_t^{\text{targ}})^2$.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;vLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;newvalues&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;However, we use &lt;a href=&#34;https://arxiv.org/pdf/2005.12729.pdf&#34;&gt;clipped value loss&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;clippedValueLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newval&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ret&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lossUnclipped&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;newval&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ret&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;clipped&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;clamp&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;newval&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val&lt;/span&gt;))
      &lt;span style=&#34;color:#a6e22e&#34;&gt;lossClipped&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;clipped&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ret&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;lossMax&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lossUnclipped&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lossClipped&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lossMax&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, the entropy bonus $S$ is used in order to stimulate exploration,
i.e. performing the same task by as many ways as possible.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;entropyLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is updated &lt;code&gt;evaluate&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- | Get action, logProb, and entropy tensors&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Phi&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- ^ Policy weights&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- ^ Observations&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Maybe&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- ^ Action&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;probs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;policy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Categorical&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;fromProbs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;probs&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logProb&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;)
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Maybe&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Categorical&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Categorical&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Nothing&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;D&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dist&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;shape&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs&lt;/span&gt;]
      &lt;span style=&#34;color:#a6e22e&#34;&gt;_getAct&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Putting it all together, we get this &lt;code&gt;optimize&lt;/code&gt; function:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;optimize&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Config&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;acs_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advantages_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  (&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;newlogprobs&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;evaluate&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_t&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Just&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;acs_t&lt;/span&gt;)

  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newvalues&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;critic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;θ&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;obs_t&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newlogprobs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logprobs_t&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Normalized advantages&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;advantages_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advantages_t&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;std&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advantages_t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-8&lt;/span&gt;)

      &lt;span style=&#34;color:#a6e22e&#34;&gt;pg&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pgLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logratio&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;advNorm&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;vLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clippedValueLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clipC&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;val_t&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newvalues&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;returns_t&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;entropyLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mean&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pg&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vfC&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mulScalar&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;vLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entC&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mulScalar&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;entropyLoss&lt;/span&gt;

  ((&lt;span style=&#34;color:#a6e22e&#34;&gt;θ&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&amp;#39;&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;θ&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;)

  &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Agent&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;θ&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ϕ&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Trainer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;See the complete code on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day10/Ppo.hs&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;alphago-vs-lee-sedol&#34;&gt;AlphaGo vs Lee Sedol&lt;/h2&gt;

&lt;p&gt;We started this article with the defeated Go champion Lee Sedol. He played
against software called AlphaGo (version Lee, after him). How &lt;em&gt;actually&lt;/em&gt; did
AlphaGo win? What is &lt;em&gt;self-play&lt;/em&gt; and how does it relate to reinforcement
learning? Below we will address those questions.&lt;/p&gt;

&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;

&lt;p&gt;AlphaGo generates data by playing games against an opponent (since the game of
Go is a two-player game). This opponent is another machine player randomly
chosen from a pool of opponents. In the end of the game one player
wins (reward $r = +1$) and another loses (reward $r = -1$).&lt;/p&gt;

&lt;p&gt;After several games have been played, the player is updated. Then, this new
player is compared to the old one. If the new one wins sufficiently often, it
is then accepted. Iteration by iteration, and the AlphaGo is improved by
playing against itself. This is called a &lt;em&gt;self-play&lt;/em&gt;. Below, we are going into
mode details.&lt;/p&gt;

&lt;h3 id=&#34;monte-carlo-tree-search&#34;&gt;Monte Carlo Tree Search&lt;/h3&gt;

&lt;p&gt;We should introduce a new concept called Monte Carlo Tree Search. Monte Carlo,
if you didn&#39;t know, is the area in the city-state of Monaco. It is also the
European gambling capital. Some rich people like to waste money in the Monte
Carlo casino. The author had a chance to visit it once and can confirm that is
absolutely true.&lt;/p&gt;

&lt;p&gt;Anyway, I digress. Statisticians simply love calling everything &lt;em&gt;Monte Carlo&lt;/em&gt;
when there are random simulations involved. For example, have you noticed that
REINFORCE is also named Monte Carlo Policy Gradient? This is related to
stochastic trajectories generated during rollouts.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/mcts.jpg&#34; alt=&#34;Monte Carlo Tree Search. Source: [Silver *et al.*](http://dx.doi.org/10.1038/nature16961)&#34; width=&#34;690px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;&lt;/h4&gt;
  &lt;p&gt;
    Monte Carlo Tree Search. Source: &lt;a href=&#34;http://dx.doi.org/10.1038/nature16961&#34;&gt;Silver &lt;em&gt;et al.&lt;/em&gt;&lt;/a&gt;
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Monte Carlo Tree Search (MCTS) explores a tree of possible moves and is
continuously refining its understanding of the game state by simulating random
rollouts (also called playouts because of the game aspect). In Monte Carlo
tree, each node is a board state (see Fig. 1). For each board state, we
estimate the &lt;em&gt;value&lt;/em&gt; of this state $Q$. That is how good it is or, in other
words, whether we believe this board position is leading to a win or loss.  The
innovation behind AlphaGo was in combining MCTS with convolutional neural
networks for state value estimation and for selecting the move to play.&lt;/p&gt;

&lt;p&gt;In the first MCTS stage called &lt;em&gt;Selection&lt;/em&gt; (Fig. 1&lt;strong&gt;a&lt;/strong&gt;),
an action is selected to maximize the value $Q$ plus some bonus $u(P)$
that encourages exploration. This bonus is designed such that in the beginning
the algorithm prefers actions with high prior probability $P$ and low
visit count; and eventually it prefers actions with high action value $Q$.
This is achieved by weighting the bonus term by an exploration constant.&lt;/p&gt;

&lt;p&gt;After a certain depth of Monte Carlo tree is reached, the second stage
&lt;em&gt;Evaluation&lt;/em&gt; (Fig. 1&lt;strong&gt;c&lt;/strong&gt;) is performed: current position (leaf node in tree)
is evaluated using the value network. And the actions (game moves) are selected
according to the policy network $\pi$ until the end of the game (terminal state),
which leads to the &lt;em&gt;outcome&lt;/em&gt; $\pm r$.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;em&gt;Backup&lt;/em&gt; is performed (Fig. 1&lt;strong&gt;d&lt;/strong&gt;): the rollout statistics are
updated by adding the outcome in a backward pass through the Monte Carlo tree.
In the end, the value estimate $Q(s,a)$ becomes a weighted sum of the value
network and just obtained rollout statistics. At the end of the search the
algorithm selects an action with the maximum visit count. The authors state
that this is less sensitive to outliers as compared to maximizing action value.&lt;/p&gt;

&lt;p&gt;One more thing: when the number of certain node visits is frequent, the
successor state is added to the tree. This is called &lt;em&gt;Expansion&lt;/em&gt; (Fig. 1&lt;strong&gt;b&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;Coming back to the neural networks you might be pleased to learn that the
policy network $\pi$ was trained using the REINFORCE algorithm you already
know. Each iteration consisted of a minibatch of several games played between
the current policy network $\pi_{\phi}$ and an opponent $\pi_{\phi}-$ using
parameters from the previous iteration. Every 500 iterations, parameters
$\phi$ were saved to the opponent pool (so that there is always a variety
of opponents to choose from).&lt;/p&gt;

&lt;p&gt;The value network was trained to approximate the value function of the RL
policy network $\pi_{\phi}$. This was a regression task. The network was
trained on a dataset of 30 million positions drawn from the self-play.  There
are many interesting technical aspects I suggest to read about in the &lt;a href=&#34;http://dx.doi.org/10.1038/nature16961&#34;&gt;original
publication&lt;/a&gt;. &lt;!-- For instance, invalid game moves are masked out
during the MCTS simulation so that they are never selected. --&gt;&lt;/p&gt;

&lt;p&gt;To summarize, Monte Carlo Tree Search was employed in AlphaGo because an
exhaustive search is simply impossible as the game tree quickly grows too
large. The idea of MCTS combined with neural networks is conceptually simple
and provided sufficient computational resources, it wins.&lt;/p&gt;

&lt;h3 id=&#34;instead-of-conclusion&#34;&gt;Instead of Conclusion&lt;/h3&gt;

&lt;p&gt;Beating the strongest human player is an amazing feat by the DeepMind team.
However, we should not forget that behind the scenes there was operating a
whole data center to support AlphaGo computation. This is about six orders of
magnitude more power consumption compared to the human brain (~20W)!
Devising energy-efficient AI hardware is therefore our
&lt;a href=&#34;https://penkovsky.com/project/edge-ai/&#34;&gt;next milestone&lt;/a&gt; we are heading to.&lt;/p&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;pre&gt;
@article{penkovsky2023RL,
 title   = &#34;Beyond Supervised Learning&#34;,
 author  = &#34;Penkovsky, Bogdan&#34;,
 journal = &#34;penkovsky.com&#34;,
 year    = &#34;2023&#34;,
 month   = &#34;May&#34;,
 url     = &#34;https://penkovsky.com/neural-networks/beyond/&#34;
}
&lt;/pre&gt;

&lt;p&gt;If you like the article please consider sharing it.&lt;/p&gt;

&lt;h2 id=&#34;goodbye&#34;&gt;Goodbye?&lt;/h2&gt;

&lt;p&gt;I have to admit that after all these days we have barely scratched the surface.
Yet, I am happy about the journey we have made.  We have seen how to create
neural networks and to benefit from them; how to estimate model uncertainty;
how to generate new things. And today we have learned how to continuously make
decisions. There are so many more ideas to explore! Reinforcement learning is a
rabbit hole in itself. By the way, did you know that ChatGPT is secretly using
PPO to get better answers?&lt;/p&gt;

&lt;p&gt;Let me know if you have any remarks.&lt;/p&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.davidsilver.uk/wp-content/uploads/2020/03/pg.pdf&#34;&gt;D. Silver. Policy Gradient - Lecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/221402/understanding-the-role-of-the-discount-factor-in-reinforcement-learning&#34;&gt;Understanding the role of the discount factor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/learn/deep-rl-course&#34;&gt;Hugging Face Deep RL Course&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://journals.sagepub.com/doi/pdf/10.1177/0278364919887447&#34;&gt;Learning dexterous in-hand manipulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1810.05687&#34;&gt;Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cse-robotics.engr.tamu.edu/dshell/cs689/papers/jakobi95noise.pdf&#34;&gt;Noise and The Reality Gap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/blog/deep-rl-pg&#34;&gt;Policy Gradient with PyTorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1707.06347&#34;&gt;Proximal Policy Optimization Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2005.12729.pdf&#34;&gt;Implementation matters in deep policy gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dx.doi.org/10.1038/nature16961&#34;&gt;Mastering the game of Go with deep neural networks and tree search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dx.doi.org/10.1038/nature24270&#34;&gt;Mastering the game of Go without human knowledge&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; } }
});
&lt;/script&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;This is what we were doing all the days before. Supervised learning. That is how it is called. One of my favourite teachers used to quote Molière, &amp;quot;&lt;em&gt;Par ma foi, il y a plus de quarante ans que je dis de la prose, sans que j&#39;en susse rien&lt;/em&gt;&amp;quot; (&amp;quot;These forty years now I&#39;ve been speaking in prose without knowing it!&amp;quot;).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-2&#34;&gt;Honestly, I have no clue how a director of AI works at Tesla. But if you Andrej Karpathy and you are reading this, please share your past experiences. I would appreciate.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-3&#34;&gt;A trajectory is a repetitive sequence of observations and actions.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-4&#34;&gt;In Haskell it is possible to benefit from existing OpenAI Gym environments via &lt;a href=&#34;https://github.com/stites/gym-http-api&#34;&gt;Gym HTTP API&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-4&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-5&#34;&gt;See D. Silver&#39;s Lecture about &lt;a href=&#34;https://www.davidsilver.uk/wp-content/uploads/2020/03/pg.pdf&#34;&gt;Policy Gradients&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-5&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-6&#34;&gt;PyTorch seems to be better at minimizing rather than maximizing.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-6&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Towards Autonomous Synthesis With Deep Reinforcement Learning</title>
      <link>https://penkovsky.com/talk/towards-autonomous-synthesis2022/</link>
      <pubDate>Wed, 31 Aug 2022 20:05:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/talk/towards-autonomous-synthesis2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Day 9: Roaming The Latent Space</title>
      <link>https://penkovsky.com/neural-networks/day9/</link>
      <pubDate>Thu, 11 Aug 2022 10:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/day9/</guid>
      <description>

&lt;p&gt;Imagine you are a designer and you want a new font: A little bit heavier, with
rounder letters, more casual or a little bit more fancy. Could
this font be created just by tuning a handful of parameters?  Or imagine
that you are a fashion designer and you would like to create a new collection
as a mix of previous seasons?  Or that you are a musician desperately looking
for inspiration. How about a new song that mixes your mood and
Beethoven&#39;s Symphony No 3? It turns out, all this is actually possible.  To
better illustrate the concept, here is some music
interpolation:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/G5JT16flZwM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Don&#39;t forget to check out&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day8/&#34;&gt;Day 8: Model Uncertainty Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day7/&#34;&gt;Day 7: Real World Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The complete project is also available &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day9&#34;&gt;on Github&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;the-secret-space&#34;&gt;The Secret Space&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;latent&lt;/em&gt; - present and capable of emerging or developing but not now visible, obvious, active, or symptomatic&lt;/p&gt;

&lt;p&gt;—Webster&#39;s Dictionary&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;autoencoders&#34;&gt;Autoencoders&lt;/h3&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/ae_mlp.png&#34; alt=&#34;A simple autoencoder with latent dimension $L$.&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    A simple autoencoder with latent dimension $L$.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;How do we implement an autoencoder? Let us take a multilayer network from the
image above: $784 \rightarrow 400 \rightarrow L \rightarrow 400 \rightarrow
784$. Where the latent space dimension $L$ is some smaller number such as $20$
or maybe even $2$. The $L$-sized &lt;em&gt;latent&lt;/em&gt; vector $z$ is often called a
&lt;em&gt;bottleneck&lt;/em&gt;. The left part from the bottleck is called an &lt;em&gt;encoder&lt;/em&gt;
$q_{\phi}$ and the part on the right, a &lt;em&gt;decoder&lt;/em&gt; $p_{\theta}$. Where
$\phi$ and $\theta$ are trainable parameters of encoder and decoder,
respectively.&lt;/p&gt;

&lt;p&gt;The encoder takes an input (like an image) and generates a compact
representation, typically a vector. It is also not a mistake to call it a
&lt;em&gt;compressed representation&lt;/em&gt;. The decoder takes this compact representation and
creates an output as close as possible to the original input. Hence the name,
autoencoder. Of course, some information is lost due to the dimensionality
reduction. Therefore, the goal of a autoencoder is to find the most relevant
features to preserve as much information about the input object as possible.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AE&lt;/span&gt;
  { &lt;span style=&#34;color:#75715e&#34;&gt;-- Encoder parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Decoder parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, the whole autoencoder network is&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;ae&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;ae&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Encoder&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Decoder&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l3&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l4&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can also specify the exact dimensions&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;aeConfig&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;AESpec&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Of course, a smaller $L$ (&lt;code&gt;latent_size&lt;/code&gt;), the more information is lost.
Therefore, depending on the application we may want to change this value.
As a rule of thumb, $L$ contains the smallest number of neurons to enforce the
compression. In this article we set $L=2$ so that we can simply reveal our
latent space in two dimensions.&lt;/p&gt;

&lt;h3 id=&#34;variational-autoencoder&#34;&gt;Variational autoencoder&lt;/h3&gt;

&lt;p&gt;The principal difference of variational autoencoders (VAE)
from normal autoencoders is in the bottleneck. Instead of
a compressed input, it estimates a &lt;em&gt;distribution&lt;/em&gt;. In practice, VAE estimates
the mean $\mu$ and the standard deviation $\sigma$ -- normal distribution
parameters. By sampling from that distribution, a new unseen before object can
be generated. Like a new font or a new piece of cloth. Or a face. Or a melody.
Isn&#39;t that nice?&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/vae_mlp.png&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Variational autoencoder. Arrows signify fully-connected layers and vertical bars are data vectors.&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt;
  {
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Encoder trainable parameters (phi)&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fcMu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fcSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Decoder trainable parameters (theta)&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc6&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Eq&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;myConfig&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lMu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It can be useful to have separate &lt;code&gt;encode&lt;/code&gt; $q_{\phi}(z|x)$
and &lt;code&gt;decode&lt;/code&gt; $p_{\theta}(x|z)$ functions.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enc_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l1&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enc_&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lMu&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lSigma&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l4&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l5&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, the complete variational autoencoder will be&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;vaeForward&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Bool&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;vaeForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;}) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;sigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)

  &lt;span style=&#34;color:#a6e22e&#34;&gt;eps&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randnLikeIO&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigma&lt;/span&gt;

  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;z&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;eps&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mul&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;sigma&lt;/span&gt;) `&lt;span style=&#34;color:#a6e22e&#34;&gt;add&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;reconstruction&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;z&lt;/span&gt;

  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;reconstruction&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Pay a special attention to the &lt;em&gt;reparametrization&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;$$\varepsilon \sim \mathcal{N}(0,\,1)$$
$$z = \varepsilon \odot \sigma + \mu$$&lt;/p&gt;

&lt;p&gt;Where $z$ is our latent vector, noise $\varepsilon$ is sampled from the normal
distribution (&lt;code&gt;randnLikeIO&lt;/code&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-2&#34;&gt;&lt;a href=&#34;#fn:fn-2&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;), and $\odot$ is elementwise product. Thanks
to this trick, we can backpropagate through a stochastic layer. See this
excellent &lt;a href=&#34;https://gregorygundersen.com/blog/2018/04/29/reparameterization/&#34;&gt;post&lt;/a&gt; for more details.  There are two differences
between variational and ordinary autoencoder training: (1) the
reparametrization and (2) the loss function, which we cover below.&lt;/p&gt;

&lt;h3 id=&#34;vae-loss-function&#34;&gt;VAE Loss Function&lt;/h3&gt;

&lt;p&gt;The loss function consists of two parts:&lt;/p&gt;

&lt;p&gt;$$ \rm{loss} = \mathbb{L}(x, \hat x) + \rm{D}_\rm{KL} \left(q_\phi(z) || p_\theta(z) \right).$$&lt;/p&gt;

&lt;p&gt;$\mathbb{L}(x, \hat x)$ is the &lt;em&gt;reconstruction loss&lt;/em&gt;.  It decreases
when the decoded output $\hat x$ is closer to the original input $x$.  This is
basically the loss of an ordinary autoencoder. For instance, it can be binary
cross-entropy loss or L2 loss.&lt;/p&gt;

&lt;p&gt;And the second term $\rm{D_{KL}}( \cdot )$ is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&#34;&gt;Kullback-Leibner
divergence&lt;/a&gt;. It tells how much the distribution $p_\theta(z)$ &lt;a href=&#34;https://blog.evjang.com/2016/08/variational-bayes.html&#34;&gt;is
different&lt;/a&gt; from the distribution $q_\phi(z)$.  Or even more
informative is to say that KL divergence tells how much information is lost if
the distribution $p_\theta$ is used to represent $q_\phi$.  From the
original &lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34;&gt;paper&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;$$ -\rm{D_{KL}}\left(q_\phi(z) || p_\theta(z) \right) =\frac 1 2 \sum_{j=1}^J \left( 1 + \log(\sigma_j^2) - \mu_j^2 - \sigma_j^2  \right).$$&lt;/p&gt;

&lt;p&gt;Therefore, the complete VAE loss is&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;vaeLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;vaeLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;recon_x&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reconLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;kld&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;reconLoss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bceLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;recon_x&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;kld&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sumAll&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pow&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We also include the $\beta \ge 0$ term. When $\beta = 0$ the networks is trained as an
ordinary autoencoder. When $\beta = 1$, we have a classical VAE. And when
$\beta &amp;gt; 1$, we force latent vector &lt;a href=&#34;https://openreview.net/pdf?id=Sy2fzU9gl&#34;&gt;representations
disentanglement&lt;/a&gt;. As we can see from the image below, in case of
disentanglement, there are separate latent variables that encode position,
rotation, and scale. Whereas entangled variables tend to encode all object
properties at the same time. I recommend the excellent &lt;a href=&#34;https://arxiv.org/abs/1606.05579&#34;&gt;article by Higgins et
al.&lt;/a&gt;, which is featuring some insights from neuroscience.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/articles/Higgins16.png&#34; alt=&#34;Disentangled vs entangled latent representations. &amp;lt;small&amp;gt;Image source: [Higgins et al. 2016](https://arxiv.org/abs/1606.05579).&amp;lt;/small&amp;gt;&#34; width=&#34;600px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Disentangled vs entangled latent representations. &lt;small&gt;Image source: &lt;a href=&#34;https://arxiv.org/abs/1606.05579&#34;&gt;Higgins et al. 2016&lt;/a&gt;.&lt;/small&gt;
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The binary cross-entropy loss is defined as&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;bceLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;target&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sumAll&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-10&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;target&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-10&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;target&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We add a small term $10^{-10}$ to avoid numerical errors due to $\log(0)$.&lt;/p&gt;

&lt;h2 id=&#34;visualizing-the-latent-space&#34;&gt;Visualizing the Latent Space&lt;/h2&gt;

&lt;p&gt;Here is how our latent space looks for different values of $\beta$.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/vae_beta_0.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/vae_beta_1.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/vae_beta_4.png&#34; alt=&#34;Test data distributions for different $\beta$ values.&#34; width=&#34;500px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Test data distributions for different $\beta$ values.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;And here is how we compute that&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    (&lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;myConfig&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getArgs&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;beta = &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt; }
        &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt; }
        &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;cpt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;VAE-Aug2022-beta_%s.ht&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;beta_%s.log&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Starting training...&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;time&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnistStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Done&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Saving the trained model&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;save&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cpt&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Restoring the model&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;cpt&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Test data distribution in the latent space&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Saving test dataset distribution to &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testLatentSpace&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Where&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;testLatentSpace&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FilePath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;testLatentSpace&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fn&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;testStream&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;recordPoints&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fn&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;recordPoints&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FilePath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ListT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;recordPoints&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enumerateData&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; () &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; () &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;labels&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt;
          (&lt;span style=&#34;color:#a6e22e&#34;&gt;encMu&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;shape&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;encMu&lt;/span&gt;

      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toStr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) [&lt;span style=&#34;color:#a6e22e&#34;&gt;reshape&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#a6e22e&#34;&gt;labels&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;encMu&lt;/span&gt;]
      &lt;span style=&#34;color:#a6e22e&#34;&gt;appendFile&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logname&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;s&lt;/span&gt;

      &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; ()

    &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt; () &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; ()
    &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; ()

&lt;span style=&#34;color:#a6e22e&#34;&gt;toStr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;String&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;toStr&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; [[&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;]]
        &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;unwords&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;
     &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unlines&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, let&#39;s take a walk around our latent space to get an idea how it looks like inside.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;VAE-Aug2022-beta_1.ht&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.7&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;]

        &lt;span style=&#34;color:#75715e&#34;&gt;-- 2D latent space as a Cartesian product&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;zs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [ [&lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;,&lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;y&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;xs&lt;/span&gt; ]

        &lt;span style=&#34;color:#a6e22e&#34;&gt;decoded&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;
                    &lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asTensor&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;:[]&lt;/span&gt;)) &lt;span style=&#34;color:#a6e22e&#34;&gt;zs&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;writeFile&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;latent_space_2D.txt&amp;#34;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;toStr&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;decoded&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/latent_space_21x21.png&#34; alt=&#34;Some examples from 2D latent space.&#34; width=&#34;600px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Some examples from 2D latent space.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Pretty neat! We see gradual transitions between different
digits. Note that these digits are actually &lt;em&gt;generated&lt;/em&gt; by VAE.&lt;/p&gt;

&lt;h2 id=&#34;convnet-vae&#34;&gt;ConvNet VAE&lt;/h2&gt;

&lt;p&gt;While we have built a simple variational autoencoder based on
MLP (&lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;multilayer perceptron&lt;/a&gt;), nothing prevents us
from using other architectures. In fact, let&#39;s build a
&lt;a href=&#34;https://penkovsky.com/neural-networks/day5/&#34;&gt;convolutional&lt;/a&gt; VAE!&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt;
  {
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Encoder trainable parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;conv1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;conv3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fcMu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fcSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Decoder trainable parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Eq&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;myConfig&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)    &lt;span style=&#34;color:#75715e&#34;&gt;-- 1 -&amp;gt; 32 channels; 4 x 4 kernel&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)   &lt;span style=&#34;color:#75715e&#34;&gt;-- 32 -&amp;gt; 64 channels; 4 x 4 kernel&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;-- 64 -&amp;gt; 128 channels; 3 x 3 kernel&lt;/span&gt;
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;latent_size&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)
    (&lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2dSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;c1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;c2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;c3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Conv2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lMu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;l&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;t1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;t2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2d&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;t3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ConvTranspose2d&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;instance&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Randomizable&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAESpec&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv1&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv3&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fcMu&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fcSigma&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv1&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv2&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;deconv3&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;encode&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enc_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- Reshape vectors [batch_size x 784]&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- into grayscale images of [batch_size x 1 x 28 x 28]&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;reshape&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;]
          &lt;span style=&#34;color:#75715e&#34;&gt;-- Stride 2, padding 0&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c1&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c2&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;conv2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c3&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flatten&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))

      &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enc_&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lMu&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lSigma&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;
   &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;decode&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
         &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;l&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reshape&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
         &lt;span style=&#34;color:#75715e&#34;&gt;-- Stride 2, padding 0&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;convTranspose2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;t1&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;convTranspose2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;t2&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;convTranspose2dForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;t3&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;
         &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reshape&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;-- Reshape back&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And that is all we need.&lt;/p&gt;

&lt;p&gt;Here is the latent space for $\beta=1$ (normal VAE) using our CNN architecture:&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/latent_space_cnn_beta_1.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;disentanglement&#34;&gt;Disentanglement&lt;/h3&gt;

&lt;p&gt;To better illustrate how parameter $\beta$ encourages disentanglement between
latent representations, let us first increase the latent dimension to $L=10$.
For $\beta=1$ and $\beta=4$ we perform scan along each individual $z$ coordinate.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/latent_space_cnn_beta_1_z10.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/latent_space_cnn_beta_4_z10.png&#34; width=&#34;500px&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;Indeed, the latent space under $\beta=4$ looks more disentangled compared to
$\beta=1$. We can see e.g. that $z_1$ is the parameter that defines how
&amp;quot;light&amp;quot; or how &amp;quot;bold&amp;quot; is the digit, whereas $z_2$ controls how wide is the
digit. Whereas such individual components for $\beta=1$ are hard to identify.
For instance when $\beta=1$, $z_4$ controls not only how &amp;quot;bold&amp;quot; is the digit,
but also its shape.&lt;/p&gt;

&lt;p&gt;For more details, see this &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/blob/master/day9/data/cnn/visualize.ipynb&#34;&gt;notebook&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Find the complete project and associated data on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day9&#34;&gt;Github&lt;/a&gt;. For
suggestions about the content feel free to open a
&lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/issues&#34;&gt;new issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Variational autoencoder is a great tool in modern deep learning. Manipulating
the latent space allows us not only to &amp;quot;interpolate&amp;quot; between different images
or other objects, but also to perform &lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Peng_Generating_Diverse_Structure_for_Image_Inpainting_With_Hierarchical_VQ-VAE_CVPR_2021_paper.pdf&#34;&gt;inpainting&lt;/a&gt; (adding details to
incomplete images) or even &lt;a href=&#34;https://arxiv.org/abs/1606.05579&#34;&gt;zero shot learning&lt;/a&gt;. The last one is
crucial for the so-called &lt;em&gt;artificial general intelligence&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The loss function is important for VAE training.
If your VAE does not work as expected, the odds
are that the loss function is not implemented correctly. Also check if the
random noise $\varepsilon$ is drawn from the normal distribution.&lt;/p&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;pre&gt;
@article{penkovsky2022VAE,
 title   = &#34;Roaming The Latent Space&#34;,
 author  = &#34;Penkovsky, Bogdan&#34;,
 journal = &#34;penkovsky.com&#34;,
 year    = &#34;2022&#34;,
 month   = &#34;August&#34;,
 url     = &#34;https://penkovsky.com/neural-networks/day9/&#34;
}
&lt;/pre&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34;&gt;Auto-Encoding Variational Bayes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.evjang.com/2016/08/variational-bayes.html&#34;&gt;A Beginner&#39;s Guide to Variational Methods: Mean-Field Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1606.05579&#34;&gt;Early Visual Concept Learning with Unsupervised Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/examples/blob/main/vae/main.py&#34;&gt;Pytorch VAE Implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://magenta.tensorflow.org/music-vae&#34;&gt;Interpolating Music&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openreview.net/pdf?id=Sy2fzU9gl&#34;&gt;β-VAE: Learning Basic Visual Concepts With A Constrained Variational Framework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gregorygundersen.com/blog/2018/04/29/reparameterization/&#34;&gt;The Reparameterization Trick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1906.00446&#34;&gt;Generating Diverse High-Fidelity Images with VQ-VAE-2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Peng_Generating_Diverse_Structure_for_Image_Inpainting_With_Hierarchical_VQ-VAE_CVPR_2021_paper.pdf&#34;&gt;Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vincentcartillier.github.io/papers/variational-image-inpainting.pdf&#34;&gt;Variational Image Inpainting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;a-technical-sidenote&#34;&gt;A Technical Sidenote&lt;/h2&gt;

&lt;p&gt;Compared to the previous &lt;a href=&#34;https://penkovsky.com/neural-networks/day8/&#34;&gt;day&lt;/a&gt;, the &lt;code&gt;trainLoop&lt;/code&gt; is
slightly modified: First, we rescale the images between 0 and 1.  Second, we
include our new loss function in the &lt;code&gt;step&lt;/code&gt; function.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- Rescale pixel values [0, 255] -&amp;gt; [0, 1.0].&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- This is important as the sigmoid activation in decoder can&lt;/span&gt;
          &lt;span style=&#34;color:#75715e&#34;&gt;-- reach values only between 0 and 1.&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;x&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt;
      (&lt;span style=&#34;color:#a6e22e&#34;&gt;recon_x&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vaeForward&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&amp;#39;&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vaeLoss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;recon_x&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mu&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSigma&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Print loss every 100 batches&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mod&lt;/span&gt;` &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Batch: %d | Loss: %.2f&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;)
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;train&lt;/code&gt; function now uses Adam optimizer from &lt;code&gt;Torch.Optim.CppOptim&lt;/code&gt;, which
tends to be faster compared to &lt;code&gt;mkAdam&lt;/code&gt; we used previously.  This is not very
different from mkAdam-based training, except that the learning rate is
specified as &lt;code&gt;Cpp.adamLr&lt;/code&gt; parameter and not as a &lt;code&gt;trainLoop&lt;/code&gt; parameter (ignored
when passed to &lt;code&gt;runStep&lt;/code&gt;).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;VAE&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;initOptimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;adamOpt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;

    (&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foldLoop&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optState&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dsetOpt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt;)
      &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optState&lt;/span&gt;) &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;

    &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;dsetOpt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;workers&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;workers&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Adam optimizer parameters&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;adamOpt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;def&lt;/span&gt;
          { &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamLr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;learningRate&lt;/span&gt;,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamBetas&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.999&lt;/span&gt;),
            &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamEps&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-8&lt;/span&gt;,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamWeightDecay&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;adamAmsgrad&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;
          } &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;
          &lt;span style=&#34;color:#66d9ef&#34;&gt;Cpp&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;AdamOptions&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;learningRate&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Double&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;learningRate&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I used a compiled version instead of a notebook since the network training
worked much faster (the bottleneck was in training data mini-batches loading).
Also I have trained networks with &lt;code&gt;Torch.Optim.CppOptim&lt;/code&gt;. It is slightly faster
compared to &lt;code&gt;mkAdam&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I was also wondering why I get large values out of the encoder. It turns out
that this is because &lt;code&gt;relu&lt;/code&gt; function is unbounded. You may want to replace
&lt;code&gt;relu&lt;/code&gt; with &lt;code&gt;Torch.tanh&lt;/code&gt; and visualize the latent space again.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-2&#34;&gt;We use &lt;code&gt;sigma&lt;/code&gt; as an argument to &lt;code&gt;randnLikeIO&lt;/code&gt; so that the resulting random tensor has the same shape as &lt;code&gt;sigma&lt;/code&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Day 8: Model Uncertainty Estimation</title>
      <link>https://penkovsky.com/neural-networks/day8/</link>
      <pubDate>Sat, 23 Apr 2022 17:20:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/day8/</guid>
      <description>

&lt;p&gt;Wouldn&#39;t it be nice if the model also told us which predictions are not
reliable? Can this be done even on unseen data? The good news is yes, and even
on new, completely unseen data. It is also simple to implement in
practice.  A canonical example is in a medical setting. By measuring model
uncertainty, the doctor can learn how reliable is their AI-assisted patient&#39;s
diagnosis.  This allows the doctor to make a better informed decision whether
to trust the model or not. And potentially save someone&#39;s life.&lt;/p&gt;

&lt;p&gt;Today we build upon &lt;a href=&#34;https://penkovsky.com/neural-networks/day7/&#34;&gt;Day 7&lt;/a&gt; and we continue our
journey with Hasktorch:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We will introduce a Dropout layer.&lt;/li&gt;
&lt;li&gt;We will compute on a graphics processing unit (GPU).&lt;/li&gt;
&lt;li&gt;We will also show how to load and save models.&lt;/li&gt;
&lt;li&gt;We will train with &lt;a href=&#34;https://penkovsky.com/neural-networks/day2&#34;&gt;Adam&lt;/a&gt; optimizer.&lt;/li&gt;
&lt;li&gt;And finally we will talk about model uncertainty estimation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The complete project is also available &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day8&#34;&gt;on Github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;dropout-layer&#34;&gt;Dropout Layer&lt;/h2&gt;

&lt;p&gt;Neural networks, as any other model with many parameters, tend to overfit. By overfitting I mean
&amp;quot;&lt;a href=&#34;https://en.wikipedia.org/wiki/Overfitting&#34;&gt;fail to fit to additional data or predict future observations reliably&lt;/a&gt;&amp;quot;. Let us consider a classical example below.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/neural-networks/Overfitting.png&#34; alt=&#34;Overfitting. &amp;lt;small&amp;gt;Credit [Ignacio Icke](https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/480px-Overfitting.svg.png), [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)&amp;lt;/small&amp;gt;&#34; width=&#34;400px&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Overfitting. &lt;small&gt;Credit &lt;a href=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/480px-Overfitting.svg.png&#34;&gt;Ignacio Icke&lt;/a&gt;, &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;CC BY-SA 4.0&lt;/a&gt;&lt;/small&gt;
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The green line is a decision boundary created by an overfitted model.
We see that the model tries to memorize every possible data point.
However, it fails to generalize. To ameliorate the situation, we perform
a so-called &lt;em&gt;regularization&lt;/em&gt;. That is a technique that helps to prevent
overfitting. In the image above, the black line is a decision boundary of a
regularized model.&lt;/p&gt;

&lt;p&gt;One of regularization techniques for artificial neural networks is called
&lt;a href=&#34;https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf&#34;&gt;dropout&lt;/a&gt;
or &lt;a href=&#34;https://en.wikipedia.org/wiki/Dilution_(neural_networks)&#34;&gt;dilution&lt;/a&gt;.
Its principle of operation is quite simple.  During neural network training, we
randomly disconnect a fraction of neurons with some probability.  It turns out
that dropout conditioning results in more reliable neural network models.&lt;/p&gt;

&lt;h2 id=&#34;a-neural-network-with-dropout&#34;&gt;A Neural Network with Dropout&lt;/h2&gt;

&lt;p&gt;The data structures &lt;code&gt;MLP&lt;/code&gt; (learnable parameters) and &lt;code&gt;MLPSpec&lt;/code&gt; (number of
neurons) remain unchanged.  However, we will need to modify the &lt;code&gt;mlp&lt;/code&gt; function
(full network) to include a Dropout layer. If we inspect
&lt;code&gt;dropout :: Double -&amp;gt; Bool -&amp;gt; Tensor -&amp;gt; IO Tensor&lt;/code&gt;
type, we see that it accepts three arguments: a &lt;code&gt;Double&lt;/code&gt; probability of
dropout, a &lt;code&gt;Bool&lt;/code&gt; that turns this layer on or off, and a data &lt;code&gt;Tensor&lt;/code&gt;.
Typically, we turn the dropout on during the training and off during the
inference stage.&lt;/p&gt;

&lt;p&gt;However, the biggest distinction between e.g. &lt;code&gt;relu&lt;/code&gt;
function and &lt;code&gt;dropout&lt;/code&gt; is that &lt;code&gt;relu :: Tensor -&amp;gt; Tensor&lt;/code&gt;
is a &lt;em&gt;pure&lt;/em&gt; function, i.e. it does not have any &#39;side-effects&#39;.
This means that every time when we call a pure function,
the result will be the same.
This is not the case with &lt;code&gt;dropout&lt;/code&gt; that relies on an
(external) random number generator, and therefore returns
a new result each time.
Therefore, its outcome is an &lt;code&gt;IO Tensor&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One has to pay a particular attention to those &lt;code&gt;IO&lt;/code&gt; functions, because they can
change the state in the external world. This can be printing text on the
screen, deleting a file, or launching missiles. Typically, we prefer to keep
functions pure whenever possible, as function purity improves the reasoning
about the program: It is a child&#39;s play to refactor (reorganize) a program
consisting only of pure functions.&lt;/p&gt;

&lt;p&gt;I find the so-called &lt;em&gt;do-notation&lt;/em&gt; to be the most natural way to combine both
pure functions and those with side-effects.  The pure equations can be grouped
under &lt;code&gt;let&lt;/code&gt; keyword(s), while the side-effects are summoned with a special &lt;code&gt;&amp;lt;-&lt;/code&gt;
glue. This is how we integrate &lt;code&gt;dropout&lt;/code&gt; in &lt;code&gt;mlp&lt;/code&gt;. Note that now the
outcome of &lt;code&gt;mlp&lt;/code&gt; also becomes an &lt;code&gt;IO Tensor&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Bool&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;isStochastic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- This subnetwork encapsulates the composition&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- of pure functions&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sub1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- The dropout is applied to the output&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- of the subnetwork&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dropout&lt;/span&gt;
          &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;   &lt;span style=&#34;color:#75715e&#34;&gt;-- Dropout probability&lt;/span&gt;
          &lt;span style=&#34;color:#a6e22e&#34;&gt;isStochastic&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- Activate Dropout when in stochastic mode&lt;/span&gt;
          (&lt;span style=&#34;color:#a6e22e&#34;&gt;sub1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x0&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;-- Apply dropout to&lt;/span&gt;
                     &lt;span style=&#34;color:#75715e&#34;&gt;-- the output of `relu` in layer 2&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Another linear layer&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;x1&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Finally, logSoftmax, which is numerically more stable&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- compared to simple log(softmax(x2))&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSoftmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;x2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For model uncertainty estimation, it is empirically recommended to keep the
dropout probability anywhere between 0.1 and 0.2.&lt;/p&gt;

&lt;h2 id=&#34;computing-on-a-gpu&#34;&gt;Computing on a GPU&lt;/h2&gt;

&lt;p&gt;To transfer data onto a GPU, we use &lt;code&gt;toDevice :: ... =&amp;gt; Device -&amp;gt; a -&amp;gt; a&lt;/code&gt;.
Below are helper methods to traverse data structures containing tensors
(e.g. &lt;code&gt;MLP&lt;/code&gt;) to convert those between devices.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forall&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;HasTypes&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Device&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DType&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;device&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dtype&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;over&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;types&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;) (&lt;span style=&#34;color:#a6e22e&#34;&gt;toDevice&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;device&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forall&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;HasTypes&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;over&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;types&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;) (&lt;span style=&#34;color:#a6e22e&#34;&gt;toDevice&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Device&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;CPU&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Below is a shortcut to transfer data to &lt;code&gt;cuda:0&lt;/code&gt; device, assuming the &lt;code&gt;Float&lt;/code&gt;
type.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Device&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;CUDA&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The train loop is almost the same as in the previous post, except a few changes.
First, we convert training data to GPU with &lt;code&gt;toLocalModel&#39;&lt;/code&gt; (assuming that the
model itself was already converted to GPU).
Second, &lt;code&gt;predic &amp;lt;- mlp model isTrain input&lt;/code&gt; is an &lt;code&gt;IO&lt;/code&gt; action.
Third, we manage optimizer&#39;s internal state&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LearningRate&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ListT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;model0&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt0&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enumerateData&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;isTrain&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;label&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;isTrain&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;nllLoss&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;label&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Print loss every 100 batches&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mod&lt;/span&gt;` &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;printf&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Batch: %d | Loss: %.2f&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;)
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;opt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;model0&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;opt0&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We also modify the &lt;code&gt;train&lt;/code&gt; function to use Adam optimizer with &lt;code&gt;mkAdam&lt;/code&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;0&lt;/code&gt; is the initial iteration number (then internally increased by the optimizer).&lt;/li&gt;
&lt;li&gt;We provide &lt;code&gt;beta1&lt;/code&gt; and &lt;code&gt;beta2&lt;/code&gt; values.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;flattenParameters net0&lt;/code&gt; are needed to get the shapes of the trained parameters momenta. See also &lt;a href=&#34;https://penkovsky.com/neural-networks/day2&#34;&gt;Day 2&lt;/a&gt; for more details.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    (&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foldLoop&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optState&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dsetOpt&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt;)
      &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;optState&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;dsetOpt&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;workers&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;workers&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;lr&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-4&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- Learning rate&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mkAdam&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta2&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;flattenParameters&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;)
    &lt;span style=&#34;color:#a6e22e&#34;&gt;beta1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;beta2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.999&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is a function to get model accuracy:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;accuracy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ListT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;accuracy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enumerateData&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;)
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;total&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;labels&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;args&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Compute predictions&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;argmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt; 
                     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;

      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;correct&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt;
                        &lt;span style=&#34;color:#75715e&#34;&gt;-- Sum those elements&lt;/span&gt;
                        &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sumDim&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int64&lt;/span&gt;
                        &lt;span style=&#34;color:#75715e&#34;&gt;-- Find correct predictions&lt;/span&gt;
                        &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;eq&lt;/span&gt;` &lt;span style=&#34;color:#a6e22e&#34;&gt;labels&lt;/span&gt;

      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;shape&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predic&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;correct&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;total&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;-- When done folding, compute the accuracy&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;total&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fromIntegral&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fromIntegral&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;total&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Initial errors and totals&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)

&lt;span style=&#34;color:#a6e22e&#34;&gt;testAccuracy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;testAccuracy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;testStream&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;accuracy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Below we provide the MLP specification: number of neurons in each layer.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;saving-and-loading-the-model&#34;&gt;Saving and Loading the Model&lt;/h2&gt;

&lt;p&gt;Before we can save the model, we have to make the weight tensors dependent
first:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;save&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FilePath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;save&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;save&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toDependent&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flattenParameters&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The inverse is true for model loading. We also replace
parameters in a newly generated model with the one we
have just loaded:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FilePath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fpath&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;params&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mapM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;makeIndependent&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fpath&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;replaceParameters&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;params&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Load the MNIST data:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Train a new model:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- A train &amp;#34;loader&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt; }
&lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;toLocalModel&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnistStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epochs&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Saving the model:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;save&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weights.bin&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To load a pretrained model:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weights.bin&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can verify the model&#39;s accuracy:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- A test &amp;#34;loader&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; { &lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt; }

&lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testAccuracy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accuracy &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ac&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;Accuracy 0.9245&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The accuracy is not tremendous, but it can be improved by introducing
&lt;a href=&#34;https://penkovsky.com/neural-networks/day4&#34;&gt;batch norm&lt;/a&gt;,
&lt;a href=&#34;https://penkovsky.com/neural-networks/day5&#34;&gt;convolutional layers&lt;/a&gt;, and
training longer. We are about to discuss model uncertainty estimation and
this accuracy is good enough.&lt;/p&gt;

&lt;h2 id=&#34;predictive-entropy&#34;&gt;Predictive Entropy&lt;/h2&gt;

&lt;p&gt;Model uncertainties are obtained as:&lt;/p&gt;

&lt;p&gt;$$
\begin{equation}
\mathbb{H}(y|\mathbf{x}) = -\sum_c p(y = c|\mathbf{x}) \log p(y = c|\mathbf{x}),
\end{equation}
$$&lt;/p&gt;

&lt;p&gt;where $y$ is label, $\mathbf{x}$ – input image, $c$ – class, $p$ – probability.&lt;/p&gt;

&lt;p&gt;We call $\mathbb{H}$ &lt;a href=&#34;https://towardsdatascience.com/2-easy-ways-to-measure-your-image-classification-models-uncertainty-1c489fefaec8&#34;&gt;predictive entropy&lt;/a&gt;.
And it is the very dropout technique that helps us to estimate those
uncertainties.  All we need to do is to collect several predictions in the
stochastic mode (i.e. dropout enabled) and apply the formula from above.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;predictiveEntropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;predictiveEntropy&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predictions&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epsilon&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-45&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;meanDim&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predictions&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;epsilon&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;negate&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sumAll&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;visualizing-softmax-predictions&#34;&gt;Visualizing Softmax Predictions&lt;/h2&gt;

&lt;p&gt;To get a better feeling what model outputs look like, it would be nice to
visualize the softmax output as a histogram or a bar chart. For instance&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;bar&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apples&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;oranges&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kiwis&amp;#34;&lt;/span&gt;] [&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;apples  ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 50.00
oranges ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 100.00
kiwis   ▉▉▉▉▉▉▉▉▉▉▉▉▋ 25.00&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, we would like to display an image, the predictive entropy, and the softmax
output, followed by prediction and ground truth.  To transform logSoftmax into
softmax, we use the following identity:&lt;/p&gt;

&lt;p&gt;$$
\begin{equation}
e^{\ln(\rm{softmax}(x))} = \rm{softmax}(x),
\end{equation}
$$&lt;/p&gt;

&lt;p&gt;that is &lt;code&gt;softmax = exp. logSoftmax&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;repeatN&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;preds&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forM&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;repeatN&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- logSoftmax -&amp;gt; softmax&lt;/span&gt;
                                     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stochastic&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predictiveEntropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;preds&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Select only the images with high entropy&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;dispImage&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;putStr&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entropy &amp;#34;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- exp. logSoftmax = softmax&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;bar&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;]) (&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flattenAll&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; [&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;])
      &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Model        : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;argmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt;)
      &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ground Truth : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note that below we show only some of those images the model is uncertain about
(entropy &amp;gt; 0.9)&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; {&lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;}
&lt;span style=&#34;color:#a6e22e&#34;&gt;forM_&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getItem&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;     +%       
     %        
     *        
    #-  +%%=  
    %  %%  %  
    % %+   #  
    % %    *  
    %  % :%   
    #*:=%#    
     -%=.     
              
              
Entropy 1.044228
0 ▉▏ 0.01
1 ▏ 0.00
2 ▋ 0.01
3 ▏ 0.00
4 ▉ 0.01
5 ▍ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.70
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.21
9 ▉▉▉▋ 0.05
Model        : Tensor Int64 [1] [ 6]
Ground Truth : Tensor Int64 [1] [ 6]
              
              
      .#%#.   
    %%+:      
     %        
     %..      
    ##-#%.    
         -%   
          :%  
           +  
    -     .%  
    @%+*%%+   
              
              
Entropy 1.2909155
0 ▏ 0.00
1 ▏ 0.00
2 ▍ 0.00
3 ▉▉▉▉▉▉▉▉ 0.07
4 ▏ 0.00
5 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.44
6 ▏ 0.00
7 ▍ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.47
9 ▉▏ 0.01
Model        : Tensor Int64 [1] [ 8]
Ground Truth : Tensor Int64 [1] [ 5]
              
              
              
     =-     = 
     #-    =# 
     %-    #  
    +%     %  
    %.    .%  
   ##     .*  
   %%%%%#%#.  
   .      %   
              
              
              
Entropy 1.3325933
0 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.19
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.46
5 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▊ 0.18
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▊ 0.16
7 ▏ 0.00
8 ▏ 0.00
9 ▏ 0.00
Model        : Tensor Int64 [1] [ 4]
Ground Truth : Tensor Int64 [1] [ 4]
              
              
       *:     
     :%%*     
    #- -+     
       -      
       #      
      +:      
      #    =. 
     #.  =%:  
     *.*%-    
    #%%:      
              
              
Entropy 1.2533671
0 ▉ 0.01
1 ▉▉▍ 0.03
2 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.38
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.54
4 ▏ 0.00
5 ▋ 0.01
6 ▏ 0.00
7 ▏ 0.00
8 ▉▉▋ 0.03
9 ▏ 0.00
Model        : Tensor Int64 [1] [ 3]
Ground Truth : Tensor Int64 [1] [ 2]
              
              
              
     +##-     
     *   :    
     =        
     %  =     
     %  %     
     -= @     
      = %     
        %     
        %     
        %     
              
Entropy 0.9308149
0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▉ 0.01
4 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.29
5 ▍ 0.00
6 ▏ 0.00
7 ▎ 0.00
8 ▉▎ 0.02
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.67
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
              
        #     
      % #     
      % *     
      % =     
     %%@%     
     *  %     
        %     
        %     
        %     
        =     
              
Entropy 1.39582
0 ▏ 0.00
1 ▉▍ 0.01
2 ▏ 0.00
3 ▉▉▉▉▉▊ 0.06
4 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.48
5 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▋ 0.17
6 ▉▉▉▉ 0.04
7 ▏ 0.00
8 ▉▋ 0.02
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.22
Model        : Tensor Int64 [1] [ 4]
Ground Truth : Tensor Int64 [1] [ 4]
              
              
              
      .#%@    
      %%%%=   
     +%. %#   
      %%%%:   
       %%%    
      -%%     
     -%%      
    .%%       
    %%-       
    %*        
              
Entropy 1.0009595
0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▉▊ 0.02
4 ▏ 0.00
5 ▎ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.35
8 ▉ 0.01
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.62
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
              
              
     %##%     
    :%+%%.    
    -%  %:    
    -%  %+    
     +  %+    
        %+    
        %+    
        %#    
        %%    
        .+    
Entropy 1.0057298
0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▉▉▍ 0.03
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.33
8 ▏ 0.00
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.63
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 7]
              
              
              
   %%%%%      
      .%      
      %.      
    =%%%+     
    %   %# -  
         %%.  
        *%-   
       %:%    
      %-%=    
      %%-     
              
Entropy 1.0500848
0 ▉▉▉▉▍ 0.07
1 ▎ 0.00
2 ▎ 0.00
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.79
4 ▉▉▊ 0.04
5 ▉▉▉▎ 0.05
6 ▏ 0.00
7 ▍ 0.01
8 ▎ 0.00
9 ▉▊ 0.03
Model        : Tensor Int64 [1] [ 3]
Ground Truth : Tensor Int64 [1] [ 3]
              
              
              
     :*       
      %       
      %%      
      :%      
       %*     
       +*     
        %     
        %     
        %     
        =     
              
Entropy 1.590256
0 ▏ 0.00
1 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.36
2 ▏ 0.00
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.10
4 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.32
5 ▉▉▉▎ 0.02
6 ▏ 0.00
7 ▎ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.12
9 ▉▉▉▉▉▉▉▉▉▉▍ 0.07
Model        : Tensor Int64 [1] [ 1]
Ground Truth : Tensor Int64 [1] [ 1]
              
              
              
    =   =     
    %%%%%.    
      :%%     
       %*     
    .%%%%%%%%+
      %%%*:   
      %%      
      %%      
      %%      
      %%      
              
Entropy 0.9592192
0 ▏ 0.00
1 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▊ 0.28
2 ▋ 0.01
3 ▍ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▍ 0.01
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.67
8 ▏ 0.00
9 ▉▉▏ 0.03
Model        : Tensor Int64 [1] [ 7]
Ground Truth : Tensor Int64 [1] [ 7]
              
              
              
      =%#*    
    :%%- .#   
    %%   :%   
   .%    #=   
         %    
       %%#    
     -%%%%    
     %%%.%    
     #%  *+   
          :   
              
Entropy 1.0005924
0 ▍ 0.00
1 ▏ 0.00
2 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.48
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.47
8 ▉▉▉▋ 0.03
9 ▉▎ 0.01
Model        : Tensor Int64 [1] [ 2]
Ground Truth : Tensor Int64 [1] [ 2]
              
              
      -       
    :%%%-     
   :%   %     
   +:   :%-   
  -%     *%   
  *:      %*  
  ==      *%  
   *      :%  
   #::..:*%%  
    :%*%%-:   
              
              
Entropy 1.3647958
0 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.50
1 ▏ 0.00
2 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.23
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.23
4 ▏ 0.00
5 ▉▉▉▏ 0.03
6 ▏ 0.00
7 ▏ 0.00
8 ▏ 0.00
9 ▉▍ 0.01
Model        : Tensor Int64 [1] [ 0]
Ground Truth : Tensor Int64 [1] [ 0]
              
              
              
      %-      
       :%     
        #     
    -%#%*     
   ::  @%.    
   *  %  #.   
    %%    %   
           %  
            % 
              
              
Entropy 1.1518966
0 ▉▉▉▎ 0.06
1 ▍ 0.01
2 ▊ 0.01
3 ▏ 0.00
4 ▉▉▊ 0.05
5 ▏ 0.00
6 ▏ 0.00
7 ▏ 0.00
8 ▍ 0.01
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.86
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 2]
              
              
              
    =%%%%+    
   .#. =#%    
   %*   %#    
   #.   .%    
   .#   *%:   
    .%%%- =   
           #  
           #  
      -%% =%  
       =%%#   
              
Entropy 1.1256037
0 ▉▊ 0.02
1 ▏ 0.00
2 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▏ 0.29
3 ▎ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.59
9 ▉▉▉▉▉▉▉▉▎ 0.10
Model        : Tensor Int64 [1] [ 8]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
      --%:    
     .   %    
         %:   
     ** .%    
      *%%.    
      %%*%    
     %*  %    
     %   %    
     %  %:    
     %%%:     
              
              
Entropy 1.0862491
0 ▏ 0.00
1 ▉▉▋ 0.03
2 ▉▉▉▉▉ 0.05
3 ▏ 0.00
4 ▏ 0.00
5 ▋ 0.01
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.42
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.50
9 ▏ 0.00
Model        : Tensor Int64 [1] [ 8]
Ground Truth : Tensor Int64 [1] [ 8]
              
              
              
        %%    
        %%    
       *%#    
      :%%-    
      .%%     
      %%+     
     +%%      
     *%+      
     =%=      
      =:      
              
Entropy 1.0085171
0 ▏ 0.00
1 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.81
2 ▎ 0.00
3 ▍ 0.01
4 ▎ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▏ 0.16
8 ▎ 0.01
9 ▍ 0.01
Model        : Tensor Int64 [1] [ 1]
Ground Truth : Tensor Int64 [1] [ 1]
              
              
              
    -@@:      
   -#  +:     
   #-   %     
    %: ..-    
     +%=*%    
       .%%    
        %*    
        %%    
        %%    
        %.    
              
Entropy 1.5438546
0 ▏ 0.00
1 ▏ 0.00
2 ▉▉▉▉ 0.03
3 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.14
4 ▉▉▉▉▉▊ 0.05
5 ▊ 0.01
6 ▏ 0.00
7 ▉▉▉▉▊ 0.04
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▎ 0.31
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.42
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Reflecting on softmax outputs above we can state that&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Softmax output alone is not enough to estimate the model uncertainty. We can observe wrong predictions even when the margin between the top and second-best guess is large.&lt;/li&gt;
&lt;li&gt;Sometimes prediction and ground truth coincide. So why the entropy is high? We actually need to inspect such cases in more details.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first point is well illustrated by this example:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;              
              
              
      %-      
       :%     
        #     
    -%#%*     
   ::  @%.    
   *  %  #.   
    %%    %   
           %  
            % 
              
              
Entropy 1.1518966
0 ▉▉▉▎ 0.06
1 ▍ 0.01
2 ▊ 0.01
3 ▏ 0.00
4 ▉▉▊ 0.05
5 ▏ 0.00
6 ▏ 0.00
7 ▏ 0.00
8 ▍ 0.01
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.86
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 2]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To illustrate the last point, let us take a closer look at cases with high
entropy. By running several realizations of the stochatic model, we can verify
if the model has any &amp;quot;doubt&amp;quot; by selecting different answers.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;repeatN&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pred&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forM&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;repeatN&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;-- logSoftmax -&amp;gt; softMax&lt;/span&gt;
                                     &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predictiveEntropy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;cat&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;pred&amp;#39;&lt;/span&gt;

  &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;dispImage&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStr&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entropy &amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;entropy&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;forM_&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred&amp;#39;&lt;/span&gt; ( &lt;span style=&#34;color:#a6e22e&#34;&gt;\pred&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bar&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;map&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;]) (&lt;span style=&#34;color:#a6e22e&#34;&gt;asValue&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;flattenAll&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; [&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;]) )
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Model        : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;argmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pred0&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ground Truth : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first example from above (dataset index &lt;code&gt;11&lt;/code&gt;) gives this:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&amp;#39;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getItem&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt;) &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;              
              
     +%       
     %        
     *        
    #-  +%%=  
    %  %%  %  
    % %+   #  
    % %    *  
    %  % :%   
    #*:=%#    
     -%=.     
              
              
Entropy 1.1085687

0 ▎ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.90
7 ▏ 0.00
8 ▉▉▉▉▉▍ 0.10
9 ▏ 0.00

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▋ 0.01
1 ▏ 0.00
2 ▏ 0.00
3 ▎ 0.01
4 ▉▉▉▏ 0.05
5 ▏ 0.00
6 ▉▉▎ 0.04
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.86
9 ▉▎ 0.02

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▉▉▉▉▍ 0.04
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▉▉▉▉▉▉▉▉▉▉▏ 0.09
5 ▉▏ 0.01
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▋ 0.30
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.12
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.43

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▋ 0.01
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▎ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.74
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.20
9 ▉▉▋ 0.04

0 ▉▏ 0.02
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▋ 0.01
5 ▏ 0.00
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.80
7 ▏ 0.00
8 ▉▉▉▉▉▉▋ 0.10
9 ▉▉▉▉▎ 0.07

0 ▉▉▉▉▍ 0.04
1 ▏ 0.00
2 ▎ 0.00
3 ▏ 0.00
4 ▉▉▉▉▉▉▉▉▉▉▏ 0.09
5 ▉▏ 0.01
6 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▋ 0.30
7 ▏ 0.00
8 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▍ 0.12
9 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0.43
Model        : Tensor Int64 [1] [ 6]
Ground Truth : Tensor Int64 [1] [ 6]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Wow! The model sometimes &amp;quot;sees&amp;quot; digit 6, sometimes digit 8, and sometimes digit
9! For the contrast, here is how predictions with low entropy typically look
like.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImage&amp;#39;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;fromLocalModel&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getItem&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnistStream&lt;/span&gt;) &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;              
              
              
   #%%*****   
      ::: %   
         %:   
        :%    
        #:    
       :%     
       %.     
      #=      
     :%.      
     =#       
Entropy 4.8037423e-4

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00

0 ▏ 0.00
1 ▏ 0.00
2 ▏ 0.00
3 ▏ 0.00
4 ▏ 0.00
5 ▏ 0.00
6 ▏ 0.00
7 ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 1.00
8 ▏ 0.00
9 ▏ 0.00
Model        : Tensor Int64 [1] [ 7]
Ground Truth : Tensor Int64 [1] [ 7]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The model always &amp;quot;sees&amp;quot; digit 7. That is why the predictive entropy is low.
Note that the results are model-dependent. Therefore we also
share the weights for reproducibility. However, every realization of the
stochastic model might still be different, especially in those cases where the
entropy is high.&lt;/p&gt;

&lt;p&gt;Find the complete project on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day8&#34;&gt;Github&lt;/a&gt;. For suggestions about the content
feel free to open a
&lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/issues&#34;&gt;new issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;I hope you are now convinced that model&#39;s uncertainty estimation is an invaluable tool. This simple technique is essential when applying deep learning for real-life decision making. This post also develops on how to use Hasktorch library in practice. Notably, it is very straightforward to run computations on a GPU. Overall, Hasktorch can be used for real-world deep learning. The code is well-structured and relies on a mature Torch library. On the other hand, it would be desirable to capture high-level patterns so that the user does not need to think about low-level concepts such as dependent and independent tensors, for example. The end user should be able to simply apply &lt;code&gt;save net &amp;quot;weights.bin&amp;quot;&lt;/code&gt; and &lt;code&gt;mynet &amp;lt;- load &amp;quot;weights.bin&amp;quot;&lt;/code&gt; without any indirections. The same reasoning applies to the &lt;code&gt;trainLoop&lt;/code&gt;, i.e. the user does not need to reinvent it every time. Eventually, a higher-level package on top of Hasktorch should capture the best practices, similar to &lt;a href=&#34;https://www.pytorchlightning.ai/&#34;&gt;PyTorch Lightning&lt;/a&gt; or &lt;a href=&#34;https://github.com/fastai/fastai&#34;&gt;fast.ai&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now your turn: explore image recognition with &lt;a href=&#34;https://github.com/hasktorch/hasktorch/blob/master/examples/alexNet/AlexNet.hs&#34;&gt;AlexNet&lt;/a&gt; convolutional network and have fun!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit 27/04/2022:&lt;/strong&gt; The original version from 23/04 did not correctly handle
optimizer&#39;s internal state. Therefore, &lt;code&gt;train&lt;/code&gt; and &lt;code&gt;trainLoop&lt;/code&gt; were fixed.
You will find the updated notebook on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day8&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1207.0580.pdf&#34;&gt;Improving neural networks by preventing
co-adaptation of feature detectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf&#34;&gt;Dropout: A Simple Way to Prevent Neural Networks from
Overfitting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://xuwd11.github.io/Dropout_Tutorial_in_PyTorch/&#34;&gt;Tutorial: Dropout as Regularization and Bayesian Approximation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/2-easy-ways-to-measure-your-image-classification-models-uncertainty-1c489fefaec8&#34;&gt;Two Simple Ways To Measure Your Model’s Uncertainty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf&#34;&gt;Uncertainty in Deep Learning, Yarin Gal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hasktorch/hasktorch/tree/master/examples/alexNet&#34;&gt;AlexNet example in Hasktorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;Previously, there was no need to handle &lt;code&gt;GD&lt;/code&gt; optimizer&#39;s internal state. This is not true in a more general case. For instance, &lt;a href=&#34;https://hasktorch.github.io/hasktorch/html/src/Torch.Optim.html#adam&#34;&gt;Adam&lt;/a&gt; keeps track of momenta and iterations for bias adjustment.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Day 7: Real World Deep Learning</title>
      <link>https://penkovsky.com/neural-networks/day7/</link>
      <pubDate>Mon, 18 Apr 2022 22:55:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/neural-networks/day7/</guid>
      <description>

&lt;p&gt;So far we have explored neural networks almost in the vacuum. Although we have
provided some illustrations for better clarity, relying an existing framework
would allow us to benefit from the knowledge of previous contributors. One such
framework is called &lt;a href=&#34;https://github.com/hasktorch/hasktorch&#34;&gt;Hasktorch&lt;/a&gt;. Among
the practical reasons to use Hasktorch is relying on a mature &lt;a href=&#34;https://pytorch.org/docs/stable/torch.html&#34;&gt;Torch&lt;/a&gt;
Tensor library. Another good reason is strong GPU acceleration, which is
necessary for almost any serious deep learning project. Finally, standard
interfaces rather than reinventing the wheel will help to reduce the
boilerplate.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Fun fact: one of Hasktorch
&lt;a href=&#34;https://github.com/hasktorch/hasktorch/graphs/contributors&#34;&gt;contributors&lt;/a&gt; is
Adam Paszke, the original author of Pytorch.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Today&#39;s post is also based on&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day2/&#34;&gt;Day 2: What Do Hidden Layers Do?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day4/&#34;&gt;Day 4: The Importance Of Batch Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/neural-networks/day5/&#34;&gt;Day 5: Convolutional Neural Networks Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The source code from this post is available &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day7&#34;&gt;on Github&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;the-basics&#34;&gt;The Basics&lt;/h2&gt;

&lt;p&gt;The easiest way &lt;a href=&#34;https://github.com/hasktorch/hasktorch#getting-started&#34;&gt;to start&lt;/a&gt;
with Hasktorch is via &lt;a href=&#34;https://www.docker.com/get-started/&#34;&gt;Docker&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;  docker run --gpus all -it --rm -p &lt;span style=&#34;color:#ae81ff&#34;&gt;8888&lt;/span&gt;:8888 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    -v &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;pwd&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;:/home/ubuntu/data &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    htorch/hasktorch-jupyter:latest-cu11&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, you may open &lt;code&gt;localhost:8888&lt;/code&gt; in your browser to access &lt;a href=&#34;https://jupyter.org/&#34;&gt;Jupyterlab&lt;/a&gt;
notebooks. Note that you need to select &lt;code&gt;Haskell&lt;/code&gt; kernel when creating a new notebook.&lt;/p&gt;

&lt;p&gt;If you have never used Torch library before, you may also want to review this
&lt;a href=&#34;https://hasktorch.github.io/tutorial/02-tensors.html&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;mnist-example&#34;&gt;MNIST Example&lt;/h2&gt;

&lt;p&gt;Let&#39;s take the familiar MNIST example and see how it can be implemented
&lt;a href=&#34;https://github.com/hasktorch/hasktorch/tree/master/examples/mnist-mlp&#34;&gt;in Hasktorch&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;imports&#34;&gt;Imports&lt;/h3&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE DeriveAnyClass #-}&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE DeriveGeneric #-}&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE MultiParamTypeClasses #-}&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE RecordWildCards #-}&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;{-# LANGUAGE ScopedTypeVariables #-}&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Control.Exception.Safe
  ( &lt;span style=&#34;color:#66d9ef&#34;&gt;SomeException&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;),
    &lt;span style=&#34;color:#a6e22e&#34;&gt;try&lt;/span&gt;,
  )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Control.Monad ( &lt;span style=&#34;color:#a6e22e&#34;&gt;forM_&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt;, (&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt;) )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Control.Monad.Cont ( &lt;span style=&#34;color:#66d9ef&#34;&gt;ContT&lt;/span&gt; (&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;) )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; GHC.Generics
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Pipes &lt;span style=&#34;color:#66d9ef&#34;&gt;hiding&lt;/span&gt; ( (&lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt;) )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;qualified&lt;/span&gt; Pipes.Prelude &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; P
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Torch
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Torch.Serialize
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Torch.Typed.Vision ( &lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; )
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;qualified&lt;/span&gt; Torch.Vision &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; V
&lt;span style=&#34;color:#66d9ef&#34;&gt;import&lt;/span&gt; Prelude &lt;span style=&#34;color:#66d9ef&#34;&gt;hiding&lt;/span&gt; ( &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; )&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The most notable import is the &lt;code&gt;Torch&lt;/code&gt; module itself. There are also related
helpers such &lt;code&gt;Torch.Vision&lt;/code&gt; to handle image data. The function &lt;code&gt;initMnist&lt;/code&gt; has
type&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;MnistData&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;MnistData&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The function is loading MNIST train and test datasets, similar to &lt;code&gt;loadMNIST&lt;/code&gt;
from previous posts.&lt;/p&gt;

&lt;p&gt;It might be also useful to pay attention to
&lt;a href=&#34;https://hackage.haskell.org/package/pipes&#34;&gt;&lt;code&gt;Pipes&lt;/code&gt;&lt;/a&gt; module. It is an
alternative to previously used &lt;code&gt;Streamly&lt;/code&gt;, which also allows building
streaming components.&lt;/p&gt;

&lt;p&gt;We also import functions from &lt;code&gt;Control.Monad&lt;/code&gt;, which are useful for IO
operations.&lt;/p&gt;

&lt;p&gt;Finally, we hide &lt;code&gt;exp&lt;/code&gt; function in favor of Torch &lt;code&gt;exp&lt;/code&gt;, which operates on
tensors (arrays)&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; rather than floating point scalars:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;defining-neural-network-architecture&#34;&gt;Defining Neural Network Architecture&lt;/h3&gt;

&lt;p&gt;First we define a neural network data structure that contains trained
parameters (neural network weights). In the simplest case, it can be a
multilayer perceptron (MLP).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Linear&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Generic&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Parameterized&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This MLP contains three linear layers. Next, we may define a data structure
that specifies the number of neurons in each layer:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;data&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt;
  { &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,
    &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;
  }
  &lt;span style=&#34;color:#66d9ef&#34;&gt;deriving&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Show&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Eq&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, we can define a neural network as a function, similar as we did on
&lt;a href=&#34;https://penkovsky.com/neural-networks/day5/&#34;&gt;Day 5&lt;/a&gt; with a &amp;quot;reversed&amp;quot; composition operator
&lt;code&gt;(~&amp;gt;)&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;g&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;g&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt;

&lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;-- Layer 1&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Layer 2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;relu&lt;/span&gt;

  &lt;span style=&#34;color:#75715e&#34;&gt;-- Layer 3&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;~&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;logSoftmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We finish by a (log) softmax layer reducing the tensor&#39;s dimension 1 (&lt;code&gt;Dim 1&lt;/code&gt;).
Derivatives of &lt;code&gt;linear&lt;/code&gt;, &lt;code&gt;relu&lt;/code&gt;, and &lt;code&gt;logSoftmax&lt;/code&gt; are already handled by Torch
library.&lt;/p&gt;

&lt;h3 id=&#34;initial-weights&#34;&gt;Initial Weights&lt;/h3&gt;

&lt;p&gt;How do we generate initial random weights? As you may remember from
&lt;a href=&#34;https://penkovsky.com/neural-networks/day5/&#34;&gt;Day 5&lt;/a&gt;, we could create a function such as this one:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;randNetwork&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; [&lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
  &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randLinear&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Sz2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randLinear&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Sz2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;randLinear&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Sz2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;
     &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; {  &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc1&lt;/span&gt;
          , &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc2&lt;/span&gt;
          , &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fc3&lt;/span&gt;
          }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In our example we do almost the same, except we benefit from
&lt;a href=&#34;http://learnyouahaskell.com/functors-applicative-functors-and-monoids&#34;&gt;applicative functors&lt;/a&gt; and
&lt;a href=&#34;https://github.com/hasktorch/hasktorch/blob/0269df6b3c7fdfa3f25a8c8e315b6188214c57ca/hasktorch/src/Torch/NN.hs#L201&#34;&gt;&lt;code&gt;Randomizable&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;instance&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Randomizable&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; {&lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt;} &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt;)
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h1&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt;)
      &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;LinearSpec&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;h2&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We say above that &lt;code&gt;MLP&lt;/code&gt; is an instance of the &lt;code&gt;Randomizable&lt;/code&gt; typeclass,
parametrized by &lt;code&gt;MLPSpec&lt;/code&gt;. All we needed to define this instance was to
implement a &lt;code&gt;sample&lt;/code&gt; function. To generate initial MLP weights, later we can
simply write&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;train-loop&#34;&gt;Train Loop&lt;/h3&gt;

&lt;p&gt;The core of the neural network training is &lt;code&gt;trainLoop&lt;/code&gt;, which enables a single
training &amp;quot;epoch&amp;quot;. Let us first inspect its type signature.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;o&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ListT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This signifies that the function accepts an initial neural network
configuration, an optimizer, and a dataset. The optimizer can be a gradient
descent (GD), Adam, or other
&lt;a href=&#34;https://hasktorch.github.io/hasktorch/html/Torch-Optim.html&#34;&gt;optimizer&lt;/a&gt;.
The result of the function is a new MLP configuration, as a result of IO call.
IO is necessary for instance if we want to print the loss after each iteration.
Now, let&#39;s take a look at the implementation:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;foldM&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;enumerateData&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;First, we enumerate the dataset with &lt;code&gt;enumerateData&lt;/code&gt;. Then, we iterate over (fold)
the batches. The &lt;code&gt;step&lt;/code&gt; function is an analogy to a step in the gradient descent
algorithm:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ((&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;), &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;step&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; ((&lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;label&lt;/span&gt;), &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;nllLoss&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;label&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;input&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;-- Print loss every 50 batches&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;when&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; `&lt;span style=&#34;color:#a6e22e&#34;&gt;mod&lt;/span&gt;` &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
        &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Iteration: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;iter&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; | Loss: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt;
      (&lt;span style=&#34;color:#a6e22e&#34;&gt;newParam&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;runStep&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;loss&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-3&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;newParam&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We calculate a
&lt;a href=&#34;https://hasktorch.github.io/hasktorch/html/Torch-Functional.html#v:nllLoss-39-&#34;&gt;negative log likelihood loss&lt;/a&gt;
&lt;code&gt;nllLoss&#39;&lt;/code&gt; between the ground truth label and the output
of our MLP. Note that &lt;code&gt;model&lt;/code&gt; is the parameter, i.e. weights of the MLP
network. Then, we take advantage of the iteration number &lt;code&gt;iter&lt;/code&gt; to print the
loss every 50 iterations. Finally, we perform a gradient descent step using our
optimizer via
&lt;code&gt;runStep :: ... =&amp;gt; model -&amp;gt; optimizer -&amp;gt; Loss -&amp;gt; LearningRate -&amp;gt; IO (model, optimizer)&lt;/code&gt;
and keep only new model &lt;code&gt;newParam&lt;/code&gt;. The learning rate here is &lt;code&gt;1e-3&lt;/code&gt;, but can
be eventually changed.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;done&lt;/code&gt; function is (trivial in this case) finalization of &lt;code&gt;foldM&lt;/code&gt;
iterations over the MLP model and &lt;code&gt;begin&lt;/code&gt; are the initial weights (we use &lt;code&gt;pure&lt;/code&gt;
to satisfy the type
&lt;a href=&#34;https://hackage.haskell.org/package/pipes-4.3.16/docs/src/Pipes.Prelude.html#foldM&#34;&gt;&lt;code&gt;m x&lt;/code&gt;&lt;/a&gt;
requirement).&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;done&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt;
    &lt;span style=&#34;color:#a6e22e&#34;&gt;begin&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pure&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;putting-it-all-together&#34;&gt;Putting It All Together&lt;/h3&gt;

&lt;p&gt;The remaining part is simple. We load the data into batches,
specify the number of neurons in our MLP, choose an optimizer,
and initialize the random weights.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;initMnist&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;let&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; {&lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainData&lt;/span&gt;}
      &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnist&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;MNIST&lt;/span&gt; {&lt;span style=&#34;color:#a6e22e&#34;&gt;batchSize&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;mnistData&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testData&lt;/span&gt;}
      &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLPSpec&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;784&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GD&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sample&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;spec&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, we train the network for 5 epochs:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foldLoop&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;\model&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;
      &lt;span style=&#34;color:#a6e22e&#34;&gt;runContT&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;streamFromMap&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;datasetOpts&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;trainMnist&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;trainLoop&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;optimizer&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fst&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, we may examine the model on test images&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;  &lt;span style=&#34;color:#a6e22e&#34;&gt;forM_&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;..&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;displayImages&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;net&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getItem&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testMnist&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For this purpose may use a function such as&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-haskell&#34; data-lang=&#34;haskell&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImages&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;MLP&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;Tensor&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;IO&lt;/span&gt; ()
&lt;span style=&#34;color:#a6e22e&#34;&gt;displayImages&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;V&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;dispImage&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Model        : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;argmax&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;Dim&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;RemoveDim&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;exp&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mlp&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testImg&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;putStrLn&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ground Truth : &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;testLabel&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;running&#34;&gt;Running&lt;/h3&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;Iteration: 0 | Loss: Tensor Float []  12.3775   
Iteration: 50 | Loss: Tensor Float []  1.0952   
Iteration: 100 | Loss: Tensor Float []  0.5626   
Iteration: 150 | Loss: Tensor Float []  0.6660   
Iteration: 200 | Loss: Tensor Float []  0.4771   
Iteration: 0 | Loss: Tensor Float []  0.5012   
Iteration: 50 | Loss: Tensor Float []  0.4058   
Iteration: 100 | Loss: Tensor Float []  0.3095   
Iteration: 150 | Loss: Tensor Float []  0.4237   
Iteration: 200 | Loss: Tensor Float []  0.3433   
Iteration: 0 | Loss: Tensor Float []  0.3671   
Iteration: 50 | Loss: Tensor Float []  0.3206   
Iteration: 100 | Loss: Tensor Float []  0.2467   
Iteration: 150 | Loss: Tensor Float []  0.3420   
Iteration: 200 | Loss: Tensor Float []  0.2737   
Iteration: 0 | Loss: Tensor Float []  0.3054   
Iteration: 50 | Loss: Tensor Float []  0.2779   
Iteration: 100 | Loss: Tensor Float []  0.2161   
Iteration: 150 | Loss: Tensor Float []  0.2933   
Iteration: 200 | Loss: Tensor Float []  0.2289   
Iteration: 0 | Loss: Tensor Float []  0.2693   
Iteration: 50 | Loss: Tensor Float []  0.2530   
Iteration: 100 | Loss: Tensor Float []  0.1979   
Iteration: 150 | Loss: Tensor Float []  0.2616   
Iteration: 200 | Loss: Tensor Float []  0.1986   
              
              
              
              
   #%%*****   
      ::: %   
         %:   
        :%    
        #:    
       :%     
       %.     
      #=      
     :%.      
     =#       
Model        : Tensor Int64 [1] [ 7]
Ground Truth : Tensor Int64 [1] [ 7]
              
              
     %%%#     
    %#  %     
    .  #%     
      :%:     
      %+      
     *%       
     %=       
    %%        
    %%%%++%%%=
     ==%%=.   
              
              
Model        : Tensor Int64 [1] [ 2]
Ground Truth : Tensor Int64 [1] [ 2]
              
              
        .-    
        =     
        %     
       .#     
       =:     
       @      
       #      
      ++      
      %:      
      %       
              
              
Model        : Tensor Int64 [1] [ 1]
Ground Truth : Tensor Int64 [1] [ 1]
              
              
       %.     
      *%-     
     %%%%#    
    :%%+:%-   
    %%   -%.  
    %    .@+  
    %    %%.  
    %   #%*   
    %%%%%%    
    :%%%-     
              
              
Model        : Tensor Int64 [1] [ 0]
Ground Truth : Tensor Int64 [1] [ 0]
              
              
              
     =    +   
     %    %   
    +.    %   
    %    %:   
    +    %    
    %--=*%    
     :: +%    
        =%    
        =%    
        *     
              
Model        : Tensor Int64 [1] [ 4]
Ground Truth : Tensor Int64 [1] [ 4]
              
              
              
        %@    
        @:    
       =@     
       @%     
       @      
      :@      
      %#      
      @       
      @       
      +       
              
Model        : Tensor Int64 [1] [ 1]
Ground Truth : Tensor Int64 [1] [ 1]
              
              
              
     %     %  
    %     %   
   +#    -+   
   +%*::*%    
    :%==%+    
        %     
       ++     
       %      
       %-+    
       *      
              
Model        : Tensor Int64 [1] [ 4]
Ground Truth : Tensor Int64 [1] [ 4]
              
              
              
      +       
     %%+      
    .%*%%     
    -: *%     
    -#-%%.    
     %% =#    
         %    
         .%   
          #.  
           %  
              
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
         ..=. 
      .%%%%%% 
     ::%+:    
    %         
   %          
   %=         
   %%%%%%+    
     :%%%%    
      %%%%    
       %#     
              
              
Model        : Tensor Int64 [1] [ 6]
Ground Truth : Tensor Int64 [1] [ 5]
              
              
              
              
      +%%%#   
    +%*  .%%  
   :%.  .#%+  
    %@%%%%*   
       +%-    
      -%#     
      %%      
     %%       
     %=       
     @        
Model        : Tensor Int64 [1] [ 9]
Ground Truth : Tensor Int64 [1] [ 9]
              
              
       ==:    
     %%**%%   
    .%    %:  
    *-    +#  
    %     :#  
    #     :#  
   -#     +#  
   -#    .%   
    #   +%:   
    #%%%%=    
              
              
Model        : Tensor Int64 [1] [ 0]
Ground Truth : Tensor Int64 [1] [ 0]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;See the complete project on &lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/tree/master/day7&#34;&gt;Github&lt;/a&gt;. For suggestions about the content
feel free to open a
&lt;a href=&#34;https://github.com/penkovsky/10-days-of-grad/issues&#34;&gt;new issue&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Today we have learned the basics of Hasktorch library. The most important is that
the principles from our previous days still apply. Therefore, the transition to
the new library was quite straightforward. With a few minor changes, this example
could be run on a &lt;a href=&#34;https://penkovsky.com/neural-networks/day8/&#34;&gt;graphics processing unit&lt;/a&gt; accelerator.&lt;/p&gt;

&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;

&lt;p&gt;Hasktorch:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://hasktorch.github.io/tutorial/02-tensors.html&#34;&gt;Hasktorch tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hasktorch/hasktorch/tree/master/examples&#34;&gt;Hasktorch examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://hasktorch.org/docs.html&#34;&gt;Hasktorch documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://learnyouahaskell.com/functors-applicative-functors-and-monoids&#34;&gt;Applicative functors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker containers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.docker.com/get-started/&#34;&gt;Getting started with Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Tensor&#34;&gt;Tensors&lt;/a&gt; are represented by n-dimensional arrays.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Quadcopter From Scratch: FPV Upgrade</title>
      <link>https://penkovsky.com/homelab/fpv-quad/</link>
      <pubDate>Thu, 17 Feb 2022 00:10:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/homelab/fpv-quad/</guid>
      <description>

&lt;p&gt;It has been a while since I was thinking about upgrading
&lt;a href=&#34;https://penkovsky.com/homelab/quadcopter/&#34;&gt;my drone&lt;/a&gt; to a first person view version
aka &lt;em&gt;FPV&lt;/em&gt;. The idea was placing a camera for video streaming in real time. My
first attempt was with a small raspi board and streaming image data from a raspi
camera via WiFi.  Because of the latency, range, and complicated setup this
solution was not very practical.&lt;/p&gt;

&lt;p&gt;Therefore, I decided to make a &amp;quot;real&amp;quot; FPV drone.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The jargon and some technical details were explained in the previous post.
Before you continue, you may want to read it first:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://penkovsky.com/homelab/quadcopter/&#34;&gt;A Quadcopter From Scratch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;fpv-components&#34;&gt;FPV Components&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Part&lt;/th&gt;
&lt;th&gt;Qty&lt;/th&gt;
&lt;th&gt;Unit W. (g)&lt;/th&gt;
&lt;th&gt;Price (EUR)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;FPV micro camera&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;8.6*&lt;/td&gt;
&lt;td&gt;50.67&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Video transmitter (analog)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;12*&lt;/td&gt;
&lt;td&gt;47.92&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;MMCX antenna&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;3.1&lt;/td&gt;
&lt;td&gt;10.23&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;FPV monitor or goggles&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;106.31&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;small&gt;* Weight without cables.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Note that you can easily find cheaper versions of those. For instance,
a camera and VTX combo can cost under 40 EUR in total.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/quad3.jpg&#34; alt=&#34;Basic FPV: Connecting camera directly to VTX&#34; width=&#34;600&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Basic FPV: Connecting camera directly to VTX
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Technically these components are enough to build an autonomous FPV system.
As seen above, I have connected the camera to the VTX (video transmitter), which
was powered directly from a 3S battery (12.6 V). The FPV test flight was
successful. Then, I found some space for further improvement.
So I experimented with additional components.  If you are about to build a quad from
the ground up, you may want to consider those. These parts make it much easier
to build a new copter.&lt;/p&gt;

&lt;h3 id=&#34;optional-components&#34;&gt;Optional Components&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Part&lt;/th&gt;
&lt;th&gt;Qty&lt;/th&gt;
&lt;th&gt;Unit W. (g)&lt;/th&gt;
&lt;th&gt;Price (EUR)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;F4-based flight controller + ESC stack&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;6 + 10*&lt;/td&gt;
&lt;td&gt;65.70&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Carbon fiber frame&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;107&lt;/td&gt;
&lt;td&gt;28.07&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Micro receiver&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1.7&lt;/td&gt;
&lt;td&gt;15.76&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Pink propellers (5040)&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;11.27&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;small&gt;* Weight without connector wires.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;The flight controller&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; stack gave several advantages.  First, a more powerful
processor. Second, there was no need in additional UBEC, i.e. the flight
controller was connected to the battery. Third, the controller provided an OSD
(on-screen display) that could transmit flight information such as battery
level or link quality (RSSI, LQ) in real time. I also find it overall
convenient soldering VTX and camera wires directly to the flight
controller&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-2&#34;&gt;&lt;a href=&#34;#fn:fn-2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. And don&#39;t forget included silicon vibration dampeners!
It is called a stack because of the flight controller and 4-in-1 ESC vertical
integration. This implies a standard way to place and connect the two.
Besides, the ESC already came with a XT60 connector to solder.&lt;/p&gt;

&lt;p&gt;A carbon fiber frame instead of a 3D-printed one is a bit more ergonomic. For
instance, it already has standard emplacement for four M2 screws to attach the
VTX and a support for the VTX camera. Overall it results in a cleaner, slim
build.  Commercial frames are strong enough to support a light X-shape, whereas
the 3D-printed frame I used previously had a slightly bulky H-shape.
Surprisingly, the weight of the new frame was about the same (107g vs 110g).
Last but not least the commercial frame was already supplied with a set of screws
and standoffs.&lt;/p&gt;

&lt;p&gt;The FS-iA10B receiver was quite bulky, so I have replaced it with a smaller
one. If you are choosing a transmitter-receiver system, then you may want to
consider a long-range TBS CrossFire or &lt;a href=&#34;https://github.com/ExpressLRS/ExpressLRS&#34;&gt;ExpressLRS&lt;/a&gt;. The last one
is cheaper because it is open-source, by the way. In both cases you avoid the
problem of loosing the control because of the range. Believe me, I know how
it feels bathing a copter in a lake!&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/quad4.jpg&#34; alt=&#34;F4 controller in a carbon fiber frame&#34; width=&#34;640&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    F4 controller in a carbon fiber frame
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;There was no particular utility in pink propellers, but the older ones were
worn out and had to be replaced anyway. The four motors, batteries, the radio
transmitter, &amp;quot;velcro&amp;quot; fasteners, and motor-antivibration pads were taken from
the previous build. There was no separate UBEC part anymore.&lt;/p&gt;

&lt;p&gt;This is how it feels to fly analog FPV. Signal interferences are visible,
but the latency is only about 6ms!&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/fpv-06-02.gif&#34; width=&#34;420&#34; /&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://fpv-freerider.itch.io/fpv-freerider&#34;&gt;FPV FreeRider simulator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=391D5dX7LKg&#34;&gt;Lessons how to fly an FPV drone&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;Powered by Betaflight software.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-2&#34;&gt;A pro tip: They recommend twisting the wires to reduce the interference.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Hardware-Efficient Stochastic Binary CNN Architectures for Near-Sensor Computing</title>
      <link>https://penkovsky.com/publication/stochastic-binary-cnn/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0100</pubDate>
      
      <guid>https://penkovsky.com/publication/stochastic-binary-cnn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Autonomous Factory</title>
      <link>https://penkovsky.com/project/autonomous-factory/</link>
      <pubDate>Thu, 14 Oct 2021 07:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/project/autonomous-factory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reservoir computing with biocompatible organic electrochemical networks for brain-inspired biosignal classification</title>
      <link>https://penkovsky.com/publication/biocompatible-reservoir-computing/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/publication/biocompatible-reservoir-computing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Quadcopter From Scratch</title>
      <link>https://penkovsky.com/homelab/quadcopter/</link>
      <pubDate>Sun, 09 May 2021 11:33:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/homelab/quadcopter/</guid>
      <description>

&lt;p&gt;Recently NASA has made the first powered flight on Mars.
They have deployed a drone called &lt;a href=&#34;https://en.wikipedia.org/wiki/Ingenuity_(helicopter)&#34;&gt;Ingenuity&lt;/a&gt;
costing about $85 million. The helicopter was able to fly
on about ten meters altitude (as of May, 7)
over the surface of the Red Planet.&lt;/p&gt;

&lt;p&gt;Coincidently, I have also built a flying drone.
This looked like a good challenge and an opportunity to
learn about unmanned aerial vehicles (UAVs).&lt;/p&gt;

&lt;p&gt;Here is what I learned.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/copter.gif&#34; alt=&#34;Ingenuity helicopter hovering on Mars (2021). Image credit: NASA/JPL-Caltech.&#34; width=&#34;590&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Ingenuity helicopter hovering on Mars (2021). Image credit: NASA/JPL-Caltech.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#parts&#34;&gt;Parts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assembling-a-drone&#34;&gt;Assembling a Drone&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#some-of-the-challenges-i-have-faced&#34;&gt;Some of the Challenges I Have Faced&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;parts&#34;&gt;Parts&lt;/h2&gt;

&lt;p&gt;What you will essentially need is propellers, motors, and some way to power and control them.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/parts-flat.jpg&#34; alt=&#34;Our quadcopter parts&#34; width=&#34;700&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Our quadcopter parts
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Part&lt;/th&gt;
&lt;th&gt;Qty&lt;/th&gt;
&lt;th&gt;Unit W. (g)&lt;/th&gt;
&lt;th&gt;Weight (g)&lt;/th&gt;
&lt;th&gt;Price (EUR)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Arm (printed)&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;52&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Arm support (printed)&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3.5&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Base (v1.1) (printed)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Top (v1.1) (printed)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/ZOP-Power-11_1V-1100mAh-65C-3S-Lipo-Battery-XT60-Plug-p-1085893.html&#34;&gt;1100 mAh Battery 3S&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;117&lt;/td&gt;
&lt;td&gt;117&lt;/td&gt;
&lt;td&gt;14.72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2300 KV Motors 2204&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;14.02&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/Racerstar-RS20Ax4-20A-4-in-1-Blheli_S-Opto-ESC-2-4S-Support-Dshot150-Dshot300-for-RC-FPV-Racing-Drone-p-1068210.html&#34;&gt;ESC (4 in 1)&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;24.84&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/F3-Flight-Controller-6-DOF-or-10-DOF-for-RC-Multirotor-FPV-Racing-Drone-p-1010232.html&#34;&gt;F3 flight controller&lt;/a&gt;*&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;18.87&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Radio receiver (FS-iA10B)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;17.6&lt;/td&gt;
&lt;td&gt;17.6&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/DC-DC-Converter-Step-Down-Module-UBEC-3A-5V-or-12V-BEC-For-RC-Airplane-FPV-for-RC-Drone-FPV-Racing-p-981978.html&#34;&gt;UBEC 3A 5V&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;3.13&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Wires*&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Bolts and nuts*&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;&amp;lt;10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/10-Pairs-GEPRC-5040-V2-5-Inch-3-Blade-Propeller-Transparent-Color-For-RC-Multirotor-FPV-Racing-Drone-p-1169484.html&#34;&gt;5040 Propellers&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;7.38&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/Suleve-M3NH12-50Pcs-M3-Nylon-Hex-Hexagonal-Female-Thread-PCB-Standoff-Spacers-2025303540mm-p-1262027.html&#34;&gt;Nylon spacers 40 mm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;5.72&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/10PCS-Eachine-Lipo-Battery-Tie-Down-Strap-260mm-For-FPV-RC-Drone-p-1137622.html&#34;&gt;&amp;quot;Velcro&amp;quot; fasteners&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2-3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;1.63&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/Amass-XT60-Male-Female-Plug-Connector-12AWG-10cm-Power-Cable-p-1155466.html&#34;&gt;XT60 connector&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;3.27&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.banggood.com/fr/4-PCS-22XX-Series-Motor-Silicone-Anti-vibration-Pad-in-for-RC-Drone-FPV-Racing-Drone-p-1153904.html&#34;&gt;Motor anti-vibration pads&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2.01&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Total**&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;418.6&lt;/td&gt;
&lt;td&gt;124.59&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;small&gt;* Approximate weight.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;** Total price without LiPo charger (iMAX B6), radio transmitter, and
camera. You can reuse those from other projects.  The prices are given for
indicative purpose only. The parts are not guaranteed to be optimal or
cheapest.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;The 3D printed frame was downloaded from Thingiverse: design called
&lt;a href=&#34;https://www.thingiverse.com/thing:629338&#34;&gt;Peon230&lt;/a&gt;. Initially I printed everything in PLA. However, I have found
out that, when crashing, base and top parts tend to break. Now, I use nylon
for those two parts: they are lighter in nylon and do not break so easily.  By
the way, I did not use glue for platform adhesion when printing with PLA&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-1&#34;&gt;&lt;a href=&#34;#fn:fn-1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.
Printing directly on the glass platform gave parts a shiny finish.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/3dprinting.gif&#34; alt=&#34;Fabricating quadcopter frame. Overall it took 11 hours to print all the parts.&#34; width=&#34;520&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Fabricating quadcopter frame. Overall it took 11 hours to print all the parts.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h3 id=&#34;some-jargon&#34;&gt;Some Jargon&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ESC&lt;/strong&gt; = electronic speed controller. Those translate control pulses coming
from the flight controller into voltage actually driving motors. The ESC I used
in this build contains actually four ESCs, permitting to control all four
motors. That reduces the copter&#39;s weight, which is great.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UBEC&lt;/strong&gt; = universal battery elimination circuit (DC-DC converter). Helped me
to use a single battery both for the motors (12 V) and for the flight
controller (5 V). UBECs are switching converters and they are recommended over
linear DC converters, which dissipate a lot of heat when stepping down the
voltage.&lt;/p&gt;

&lt;p&gt;(Battery) &lt;strong&gt;3S&lt;/strong&gt; = 3 cells. Each cell contributes 3.7 V, therefore 11.1 V
total. I used a battery with capacity of 1100 mAh. This battery gave me up to
15 minutes to fly.&lt;/p&gt;

&lt;p&gt;Motor characteristics. &lt;strong&gt;2300 KV&lt;/strong&gt;: 2300 revolutions per minute (RPMs) per volt
(with no load attached to that motor). Therefore, at 12 volts, these motors are
expected to achieve 12 * 2300 = 27600 RPMs. &lt;strong&gt;2204&lt;/strong&gt;: 22  is the rotor diameter
and 04 is the stator height. Larger motors give you more torque, which is
related to the uplift force you want to generate. This is especially important
when considering the vehicle&#39;s weight.  Racing drones have high thrust to
weight ratio enhancing their maneuverability and ability to rapidly accelerate
Camera drones, on the other hand, have lower thrust to weight ratio making them
more stable and easier to pilot.&lt;/p&gt;

&lt;h3 id=&#34;battery-safety&#34;&gt;Battery Safety&lt;/h3&gt;

&lt;!-- Speaking about the battery, --&gt;

&lt;p&gt;The nominal voltage of a lithium-polymer (LiPo) battery cell (3.7 V) is
actually closer to its storage voltage (3.8 V). When a battery cell is fully
charged, it reaches 4.2 V. The battery should never be overcharged because of
an explosion/fire hazard. Also discharging under 3 V is not recommended as the
battery may break. It is a good idea using a balance charger that controls each
cell individually. &lt;strong&gt;Be careful with your batteries&lt;/strong&gt;. There exist special
safety bags designed for LiPo charging.  Never charge your batteries
unattended.&lt;/p&gt;

&lt;!-- The video below gives an idea what can happen if such battery is
improperly handled.


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/CnNId0mDnBo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 --&gt;

&lt;h2 id=&#34;assembling-a-drone&#34;&gt;Assembling a Drone&lt;/h2&gt;

&lt;h3 id=&#34;soldering-motor-wires&#34;&gt;Soldering Motor Wires&lt;/h3&gt;

&lt;p&gt;First of all we need to make sure that our electronic part (flight controller, ESCs, motors, etc.) works properly.
We solder three wires of each motor directly to ESCs.
Please pay attention to the motor wiring as neighboring motors rotate
&lt;em&gt;in opposite directions&lt;/em&gt;.
Then, we solder an XT60 battery connector.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/4Ry7khyMQZo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;In parallel to motors we solder a UBEC, not shown on the video&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-2&#34;&gt;&lt;a href=&#34;#fn:fn-2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.
We connect UBEC to power the flight controller from the same battery.&lt;/p&gt;

&lt;p&gt;Here is an example diagram how the flight controller can be connected to the
receiver via the iBus protocol. It is also shown how the four motor outputs are
connected to electronic speed controllers. Usually ground (black) wires are
connected to the ESCs for the ground reference&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fn-3&#34;&gt;&lt;a href=&#34;#fn:fn-3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. If you decide to power
the flight controller from ESCs (provided that your ESCs have BEC circuits), it
is not recommended to provide more then one VCC (typically red) wire. In my
configuration I do not power the flight controller from ESCs. Instead, I use a
separate UBEC connected to the battery in parallel.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/quad/diag-ibus.png&#34; alt=&#34;Wiring the receiver and, flight controller, and motor ESCs&#34; width=&#34;590&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Wiring the receiver and, flight controller, and motor ESCs
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The diagram above also illustrates the direction of the motor rotation. Pay
attention as it is equally important to install the appropriate propellers
before the flight. Crucially, all four propellers will have to push the air
down. It is also a good idea to test every motor individually (without
propellers of course) to verify if signals are arriving to the correct motors
(see &lt;a href=&#34;#tuning-the-flight-controller&#34;&gt;Tuning the Flight Controller&lt;/a&gt; section
below).&lt;/p&gt;

&lt;h3 id=&#34;complete-build&#34;&gt;Complete Build&lt;/h3&gt;

&lt;p&gt;In this video we assemble the frame from earlier printed parts.  We put motors,
ESCs, flight controller, and the receiver on the frame.  The flight controller
is bolted on top of the 4-in-1 ESC.  Then, we connect the radio receiver to the
flight controller.  We also connect flight controller output wires to ESCs.  We
could solder everything instead, but these connections are already good for the
test. We test connection with a transmitter and the motors. We finalize the build
by putting the remaining part of the frame on top.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/kusp-hsykl8&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Please also note that it is crucial that your final build is tight.  No wire,
nothing should be in the way of your propellers.&lt;/p&gt;

&lt;h3 id=&#34;tuning-the-flight-controller&#34;&gt;Tuning the Flight Controller&lt;/h3&gt;

&lt;p&gt;While your UAV may seem functional, it is probably not yet ready to fly. In
fact, the flight controller is probably the most important part, it acts as a
&amp;quot;quadcopter&#39;s brain&amp;quot;. The controller interprets the received radio commands and
the data coming from its sensors, most notably from the inertia measurement
unit (IMU), to stabilize and steer the vehicle. In fact, without a flight
controller it would be virtually impossible for a human to pilot a quadcopter.&lt;/p&gt;

&lt;p&gt;To make sure the copter interprets the flight situation adequately, the
controller has to be properly calibrated. This includes calibrating the IMU and
compass. It is also important to verify that the remote control commands are
properly interpreted. And that the appropriate motors are activated. To perform
these individual checks and calibrations, I used
&lt;a href=&#34;http://cleanflight.com&#34;&gt;Clean Flight&lt;/a&gt; software. However, there exist multiple
alternative options, such as &lt;a href=&#34;https://betaflight.com/&#34;&gt;Beta Flight&lt;/a&gt;, which is a
popular fork of Clean Flight.&lt;/p&gt;

&lt;h2 id=&#34;some-of-the-challenges-i-have-faced&#34;&gt;Some of the Challenges I Have Faced&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Vibrations on captured videos from the quadcopter turned out to be mostly because of slightly damaged propellers (after emergency landings)&lt;/li&gt;
&lt;li&gt;The best way to position antennas turned out to be along the body. This way they don&#39;t get into the way if crashing.&lt;/li&gt;
&lt;li&gt;Regulations. In Europe, you need to obtain a special permission to fly a drone. Also there are very strict limitations where you can fly as a hobbyist.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am still learning to fly this thing.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/kVYTW7eJe7k&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;



&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/7OXhmJnP2sY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;h2 id=&#34;next-episode&#34;&gt;Next Episode&lt;/h2&gt;

&lt;p&gt;Learn how to &lt;a href=&#34;https://penkovsky.com/homelab/fpv-quad/&#34;&gt;upgrade to FPV&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Ingenuity_(helicopter)&#34;&gt;Ingenuity helicopter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cleanflight.com&#34;&gt;Clean Flight&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://fpv-freerider.itch.io/fpv-freerider&#34;&gt;FPV FreeRider simulator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=391D5dX7LKg&#34;&gt;Lessons how to fly an FPV drone&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fn-1&#34;&gt;It is always advised to apply 3d printing glue for nylon prints because of high warping forces of this material.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-2&#34;&gt;I used UBEC in the second build. In the first build, I had a separate battery and a linear step-up DC converter to power the flight controller.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fn-3&#34;&gt;Since I use a 4-in-1 ESC, it is a single ground wire.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fn-3&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Optical Computing Applications</title>
      <link>https://penkovsky.com/talk/optical-computing-applications2021/</link>
      <pubDate>Wed, 21 Apr 2021 15:40:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/talk/optical-computing-applications2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>3D Printing Tutorial: Designing a Micro Drone Frame</title>
      <link>https://penkovsky.com/homelab/beatle/</link>
      <pubDate>Sun, 21 Mar 2021 18:40:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/homelab/beatle/</guid>
      <description>&lt;p&gt;Here is a step by step tutorial on how to design objects for 3D printing using
OpenSCAD. We illustrate the design process by creating a micro quadcopter
frame. This small drone bears the code name of Beatle-1.  After following the
tutorial you will be able to conceive your own designs for 3D printing.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#3d-printing-intro&#34;&gt;3D Printing Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#designing-a-drone-frame&#34;&gt;Designing a Drone Frame&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#building&#34;&gt;Building&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#demo&#34;&gt;Demo&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;3d-printing-intro&#34;&gt;3D Printing Intro&lt;/h2&gt;

&lt;p&gt;3D printing (known in the industry as &lt;em&gt;additive manufacturing&lt;/em&gt;) is a process of
fabrication of a 3D object from a digital model. 3D printer prices have
significantly dropped during past decade, so 3D printing is much more
common nowadays. The reason why we don&#39;t see such printers in every household
is not economical, but rather psychological. People often prefer ready-made
solutions to their problems.&lt;/p&gt;

&lt;p&gt;Despite that, maker communities such as
&lt;a href=&#34;https://www.thingiverse.com/thing:1221911&#34;&gt;Thingiverse&lt;/a&gt; provide millions of
objects for free. Having access to a 3D printer means that you can download and
fabricate things that you would need to buy otherwise. Last Christmas, for
example, I have printed pegs to hang Christmas stockings :)&lt;/p&gt;

&lt;h4 id=&#34;3d-printing-steps&#34;&gt;3D printing steps&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Computer-aided design (CAD)&lt;/li&gt;
&lt;li&gt;Export to STL model (de-facto standard format)&lt;/li&gt;
&lt;li&gt;File preparation (slicing) - transforming into the series of commands &amp;quot;understood&amp;quot; by a 3D printer&lt;/li&gt;
&lt;li&gt;Building (&amp;quot;3D printing&amp;quot;)&lt;/li&gt;
&lt;li&gt;Post-processing (removing fabricated parts from the printing bed, removing support, etc.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;materials&#34;&gt;Materials&lt;/h4&gt;

&lt;p&gt;Plastics, such as &lt;a href=&#34;https://pick3dprinter.com/pla-3d-printing/&#34;&gt;PLA&lt;/a&gt;, are the
most common materials you can use to 3D print objects. While PLA is one of the
popular materials to print with, it is also relatively fragile.  For increased
robustness, it is possible to use e.g. nylon, which like PLA is also compatible
with &lt;a href=&#34;https://en.wikipedia.org/wiki/Fused_filament_fabrication&#34;&gt;FFF (FDM)&lt;/a&gt;, the most common 3D printing process. In the industry,
there exist different other methods to fabricate objects in metal, carbon
fiber, PEEK, and many other
&lt;a href=&#34;https://www.simplify3d.com/support/materials-guide/&#34;&gt;materials&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;faq&#34;&gt;FAQ&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;If you’ve ever written a simple blog post or email in HTML, you can handle OpenSCAD.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&#34;https://cubehero.com/2013/11/19/know-only-10-things-to-be-dangerous-in-openscad/&#34;&gt;Cubehero&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;OpenSCAD vs traditional graphic CAD interfaces&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why should I use OpenSCAD?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; There might be different reasons:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;OpenSCAD is a great project (and it is open source).&lt;/li&gt;
&lt;li&gt;You prefer programming to avoid wasting time for repeatable actions. Then, you can learn OpenSCAD in about an hour.&lt;/li&gt;
&lt;li&gt;Or maybe you have never done any programming, but would not mind to acquire this valuable skill.&lt;/li&gt;
&lt;li&gt;Your OpenSCAD models are easily parametrizable, virtually out-of-box.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;designing-a-drone-frame&#34;&gt;Designing a Drone Frame&lt;/h2&gt;

&lt;p&gt;Some requirements for the frame I had in mind:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;It should accommodate four motors of a given shape.&lt;/li&gt;
&lt;li&gt;The motor positions should be stable when flying (they should not wiggle).&lt;/li&gt;
&lt;li&gt;The propellers should be far enough from each other.&lt;/li&gt;
&lt;li&gt;Easy to print (fast, no support, one or two pieces).&lt;/li&gt;
&lt;li&gt;Lightweight frame.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;CAD design is an iterative process. My first attempt at designing a drone frame was naive and looked like this.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/rev01.png&#34; alt=&#34;First version. Don&amp;#39;t recommend.&#34; width=&#34;500&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    First version. Don&#39;t recommend.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;A quadcopter&#39;s frame is simply a holder for four motors and a body. Right? Wrong. The biggest issue with this design was that the arms were fragile. In fact, one of them cracked while I was removing the newly fabricated frame from printer&#39;s platform. Clearly, a better solution was required.&lt;/p&gt;

&lt;p&gt;One improvement might be to orient the arms vertically, not horizontally as they are. That would make them more robust in the vertical direction and prevent undesired wiggling. I have also recalled that I have seen a micro quadcopter on Thingiverse some time ago. Indeed, &lt;a href=&#34;https://www.thingiverse.com/thing:1221911&#34;&gt;this copter&#39;s design&lt;/a&gt; suggests a more robust frame. What I like about it is that each motor is supported not by one, but two segments making it more stable in the horizontal plane. So let&#39;s see what we can build with OpenSCAD.&lt;/p&gt;

&lt;h3 id=&#34;basic-operations-motor-compartment-design&#34;&gt;Basic Operations: Motor Compartment Design&lt;/h3&gt;

&lt;p&gt;I like to start my design from individual components (bottom-up), however, the opposite method (top-bottom) is also perfectly valid.
For starters, I have created emplacements for &lt;a href=&#34;https://www.olimex.com/Products/Robot-CNC-Parts/Micro-Motors/MOTOR-F1607/&#34;&gt;F-1607 DC motors&lt;/a&gt;,
which I have ordered from Olimex. This part can be imagined as a shell around the motor, or a Boolean difference between the external box (gray cylinder) and the motor itself (red cylinder).&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/01a.png&#34; alt=&#34;A motor holder is simply a difference between two cylinders: the outer (grey) and the inner (highlighted in red).&#34; width=&#34;300&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    A motor holder is simply a difference between two cylinders: the outer (grey) and the inner (highlighted in red).
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;The motor dimensions given by Olimex are 7 mm diameter and 16.5 mm height. I have chosen shell size parameter to be 0.8 mm. I have lifted the inner cylinder by 0.8 mm (&lt;code&gt;translate&lt;/code&gt;) so that the result is a box, not a tube. The red transparent cylinder only illustrates where the motor goes, so it will be not visible in the final rendering.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;shell&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;;

difference() {
  cylinder(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; shell, h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;);
  translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, shell])
    cylinder(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,  h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;);
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;How about the motor wires? We can carve out a side and a bottom holes using Boolean &lt;code&gt;difference&lt;/code&gt; and &lt;code&gt;union&lt;/code&gt; transformations.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/01.png&#34; alt=&#34;A motor compartment: perspective view and top view. The holes will allow motor wires to escape comfortably.&#34; width=&#34;500&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    A motor compartment: perspective view and top view. The holes will allow motor wires to escape comfortably.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; SlotF1607(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;,
                 d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,
                 shell&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;// Shell thickness
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                 slack&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;   &lt;span style=&#34;color:#75715e&#34;&gt;// Some extra space to accommodate a motor
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                 ) {
    difference() {
       &lt;span style=&#34;color:#75715e&#34;&gt;// Motor compartment
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;       cylinder(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; shell, h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;);

       union () {
           &lt;span style=&#34;color:#75715e&#34;&gt;// Motor emplacement
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;           translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, shell])
             cylinder(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; slack,  h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;);

           &lt;span style=&#34;color:#75715e&#34;&gt;// Bottom hole for motor contacts/wires
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;           cylinder(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;h, center&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;true&lt;/span&gt;);

           &lt;span style=&#34;color:#75715e&#34;&gt;// Wires hole
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;           translate([d&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
               cube([d, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;, h &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], center&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;true&lt;/span&gt;);
       }
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Last but not least you can see that I have also given some slack for a motor (0.1 mm) to more easily fit into its compartment.&lt;/p&gt;

&lt;h3 id=&#34;placing-motor-compartments&#34;&gt;Placing Motor Compartments&lt;/h3&gt;

&lt;p&gt;Usually quadcopter size is characterised by its diagonal, i.e. the largest
distance between the centers of the propellers (thus the centers of the
motors). Our microdrone is small and its diagonal will be only 92 mm (it can
fit into a hand). The nearest distance between any two motors is then computed
as $\sqrt{2} \cdot (\text{diagonal} / 2)$. This distance is an edge of a square
with 92 mm diagonal. Now, we can easily place the four motors on the vertices
of the imaginary square.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/02a.png&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;diagonal &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;92&lt;/span&gt;;

motors_dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sqrt(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; diagonal);

&lt;span style=&#34;color:#75715e&#34;&gt;// Half distance between motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;half_dist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; motors_dist;

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]) {
    &lt;span style=&#34;color:#75715e&#34;&gt;// Place the motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    translate([half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i, half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
        SlotF1607();
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note that &lt;code&gt;for (i = [1, -1], j = [1, -1])&lt;/code&gt; is simply a shortcut of two nested loops, i.e. it is the same as&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;...&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Anything wrong? Yes, we forgot to properly rotate the wire outlets.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]) {
    &lt;span style=&#34;color:#75715e&#34;&gt;// Place the motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    translate([half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i, half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
        rotate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j])  &lt;span style=&#34;color:#75715e&#34;&gt;// &amp;lt;--
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;            SlotF1607();
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/02b.png&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;Now much better.&lt;/p&gt;

&lt;h3 id=&#34;motors-support&#34;&gt;Motors Support&lt;/h3&gt;

&lt;p&gt;We would like to connect the motors using something like an arc. How to do that? First, create and place a small segment:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;41&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
    square([&lt;span style=&#34;color:#ae81ff&#34;&gt;1.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3.6&lt;/span&gt;]);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, by rotating this segment in space (&lt;a href=&#34;https://en.wikibooks.org/wiki/OpenSCAD_User_Manual/Using_the_2D_Subsystem#Rotate_Extrude&#34;&gt;&lt;code&gt;rotate_extrude&lt;/code&gt;&lt;/a&gt;), we obtain a 90-degree arc:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; arc() {
    rotate_extrude(angle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt;, $fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;70&lt;/span&gt;)
        translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;41&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
            square([&lt;span style=&#34;color:#ae81ff&#34;&gt;1.2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3.6&lt;/span&gt;]);
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/03a.png&#34; alt=&#34;An arc created with rotate_extrude()&#34; width=&#34;300&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    An arc created with rotate_extrude()
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Let us link those arcs to the motors.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]) {
    &lt;span style=&#34;color:#75715e&#34;&gt;// Place the motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    translate([half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i, half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
        rotate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j])
            SlotF1607(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6.5&lt;/span&gt;);

    &lt;span style=&#34;color:#75715e&#34;&gt;// Connect the motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    translate([half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
        rotate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j])
            arc();
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/03b.png&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;I figured out that probably 6.5 mm slot heigh would be enough. That is why I
have specified the height parameter &lt;code&gt;SlotF1607(h=6.5)&lt;/code&gt;. Works like a charm!&lt;/p&gt;

&lt;h3 id=&#34;the-platform&#34;&gt;The Platform&lt;/h3&gt;

&lt;p&gt;By now I have realized that to create the body I could reuse the same method as
for the motor emplacements to create an open box, a box with no top cover.
However, the only distinction would be the shape (a Boolean difference between
rectangular boxes rather than cylinders). Now, I would like to somehow
generalize a method of creating an open box. Ideally, I would like to create
boxes of any base shape (circle, square, etc.), thus parametrizing the method
by a base shape.&lt;/p&gt;

&lt;p&gt;To help me with this idea, OpenSCAD provides &lt;code&gt;children()&lt;/code&gt; method to access
child modules. The new operation could be described as&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; openbox(delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;) {
    difference() {
        resize_somehow(&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;...&lt;/span&gt;)
            children();
        translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,delta])
            children();
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So for example the motor compartment could be created simply as&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;openbox(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;, delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;shell) circle(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Where &lt;code&gt;openbox&lt;/code&gt; would receive a 2D shape as a child (a circle, a square, or a
polygon) and transform it into a 3D shape (a box) of a given height using the
recipe from above. So how to transform a 2D circle into a 3D cylinder? Using a
common method called &lt;code&gt;linear_extrude&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;linear_extrude(&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;) circle(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This method is similar to &lt;code&gt;rotate_extrude&lt;/code&gt; that we used for the arc. However,
it does not rotate the base 2D shape.&lt;/p&gt;

&lt;p&gt;Now, how to create a larger version of the cylinder (becoming the shell)? One
way to do that would be to use &lt;code&gt;scale()&lt;/code&gt; or &lt;code&gt;resize()&lt;/code&gt;. However, a more
efficient method would be to operate on the original 2D object, before
extruding it (that is actually the reason why our &lt;code&gt;openbox&lt;/code&gt; was assigned to
operate on 2D objects). The &lt;a href=&#34;https://en.wikibooks.org/wiki/OpenSCAD_User_Manual/Transformations#offset&#34;&gt;&lt;code&gt;offset()&lt;/code&gt;&lt;/a&gt; transformation does
exactly what we need to: enlarge the 2D object by a &amp;quot;delta&amp;quot; difference (see
&lt;a href=&#34;https://en.wikibooks.org/wiki/OpenSCAD_User_Manual/Transformations#offset&#34;&gt;documentation&lt;/a&gt;).  Therefore, the complete &lt;code&gt;openbox&lt;/code&gt; module
becomes&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; openbox(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;) {
    difference() {
        linear_extrude(h)
            &lt;span style=&#34;color:#75715e&#34;&gt;// Create a larger base by offsetting the child module by delta
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;            offset(delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;delta)
                children();

        translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,delta])
            linear_extrude(h)
                children();
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Create a motor compartment as planned&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;openbox(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;, delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;) circle(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here is how to refactor the SlotF1607 module, making use of &lt;code&gt;openbox&lt;/code&gt;&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; SlotF1607(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16.5&lt;/span&gt;,     &lt;span style=&#34;color:#75715e&#34;&gt;// Module height
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                 d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,        &lt;span style=&#34;color:#75715e&#34;&gt;// Motor diameter
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                 shell&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;// Shell thickness
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                 slack&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;   &lt;span style=&#34;color:#75715e&#34;&gt;// Some extra space to accommodate a motor
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                 ) {
        difference() {
            &lt;span style=&#34;color:#75715e&#34;&gt;// Motor compartment shell
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;            openbox(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;h, delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;shell) circle(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; slack);

            union () {
                &lt;span style=&#34;color:#75715e&#34;&gt;// Bottom hole for motor contacts/wires
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                cylinder(d&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;h, center&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;true&lt;/span&gt;);

                &lt;span style=&#34;color:#75715e&#34;&gt;// Wires hole
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                translate([d&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
                    cube([d, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;, h &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;], center&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;true&lt;/span&gt;);
            }
        }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Similarly, create the body&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;openbox(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3.6&lt;/span&gt;, delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;) square([&lt;span style=&#34;color:#ae81ff&#34;&gt;46&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;], center&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;true&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If it is hard to follow this section, note what we do in the
line above is the same operation as with the cylinders in the
very beginning:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;shell&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;;

difference() {
  cube([&lt;span style=&#34;color:#ae81ff&#34;&gt;46&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; shell, &lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; shell, &lt;span style=&#34;color:#ae81ff&#34;&gt;3.6&lt;/span&gt;]);
  translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, shell])
    cube([&lt;span style=&#34;color:#ae81ff&#34;&gt;46&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3.6&lt;/span&gt;]);
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/04a.png&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;We are essentially done. However, this design somewhat does not inspire me.
Replacing the base square with a rounded one looks like a good idea. After all,
we designed &lt;code&gt;openbox&lt;/code&gt; to support any 2D base shape. Here is a common idiom:
&lt;a href=&#34;https://en.wikibooks.org/wiki/OpenSCAD_User_Manual/Transformations#minkowski&#34;&gt;create a rounded square as a Minkowski sum&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; rounded_square(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;], r&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;) {
    minkowski() {
        square([dim[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; r, dim[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; r], center&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;true&lt;/span&gt;);
        circle(r&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;r);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/04b.png&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;So here we go:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]) {
    &lt;span style=&#34;color:#75715e&#34;&gt;// Place the motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    translate([half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i, half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
        rotate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j])
            SlotF1607(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6.5&lt;/span&gt;);

    &lt;span style=&#34;color:#75715e&#34;&gt;// Connect the motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    translate([half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
        rotate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j])
            arc();
}

openbox(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3.6&lt;/span&gt;, delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;)
    rounded_square([&lt;span style=&#34;color:#ae81ff&#34;&gt;46&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;]);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/04c.png&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;Much better!&lt;/p&gt;

&lt;p&gt;Now, I would like to shave off a bit of weight if possible. So I will introduce
some holes as e.g. in the honeycomb pattern. I will generate an array of
hexagonal cylinders and subtract it from the platform. A hexagonal cylinder is
simply a cylinder with six fragments, i.e. &lt;code&gt;cylinder($fn=6, …);&lt;/code&gt;. Here is an
array of those generated with two nested loops &lt;code&gt;for (i = [-M:M], j = [-N:N])&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; honey_comb(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, M&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, N&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, d1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, d2&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4.6&lt;/span&gt;) {
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;M:M], j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;N:N]) {
        &lt;span style=&#34;color:#75715e&#34;&gt;// Shift the row by d1/4
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (abs(i) &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
            translate([i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d1, j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d2 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; d1&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;h])
                cylinder(d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; d1, h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; h &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, $fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;);
        &lt;span style=&#34;color:#75715e&#34;&gt;// Shift the row by -d1/4
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;
            translate([i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d1, j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d2 &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; d1&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;h])
                cylinder(d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; d1, h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; h &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, $fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Where &lt;code&gt;abs(i) % 2 == 0&lt;/code&gt; simply checks if index &lt;code&gt;i&lt;/code&gt; is an even value so that odd
and even rows are shifted by a different amount.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/honeycomb-array.png&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;Now I use an &lt;code&gt;intersection&lt;/code&gt; with another shape to limit the span of the honeycomb pattern.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;intersection() {
    honey_comb(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;, M&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, N&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, d1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4.1&lt;/span&gt;, d2&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4.9&lt;/span&gt;);

    &lt;span style=&#34;color:#75715e&#34;&gt;// Limited by this volume
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;])
        linear_extrude(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
            rounded_square([dim[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;, dim[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;], r&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;);
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/04d.png&#34; width=&#34;300&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;Finally, I subtract the above pattern and some side holes.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-scad&#34; data-lang=&#34;scad&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// The platform
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; platform(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;46&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;], shell&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;) {
    difference() {
        openbox(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3.6&lt;/span&gt;, delta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.8&lt;/span&gt;) rounded_square(dim);

        union () {
            &lt;span style=&#34;color:#75715e&#34;&gt;// Honey-comb patterned floor
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;            intersection() {
                honey_comb(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;, M&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, N&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, d1&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4.1&lt;/span&gt;, d2&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4.9&lt;/span&gt;);

                &lt;span style=&#34;color:#75715e&#34;&gt;// Limited by this volume
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;                translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;])
                    linear_extrude(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
                        rounded_square([dim[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;, dim[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;], r&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;);
            }

            &lt;span style=&#34;color:#75715e&#34;&gt;// Side holes
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
                translate([&lt;span style=&#34;color:#ae81ff&#34;&gt;12.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, shell &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])
                    cube([&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;], center&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;true&lt;/span&gt;);
        }
    }
}

&lt;span style=&#34;color:#75715e&#34;&gt;// The main module
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;module&lt;/span&gt; beatle1() {
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]) {
        &lt;span style=&#34;color:#75715e&#34;&gt;// Place the motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        translate([half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i, half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
            rotate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j])
                SlotF1607(h&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6.5&lt;/span&gt;);

        &lt;span style=&#34;color:#75715e&#34;&gt;// Connect the motors
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        translate([half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), half_dist &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
            rotate([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; j])
                arc();
    }

    platform();
}

beatle1();&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/04e.png&#34; width=&#34;500&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;That was quite easy. Wasn’t it?&lt;/p&gt;

&lt;p&gt;I made the complete design available on &lt;a href=&#34;https://www.thingiverse.com/thing:4708493&#34;&gt;Thingiverse&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;To learn OpenSCAD, check its official &lt;a href=&#34;https://www.openscad.org/cheatsheet/&#34;&gt;cheatsheet&lt;/a&gt;.
For example, there you will find the magic parameter &lt;code&gt;$fn&lt;/code&gt; (number of fragments) which I have used to make the shapes smooth
(or conversely to create hexagonal cylinders).&lt;/p&gt;

&lt;h2 id=&#34;building&#34;&gt;Building&lt;/h2&gt;

&lt;p&gt;First, export the design as STL. This is quite straightforward:
after rendering the design, press &lt;F7&gt; and save an .stl file.&lt;/p&gt;

&lt;p&gt;Parameters:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fabrication method: &lt;a href=&#34;https://en.wikipedia.org/wiki/Fused_filament_fabrication&#34;&gt;FFF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Material: PLA&lt;/li&gt;
&lt;li&gt;0.2 mm layer height&lt;/li&gt;
&lt;li&gt;Three perimeters&lt;/li&gt;
&lt;li&gt;30 % infill&lt;/li&gt;
&lt;li&gt;Designed to be fabricated with no support&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next, open your favorite slicer software that often comes with a 3D printer.
You will need to specify 0.2 mm layer height and other settings from the list
above.  After slicing (transforming into a series of commands that 3D printer
can perform) the design can be inspected layer by layer.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/posts/beatle1/slicing.png&#34; alt=&#34;Sliced Beatle-1. The pink lines (so-called skirt) will be printed first to stabilize the flow of plastic.&#34; width=&#34;650&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Sliced Beatle-1. The pink lines (so-called skirt) will be printed first to stabilize the flow of plastic.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h2 id=&#34;demo&#34;&gt;Demo&lt;/h2&gt;

&lt;p&gt;I used a set of four F-1607 DC motors with propellers, a flight controller from
a drone toy, and a 150 mAh LiPo battery.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/koSanik0-8I&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;h3 id=&#34;some-of-the-challenges-i-have-faced&#34;&gt;Some of the Challenges I Have Faced&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;The design from the very first version was impractical and fragile.&lt;/li&gt;
&lt;li&gt;Motor wires could be easily detached from the controller. To prevent this, I fixated the wires to the frame.&lt;/li&gt;
&lt;li&gt;I tried several methods to create the &lt;code&gt;openbox&lt;/code&gt; module. The one presented here was the least ambiguous.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;As always, if you have any questions, remarks, or spotted any typos please
send me a message.&lt;/p&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Fused_filament_fabrication&#34;&gt;Fused filament fabrication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.openscad.org/cheatsheet/&#34;&gt;OpenSCAD cheatsheet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Making Your Self-Driving Robot</title>
      <link>https://penkovsky.com/homelab/self-driving-robot/</link>
      <pubDate>Sun, 15 Nov 2020 23:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/homelab/self-driving-robot/</guid>
      <description>

&lt;p&gt;We will build an autonomous robot. Captured by robot&#39;s camera,
video stream will be analyzed by a neural network. The network will be running
on the onboard Raspberry Pi that will steer the robot.  Before you start with
the project, I want you to answer two questions.  First, how
everything will be attached mechanically?  Second, what will be the energy
source?  While your autonomous robot can work from a cardboard box, having a
mechanically sound chassis will greatly improve the result on the AI training
stage. And the question of the energy source is essential for any autonomous
robot. Ready to answer? Then let&#39;s go!&lt;/p&gt;

&lt;h2 id=&#34;parts-and-tools&#34;&gt;Parts And Tools&lt;/h2&gt;

&lt;p&gt;For this project I used:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Raspberry Pi 3B, 1 GB RAM (priceless 😉)&lt;/li&gt;
&lt;li&gt;Power bank (for mobile phone)&lt;/li&gt;
&lt;li&gt;USB to micro-USB cable&lt;/li&gt;
&lt;li&gt;SD memory card class 10, at least 16 GB, $11.99&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/B07DNYQ3PX&#34;&gt;Chassis + 2 DC motors&lt;/a&gt; $13.99&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/B07QKCGX1Z&#34;&gt;Raspberry Pi camera&lt;/a&gt; $17.21&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/B014KMHSW6&#34;&gt;L298N dual H-bridge controller&lt;/a&gt; $6.89&lt;/li&gt;
&lt;li&gt;9 V battery (local store)&lt;/li&gt;
&lt;li&gt;Jumper wires&lt;/li&gt;
&lt;li&gt;Something to attach the components to chassis (I used rubber bands and adhesive putty)&lt;/li&gt;
&lt;li&gt;Enclosure for the electronics&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.fr/gp/product/B07N2QZPJP&#34;&gt;Soldering iron&lt;/a&gt; $20.07&lt;/li&gt;
&lt;li&gt;A laptop with WiFi and SSH client (for robot training)&lt;/li&gt;
&lt;li&gt;Multimeter (I didn&#39;t have one at hand, but it would have been useful)&lt;/li&gt;
&lt;li&gt;Small screw driver&lt;/li&gt;
&lt;li&gt;Wire strippers (optional)&lt;/li&gt;
&lt;li&gt;Breadboard (optional)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the prices may vary and they are here for indicative budget only.
You can also order similar parts on AliExpress or other sites.
The bottom line is that you can easily build a self-driving robot under $100.&lt;/p&gt;

&lt;p&gt;I decided to power the Raspberry Pi board and motors separately so that the
board will be reliably powered, even when the motors battery exhausts itself.
The power bank for that purpose (originally, for a mobile phone) and a USB
cable I already had at home, so they didn&#39;t count towards the budget.&lt;/p&gt;

&lt;p&gt;I recommend at least 16 GB SD memory card so that you can install the Raspberry
Pi OS and have some storage space for training data acquisition (images from
the camera). Regarding camera itself, usually it is recommended to use a
wide-angle camera. However, feel free to use any camera you have (as I did).&lt;/p&gt;

&lt;p&gt;The H-bridge circuit is useful to allow DC motors to run forwards or backwards.
Unlike some tutorials, mine H-bridge required between 7 V and 35 V driving
voltage. To see if the circuit is working, check if the red LED is on.  With 6
V driving voltage, it was still off. Therefore, I used a 9 V battery to power
the motors.  Finally, using a laptop with Linux will make your life easier. But
feel free to use whatever you have.&lt;/p&gt;

&lt;h2 id=&#34;part-i-let-the-hack-begin&#34;&gt;Part I: Let The Hack Begin&lt;/h2&gt;

&lt;h3 id=&#34;assemble-the-robot&#34;&gt;Assemble The Robot&lt;/h3&gt;

&lt;h4 id=&#34;1-assemble-the-chassis&#34;&gt;1. Assemble the chassis.&lt;/h4&gt;

&lt;p&gt;Attach the wheels, the ball caster, and the motors.
Don&#39;t mind the battery holder, I didn&#39;t use it in the end.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/chassis.jpg&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;2-solder-wires-to-the-motors&#34;&gt;2. Solder wires to the motors.&lt;/h4&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/solder-wires.jpg&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;3-connect-motors-to-the-h-bridge-controller&#34;&gt;3. Connect motors to the H-bridge controller.&lt;/h4&gt;

&lt;p&gt;Here you will need a small screw driver.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/H-bridge1.jpg&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;4-connect-the-motors-controller-to-the-raspberry-pi&#34;&gt;4. Connect the motors controller to the Raspberry Pi.&lt;/h4&gt;

&lt;p&gt;Here I use a breadboard in-between, but feel free to connect the jumper wires
directly. You can choose any free (non-specialized) GPIOs pins.
Please refer to the board&#39;s pinout.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/pinout.png&#34; alt=&#34;Raspberry Pi pinout. Source: [pinout.xyz](https://pinout.xyz/).&#34; width=&#34;500&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    Raspberry Pi pinout. Source: &lt;a href=&#34;https://pinout.xyz/&#34;&gt;pinout.xyz&lt;/a&gt;.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;For instance, I have chosen pins &lt;code&gt;15&lt;/code&gt;, &lt;code&gt;11&lt;/code&gt;, &lt;code&gt;13&lt;/code&gt;, and &lt;code&gt;31&lt;/code&gt;. Note those
are Raspberry Pi pins, not GPIO numbers.  For example, the above pins
correspond to GPIO 22, GPIO 17, GPIO 27, and GPIO 6.  Remember those magic
numbers.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Please do not confuse pins and GPIO numbers.
The &lt;code&gt;gpiozero&lt;/code&gt; Python module refers to GPIO numbers,
whereas the software that we will use later requires Raspberry Pi pins.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To determine the order in which you connect the jumper wires to the controller
you may want to check the controller&#39;s data sheet. Or determine the pins
experimentally, testing the digital inputs in isolation. There are four
wires: two controlling the left wheel (&lt;code&gt;IN1&lt;/code&gt; and &lt;code&gt;IN2&lt;/code&gt;) and
two for the right wheel control (&lt;code&gt;IN3&lt;/code&gt; and &lt;code&gt;IN4&lt;/code&gt;).
For example, when both &lt;code&gt;IN1&lt;/code&gt; and &lt;code&gt;IN3&lt;/code&gt; digital signals are high,
the robot will move forward.&lt;/p&gt;

&lt;p&gt;Note that you will have to connect the ground (GND) of the controller board and
the ground of Raspberry.  Otherwise, your controller may not be able to
interpret the digital signal it receives from the Raspberry.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/H-bridge2.jpg&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;5-power-up-the-motors-controller-with-a-9-v-battery&#34;&gt;5. Power up the motors controller with a 9 V battery.&lt;/h4&gt;

&lt;p&gt;I didn&#39;t have a battery connector at hand, so I used a chewing gum to
attach the wires to the battery.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/H-bridge3.jpg&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;6-power-up-the-raspberry-pi&#34;&gt;6. Power up the Raspberry Pi.&lt;/h4&gt;

&lt;p&gt;Finally, power up the Raspberry Pi with a power bank using a small USB cable.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You may want to assemble the modules neatly so that the robot is actually
autonomous. Make sure that the hardware is fixed well and will not move
during the ride.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/proto.jpg&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;sanity-check&#34;&gt;Sanity Check&lt;/h3&gt;

&lt;p&gt;Let us test what robot we have built so far! First, we connect to the
Raspberry Pi. This is done via SSH.
&lt;a href=&#34;https://gist.github.com/masterdezign/5370fdfb113e84d39314f71281d3d7cb&#34;&gt;Setup Raspberry Pi WiFi connection&lt;/a&gt;
and &lt;a href=&#34;https://penkovsky.com/homelab/raspi-ssh-over-wifi/&#34;&gt;connect to your board&lt;/a&gt;.
Now, we can play with the robot interactively.
Being connected to the Raspberry Pi via SSH, type
&lt;code&gt;python&lt;/code&gt; to open up the Python interpreter.
Then define your robot object&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; gpiozero &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Robot
robot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Robot(left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17&lt;/span&gt;), right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note the GPIO numbers we have discussed before.
Those are your connections to the bridge controller.
To make the robot do something&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;robot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here &lt;code&gt;0.4&lt;/code&gt; is the speed with which to rotate the left wheel.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/test1.gif&#34; width=&#34;300&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;To stop the robot, issue&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;robot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stop()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Type &lt;code&gt;exit()&lt;/code&gt; (or press Ctrl-D) to exit the Python&#39;s interpreter&#39;s shell.  In
your favourite text editor you can create a sequence of actions to pre-program
your robot.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; gpiozero &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Robot
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; time &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sleep
robot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Robot(left &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;22&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;17&lt;/span&gt;), right &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;27&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Left&amp;#34;&lt;/span&gt;)
robot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;left(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;)
sleep(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
robot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stop()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Right&amp;#34;&lt;/span&gt;)
robot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;right(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;)
sleep(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
robot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stop()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Forward&amp;#34;&lt;/span&gt;)
robot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;forward(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;)
sleep(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
robot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stop()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here we ask the robot to rotate left for a second,
then rotate right for a second, and finally, move
forward for three seconds.
Save it to a file on your Raspberry Pi, e.g. &lt;code&gt;robo.py&lt;/code&gt;,
and execute&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;python robo.py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If we have missed something, here is an official Raspberry Pi
&lt;a href=&#34;https://projects.raspberrypi.org/en/projects/build-a-buggy/1&#34;&gt;tutorial&lt;/a&gt; to assist with assembling your robot.
Before you continue, now is a good time to
&lt;a href=&#34;https://www.dexterindustries.com/howto/installing-the-raspberry-pi-camera/&#34;&gt;attach the camera&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;part-ii-remote-control&#34;&gt;Part II: Remote Control&lt;/h2&gt;

&lt;p&gt;Now that the robot is based on the Raspberry Pi,
we can do amazing things with it.
For example, we can benefit from the
&lt;a href=&#34;https://github.com/autorope/donkeycar&#34;&gt;DonkeyCar&lt;/a&gt;,
an open source platform to build a small scale self driving car.
You will have to &lt;a href=&#34;http://docs.donkeycar.com/guide/install_software/&#34;&gt;follow the instructions&lt;/a&gt;
to install the necessary software on your Raspberry Pi.&lt;/p&gt;

&lt;p&gt;As soon as you finish with installation,
&lt;a href=&#34;http://docs.donkeycar.com/guide/create_application/&#34;&gt;create your Donkeycar App&lt;/a&gt;. Connect to your Pi with SSH and type&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;donkey createcar --path ~/mycar&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then check the newly created project in &lt;code&gt;~/mycar&lt;/code&gt;. Thankfully, Donkey
supports our two-wheel robot almost out of the box. The remaining bits are to
edit &lt;code&gt;config.py&lt;/code&gt;. Set&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;DRIVE_TRAIN_TYPE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DC_TWO_WHEEL&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will select the appropriate motor&#39;s driver.
Finally, set the pins as discussed before:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;HBRIDGE_PIN_LEFT_FWD &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;
HBRIDGE_PIN_LEFT_BWD &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;
HBRIDGE_PIN_RIGHT_FWD &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt;
HBRIDGE_PIN_RIGHT_BWD &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, test if everything was successful.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;cd ~/mycar
python manage.py drive&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In under a minute, the Donkey server should be up
and running. As a result, you will be able
to access a control web interface
using &lt;code&gt;http://&amp;lt;your car&#39;s IP&amp;gt;:8887&lt;/code&gt;.
This will allow you to remotely control the car
and capture the video stream with its camera.
Like in this video.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/oz7arGJ-uvM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;h2 id=&#34;part-iii-making-it-self-driving&#34;&gt;Part III: Making It Self-Driving&lt;/h2&gt;

&lt;p&gt;Being able to control your car remotely is useful
to collect the training data for the neural network.
But first we may want to set up a driving track like this.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/training.jpg&#34; width=&#34;400&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;Now, drive several laps on your track. The captured image data are automatically
stored in &lt;code&gt;~/mycar/data&lt;/code&gt;.
Having collected a sufficient amount of data
we pass to the driving model (neural network) training.
Here is how the world looks like from the car&#39;s viewpoint.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/1L9VchNi3B0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Green vector illustrates human-driver commands
and the blue one is the model after training.&lt;/p&gt;

&lt;p&gt;You want to revisit &lt;code&gt;~/mycar/config.py&lt;/code&gt; to set the neural network parameters,
e.g. &lt;code&gt;LEARNING_RATE&lt;/code&gt; and &lt;code&gt;BATCH_SIZE&lt;/code&gt;.
The key training command is&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;python manage.py train --type linear --model models/mypilot.h5&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You can experiment with any of the driving models:
&lt;code&gt;linear&lt;/code&gt;, &lt;code&gt;categorical&lt;/code&gt;, &lt;code&gt;rnn&lt;/code&gt;, &lt;code&gt;imu&lt;/code&gt;, &lt;code&gt;behavior&lt;/code&gt;, etc.
More housekeeping details can be found in
&lt;a href=&#34;https://colab.research.google.com/drive/1lkQUvJ2Quu0m_LNLJvSicl9zDgCf4Qu6?usp=sharing&#34;&gt;this notebook&lt;/a&gt; adapted for TensorFlow 2.
The original version can be found
&lt;a href=&#34;http://github.com/robocarstore/donkey-car-training-on-google-colab/blob/master/Donkey_Car_Training_using_Google_Colab.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Et voilà&lt;/em&gt;, your self-driving car is ready!&lt;/p&gt;

&lt;hr style=&#34;width:50%&#34;&gt;

&lt;p&gt;&lt;p&gt;
Now, run the auto-pilot&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;screen
cd ~/mycar
python manage.py drive --model models/mypilot.h5&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube-nocookie.com/embed/k36-46wPwvA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;h2 id=&#34;what-could-be-done-better&#34;&gt;What Could Be Done Better&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The mechanical part could be better. After I have mounted the
acrylic chasssis, I have realized that the motors do not hold firmly.
Moreover, there was a friction between one of the wheels and chassis.
Therefore, I had to programmatically adjust the power
to balance the wheels.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Moreover, I believe that having a streering wheel motor
would be much more efficient, instead of
&lt;a href=&#34;https://www.societyofrobots.com/programming_differentialdrive.shtml&#34;&gt;differential drive&lt;/a&gt;, as they call this construction in
the robotics community. To test in the future.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Likewise, it is important to keep your camera in the same position during
training and during self-piloting. Also make sure that the battery is
always charged.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;It would be nice to have a 9 V battery connector, instead of a piece of
putty. As simple as that.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Quality of the training data. The better is your driving strategy, the
better training data you will produce, the better the car will learn its
turns.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Transfer learning. You can pretrain your driving model in a virtual
environment such as
&lt;a href=&#34;https://github.com/tawnkramer/gym-donkeycar&#34;&gt;Donkey Gym&lt;/a&gt;.
See also this
&lt;a href=&#34;https://www.youtube.com/watch?v=J6Ll5Obtuxk&amp;amp;feature=youtu.be&#34;&gt;video&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;figure&gt;

&lt;img src=&#34;https://penkovsky.com/img/raspi/robo.jpg&#34; alt=&#34;A robot from 70s I have seen at Musée des Arts et Métiers in Paris. The robot inspired me for this project.&#34; width=&#34;590&#34; /&gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;&lt;/h4&gt;
  &lt;p&gt;
    A robot from 70s I have seen at Musée des Arts et Métiers in Paris. The robot inspired me for this project.
    
    
    
  &lt;/p&gt; 
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;I would like to thank the folks from the Integnano group who
gave me a Raspberry Pi as a birthday gift.
You are amazing!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;As always, if you have any questions, remarks, or spotted any typos please send me
a message.&lt;/p&gt;

&lt;h2 id=&#34;learn-more&#34;&gt;Learn More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://projects.raspberrypi.org/en/projects/build-a-buggy/1&#34;&gt;Build a robot buggy tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.societyofrobots.com/programming_differentialdrive.shtml&#34;&gt;Differential drive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://donkeycar.com&#34;&gt;Donkey Car platform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/smellslikeml/LitterBug_donkey/wiki&#34;&gt;LitterBug donkey&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4fXbDf_QWM4&amp;amp;feature=emb_logo&#34;&gt;Driving Tips to Train your Autonomous End-to-End NN Driver&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>In-Memory Resistive RAM Implementation of Binarized Neural Networks for Medical Applications</title>
      <link>https://penkovsky.com/publication/medical-bnn/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0200</pubDate>
      
      <guid>https://penkovsky.com/publication/medical-bnn/</guid>
      <description>&lt;p&gt;The results are very encouraging to reduce efficiently
memory requirement of edge devices and thus to obtain low energy hardware. This is particularly useful for medical applications where little energy is available.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
